{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"TeachMe.Codes This online document helps the absolute beginners to persue the future direction in coding and machine learning. The lesson starts with how to write code in Python along with fundamental ideas in data structure, function and class, Numpy, Pandas and some projects in Machine Learning (Linear Model, Classifiers e.g., Logistic regression, trees, svm, ensamble). Index Why Codes? Getting started Guide to starting Python Guide to Python Libraries Introduction to Programming Fundamental DataStructure Loops and Condition Function and Class Input-Output Projects Project Fern Project Random Walk Project N-charges Project Diffusion Numpy Array and ND Array Product and Tensor Product Grid and MeshGrid Linear Algebra Statistics Scipy Integration Differential Equations Optimization Roots Interpolation Fitting Pandas Dataframe Indexing Data Exploration GroupBy Lambda Transform Basic Visualization Matplotlib Seaborn Pandas Bohek Plotly Machine Learning Linear Regression Logistic Regression Decision Tree Support Vector Machine Nearest Neighbours Perceptron Clustering Prepared by: TeachMe.Codes","title":"Home"},{"location":"#teachmecodes","text":"This online document helps the absolute beginners to persue the future direction in coding and machine learning. The lesson starts with how to write code in Python along with fundamental ideas in data structure, function and class, Numpy, Pandas and some projects in Machine Learning (Linear Model, Classifiers e.g., Logistic regression, trees, svm, ensamble).","title":"TeachMe.Codes"},{"location":"#index","text":"Why Codes? Getting started Guide to starting Python Guide to Python Libraries Introduction to Programming Fundamental DataStructure Loops and Condition Function and Class Input-Output Projects Project Fern Project Random Walk Project N-charges Project Diffusion Numpy Array and ND Array Product and Tensor Product Grid and MeshGrid Linear Algebra Statistics Scipy Integration Differential Equations Optimization Roots Interpolation Fitting Pandas Dataframe Indexing Data Exploration GroupBy Lambda Transform Basic Visualization Matplotlib Seaborn Pandas Bohek Plotly Machine Learning Linear Regression Logistic Regression Decision Tree Support Vector Machine Nearest Neighbours Perceptron Clustering Prepared by: TeachMe.Codes","title":"Index"},{"location":"WhyCodes/","text":"Why Codes? Codes are apparently the language for Human-Machine interface. Coding is the most fundamental skill required for growing with modern days technology. Sicen our computers are built up based on logic and algorithm, our coding languages are also higher lavel of logical steps made undersatndable for human. By typing a line of code, we are speaking the laguage of the machine. Fundamentally, each programming language has it's inner working principle with underlying datastructure and functions. Computer while running a piece of code maintains the data in the memory ( temporary at RAM or permanent at Hard Disk). Whil code is live in the machine, it has time and space complexicities with the underlying datastructure and algotihm excuting the task.","title":"Why Codes?"},{"location":"WhyCodes/#why-codes","text":"Codes are apparently the language for Human-Machine interface. Coding is the most fundamental skill required for growing with modern days technology. Sicen our computers are built up based on logic and algorithm, our coding languages are also higher lavel of logical steps made undersatndable for human. By typing a line of code, we are speaking the laguage of the machine. Fundamentally, each programming language has it's inner working principle with underlying datastructure and functions. Computer while running a piece of code maintains the data in the memory ( temporary at RAM or permanent at Hard Disk). Whil code is live in the machine, it has time and space complexicities with the underlying datastructure and algotihm excuting the task.","title":"Why Codes?"},{"location":"prog/","text":"Introduction to Python programming Course Track: Introduction to Programming Fundamental DataStructure Loops and Condition Function and Class Projects Project Fern Project Random Walk Project N-charges Project Diffusion","title":"Introduction"},{"location":"prog/#introduction-to-python-programming","text":"Course Track:","title":"Introduction to Python programming"},{"location":"prog/#introduction-to-programming","text":"Fundamental DataStructure Loops and Condition Function and Class","title":"Introduction to Programming"},{"location":"prog/#projects","text":"Project Fern Project Random Walk Project N-charges Project Diffusion","title":"Projects"},{"location":"DataStructure/ds/","text":"Fundamental Data Structure : The fundamental data structure in python includes Primitive type ( Integer, Float, String , and Boolean ) and Non-Primitive type ( Array, List, Tuples, Dictionary, Set , and File ) In this tutorial, we are going to discudd about List, Tuples, Set and Dictionary. List List is built in data structure in python. It is - Mutable i.e., we can change or edite the size of the list by appending, inserting and deleting the elements. - List can hold heterogeneous objects (e.g., integer, string, boolean) Lets try to understand the List: To initiate a blank List. l = [] To find the type of the object. type (l) list To create a list from scratch. L = [ 1 , 2 , 3 , 4 , 5 , 6 ] Indexing of list. L[ 0 ],L[ 1 ],L[ 5 ] (1, 2, 6) Revers indexing is also possible. L[ - 1 ],L[ - 2 ],L[ - 3 ] (6, 5, 4) To find the length of list. len (L) 6 To add the element from last. L . append( 12 ) L [1, 2, 3, 4, 5, 6, 12] To find the sum of the elements (if they are of same types like int. double etc) sum (L) 33 To find maximum and minimum of the list max (L), min (L) (12, 1) To create a list of heterogeneous element types. L = [ 1 , 2.0 , 3 , 4 , 5 , Apple , True ] To find the type of elements of a list. type (L[ 1 ]), type (L[ 5 ]) (float, str) To create a list of list. L = [[ 1 , 2 , 3 ],[ 3 , 4 , 5 ],[ 5 , 7 , 9 ]] To find list inside a list. L[ 0 ] [1, 2, 3] L[ 0 ][ 1 ] 2 To add two list. It is not as ususal addition. The elements are accumulated. L1 = [ 1 , 2 , 3 ] ; L2 = [ 2 , 4 , 6 ] L1 + L2, set (L1 + L2) ([1, 2, 3, 2, 4, 6], {1, 2, 3, 4, 6}) To add element from end of the list L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . append( 100 ) L [1, 4, 2, 3, 5, 6, 7, 100] To insert element (100) at specific index (1) L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . insert( 1 , 100 ) L [1, 100, 4, 2, 3, 5, 6, 7] To remove specific element form list. It will remove the first occurance. L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 , 4 ] L . remove( 4 ) L [1, 2, 3, 5, 6, 7, 4] To remove the element from specific index L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . pop( - 1 ) L [1, 4, 2, 3, 5, 6] To sort the list L = [ 1 , 10 , 2 , 30 , 5 , 60 , 7 ] L . sort() L [1, 2, 5, 7, 10, 30, 60] To reverse the list L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . reverse() L [7, 6, 5, 3, 2, 4, 1] To create a List of List LL = [[ 1 , 2 , 3 ],[ 4 , 5 , 6 ],[ 5 , 6 , 7 ]] LL [[1, 2, 3], [4, 5, 6], [5, 6, 7]] Tuples Tuples are non-mutable, which means we can ot add or remove elements once tuple is defind. To define a tuples from scratch t = ( 2 , 3 , 4 , 5 ) Find type type (t) tuple Indexing t[ 1 ] 3 Create a list of tuples L = [( 1 , 2 ),( a , b ),( True , False )] L [(1, 2), ( a , b ), (True, False)] Dictionary Dictionary organizes the data with key-value pair. Dictionary can be nested with other data types. To initiate a dictionary D = dict () DD = {} Create a dictionary from scratch D = { fruit : apple , vegetable : carrot , rice : 2.0 , milk : 10 ,} What are keys? D . keys() dict_keys([ fruit , vegetable , rice , milk ]) What are values? D . values() dict_values([ apple , carrot , 2.0, 10]) Indexing D[ fruit ], D[ rice ] ( apple , 2.0) Iteration over key and values for key,value in D . items(): print (key,value) fruit apple vegetable carrot rice 2.0 milk 10 To update a dictionary D . update({ salt : 2.0 }) D { fruit : apple , vegetable : carrot , rice : 2.0, milk : 10, salt : 2.0} To create a list form a Dictionary. Only keys are collected. list (D) [ fruit , vegetable , rice , milk ] To create a list of keys only list (D . keys()) [ fruit , vegetable , rice , milk ] To create a list of values list (D . values()) [ apple , carrot , 2.0, 10, 2.0] To create Dictionary of with list, tuples and dictionary DD = { names :[ John , Harry , Brat ],\\ roll no : ( 1 , 2 , 3 ),\\ plan :{ first :[ 12 , 34 , 56 ], second :[ 1 , 3 , 5 ]}} DD { names : [ John , Harry , Brat ], roll no : (1, 2, 3), plan : { first : [12, 34, 56], second : [1, 3, 5]}}","title":"DataStructure"},{"location":"DataStructure/ds/#fundamental-data-structure","text":"The fundamental data structure in python includes Primitive type ( Integer, Float, String , and Boolean ) and Non-Primitive type ( Array, List, Tuples, Dictionary, Set , and File ) In this tutorial, we are going to discudd about List, Tuples, Set and Dictionary.","title":"Fundamental Data Structure :"},{"location":"DataStructure/ds/#list","text":"List is built in data structure in python. It is - Mutable i.e., we can change or edite the size of the list by appending, inserting and deleting the elements. - List can hold heterogeneous objects (e.g., integer, string, boolean) Lets try to understand the List: To initiate a blank List. l = [] To find the type of the object. type (l) list To create a list from scratch. L = [ 1 , 2 , 3 , 4 , 5 , 6 ] Indexing of list. L[ 0 ],L[ 1 ],L[ 5 ] (1, 2, 6) Revers indexing is also possible. L[ - 1 ],L[ - 2 ],L[ - 3 ] (6, 5, 4) To find the length of list. len (L) 6 To add the element from last. L . append( 12 ) L [1, 2, 3, 4, 5, 6, 12] To find the sum of the elements (if they are of same types like int. double etc) sum (L) 33 To find maximum and minimum of the list max (L), min (L) (12, 1) To create a list of heterogeneous element types. L = [ 1 , 2.0 , 3 , 4 , 5 , Apple , True ] To find the type of elements of a list. type (L[ 1 ]), type (L[ 5 ]) (float, str) To create a list of list. L = [[ 1 , 2 , 3 ],[ 3 , 4 , 5 ],[ 5 , 7 , 9 ]] To find list inside a list. L[ 0 ] [1, 2, 3] L[ 0 ][ 1 ] 2 To add two list. It is not as ususal addition. The elements are accumulated. L1 = [ 1 , 2 , 3 ] ; L2 = [ 2 , 4 , 6 ] L1 + L2, set (L1 + L2) ([1, 2, 3, 2, 4, 6], {1, 2, 3, 4, 6}) To add element from end of the list L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . append( 100 ) L [1, 4, 2, 3, 5, 6, 7, 100] To insert element (100) at specific index (1) L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . insert( 1 , 100 ) L [1, 100, 4, 2, 3, 5, 6, 7] To remove specific element form list. It will remove the first occurance. L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 , 4 ] L . remove( 4 ) L [1, 2, 3, 5, 6, 7, 4] To remove the element from specific index L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . pop( - 1 ) L [1, 4, 2, 3, 5, 6] To sort the list L = [ 1 , 10 , 2 , 30 , 5 , 60 , 7 ] L . sort() L [1, 2, 5, 7, 10, 30, 60] To reverse the list L = [ 1 , 4 , 2 , 3 , 5 , 6 , 7 ] L . reverse() L [7, 6, 5, 3, 2, 4, 1] To create a List of List LL = [[ 1 , 2 , 3 ],[ 4 , 5 , 6 ],[ 5 , 6 , 7 ]] LL [[1, 2, 3], [4, 5, 6], [5, 6, 7]]","title":"List"},{"location":"DataStructure/ds/#tuples","text":"Tuples are non-mutable, which means we can ot add or remove elements once tuple is defind. To define a tuples from scratch t = ( 2 , 3 , 4 , 5 ) Find type type (t) tuple Indexing t[ 1 ] 3 Create a list of tuples L = [( 1 , 2 ),( a , b ),( True , False )] L [(1, 2), ( a , b ), (True, False)]","title":"Tuples"},{"location":"DataStructure/ds/#dictionary","text":"Dictionary organizes the data with key-value pair. Dictionary can be nested with other data types. To initiate a dictionary D = dict () DD = {} Create a dictionary from scratch D = { fruit : apple , vegetable : carrot , rice : 2.0 , milk : 10 ,} What are keys? D . keys() dict_keys([ fruit , vegetable , rice , milk ]) What are values? D . values() dict_values([ apple , carrot , 2.0, 10]) Indexing D[ fruit ], D[ rice ] ( apple , 2.0) Iteration over key and values for key,value in D . items(): print (key,value) fruit apple vegetable carrot rice 2.0 milk 10 To update a dictionary D . update({ salt : 2.0 }) D { fruit : apple , vegetable : carrot , rice : 2.0, milk : 10, salt : 2.0} To create a list form a Dictionary. Only keys are collected. list (D) [ fruit , vegetable , rice , milk ] To create a list of keys only list (D . keys()) [ fruit , vegetable , rice , milk ] To create a list of values list (D . values()) [ apple , carrot , 2.0, 10, 2.0] To create Dictionary of with list, tuples and dictionary DD = { names :[ John , Harry , Brat ],\\ roll no : ( 1 , 2 , 3 ),\\ plan :{ first :[ 12 , 34 , 56 ], second :[ 1 , 3 , 5 ]}} DD { names : [ John , Harry , Brat ], roll no : (1, 2, 3), plan : { first : [12, 34, 56], second : [1, 3, 5]}}","title":"Dictionary"},{"location":"FunctionClass/fnc/","text":"Functions and Classes Function and Class are required for object oriented programming. Functions, once created, can be implemented multiple times while Class is more useful for both data encaptulation and functions. import numpy as np import random as random Class Circle Define a function which will take radious as input and provides area as output for a circle. def area (r): A = np . pi * r ** 2 return A Claculate the area of a sample circle of radius 10. area( 10 ) 314.1592653589793 Define a function which will take radious as input and provides circumference as output for a circle. def circumference (r): C = 2 * np . pi * r return C Claculate the circumference of a sample circle of radius 10. circumference( 10 ) 62.83185307179586 Lets build a class implementing above constants and functions class Circle (): def __init__ ( self , r): self . r = r def area ( self ): A = np . pi * self . r ** 2 return A def circumference ( self ): C = 2 * np . pi * self . r return C Test using examples. Circle object can be created by calling Circle(5) and function area() can be applied later ot together. Circle( 5 ) . area() 78.53981633974483 CC = Circle( 5 ) CC . area(),CC . circumference() (78.53981633974483, 31.41592653589793) Sililar to the functions, a data can be called from class object. CC . r 5 To use class and function object multiple time. for r in [ 2 , 3 , 6 , 24 , 25 , 46 , 567 ]: CC = Circle(r) print ( radius: , r,\\ area : , CC . area(),\\ circumf : , CC . circumference()) radius: 2 area : 12.566370614359172 circumf : 12.566370614359172 radius: 3 area : 28.274333882308138 circumf : 18.84955592153876 radius: 6 area : 113.09733552923255 circumf : 37.69911184307752 radius: 24 area : 1809.5573684677208 circumf : 150.79644737231007 radius: 25 area : 1963.4954084936207 circumf : 157.07963267948966 radius: 46 area : 6647.610054996002 circumf : 289.02652413026095 radius: 567 area : 1009987.480609929 circumf : 3562.5660691708254 Class Gravity To create a function Gravity def gravity (m1,m2,d): F = (m1 * m2) / d ** 2 return F gravity( 5 , 4 , 10 ) 0.2 Lets create a class Newton for Gravity calculation class Newton (): def __init__ ( self ,value_of_G, value_of_g, supplied_info): self . G = value_of_G self . info = supplied_info self . g = value_of_g def gravity ( self ,m1,m2,d): F = self . G * (m1 * m2) / d ** 2 print ( self . info) return F def gravity_pot ( self ,m1): F = m1 * self . g return F To create a object by calling a class with define inputs. N1 = Newton(value_of_G = 6.7 , value_of_g = 9.8 ,\\ supplied_info = great job ) To find constants and output of functions N1 . G, N1 . g,N1 . gravity( 2 , 3 , 13 ),N1 . gravity_pot( 12 ) great job (6.7, 9.8, 0.2378698224852071, 117.60000000000001) N1 . gravity(m1 = 11 ,m2 = 12 ,d = 3 ) great job 98.26666666666667 Class Dice Lets create a Class called Dice for fun class Dice ( object ): def __init__ ( self ,A_value,B_value,C_value): self . pi = 3.14 self . A = A_value self . B = B_value self . C = C_value def find_sum ( self ,n1,n2): S = n1 + n2 return S def find_product ( self ,n1,n2): P = n1 * n2 return P def poly ( self ,x): pl = self . A * self . find_product(x,x) + self . B * x + self . C return pl def roll_dice ( self ): side = random . choice([ 1 , 2 , 3 , 4 , 5 , 6 ]) return side def roll_two_dices ( self ): d1 = self . roll_dice() d2 = self . roll_dice() p = self . find_product(d1,d2) s = self . find_sum(d1,d2) return d1,d2,p,s To implement object created by class with predefined input A = 2.3 ; B = 4.5 ; C = 8.9 D = Dice(A,B,C) Can I ask this object for value of A, B and C? D . A, D . B, D . C (2.3, 4.5, 8.9) To roll a dice to get randum side D . roll_dice() 4 To roll two dice for two randum side. The roll_two_dices function implements find_sum() and find_product functions inside it. D . roll_two_dices() (2, 4, 8, 6) To roll a single dice and supply the output of single roll of dice to calculate polynomial function by implementing poly function d = D . roll_dice() D . poly(d) 43.1","title":"Functions and Class"},{"location":"FunctionClass/fnc/#functions-and-classes","text":"Function and Class are required for object oriented programming. Functions, once created, can be implemented multiple times while Class is more useful for both data encaptulation and functions. import numpy as np import random as random","title":"Functions and Classes"},{"location":"FunctionClass/fnc/#class-circle","text":"Define a function which will take radious as input and provides area as output for a circle. def area (r): A = np . pi * r ** 2 return A Claculate the area of a sample circle of radius 10. area( 10 ) 314.1592653589793 Define a function which will take radious as input and provides circumference as output for a circle. def circumference (r): C = 2 * np . pi * r return C Claculate the circumference of a sample circle of radius 10. circumference( 10 ) 62.83185307179586 Lets build a class implementing above constants and functions class Circle (): def __init__ ( self , r): self . r = r def area ( self ): A = np . pi * self . r ** 2 return A def circumference ( self ): C = 2 * np . pi * self . r return C Test using examples. Circle object can be created by calling Circle(5) and function area() can be applied later ot together. Circle( 5 ) . area() 78.53981633974483 CC = Circle( 5 ) CC . area(),CC . circumference() (78.53981633974483, 31.41592653589793) Sililar to the functions, a data can be called from class object. CC . r 5 To use class and function object multiple time. for r in [ 2 , 3 , 6 , 24 , 25 , 46 , 567 ]: CC = Circle(r) print ( radius: , r,\\ area : , CC . area(),\\ circumf : , CC . circumference()) radius: 2 area : 12.566370614359172 circumf : 12.566370614359172 radius: 3 area : 28.274333882308138 circumf : 18.84955592153876 radius: 6 area : 113.09733552923255 circumf : 37.69911184307752 radius: 24 area : 1809.5573684677208 circumf : 150.79644737231007 radius: 25 area : 1963.4954084936207 circumf : 157.07963267948966 radius: 46 area : 6647.610054996002 circumf : 289.02652413026095 radius: 567 area : 1009987.480609929 circumf : 3562.5660691708254","title":"Class Circle"},{"location":"FunctionClass/fnc/#class-gravity","text":"To create a function Gravity def gravity (m1,m2,d): F = (m1 * m2) / d ** 2 return F gravity( 5 , 4 , 10 ) 0.2 Lets create a class Newton for Gravity calculation class Newton (): def __init__ ( self ,value_of_G, value_of_g, supplied_info): self . G = value_of_G self . info = supplied_info self . g = value_of_g def gravity ( self ,m1,m2,d): F = self . G * (m1 * m2) / d ** 2 print ( self . info) return F def gravity_pot ( self ,m1): F = m1 * self . g return F To create a object by calling a class with define inputs. N1 = Newton(value_of_G = 6.7 , value_of_g = 9.8 ,\\ supplied_info = great job ) To find constants and output of functions N1 . G, N1 . g,N1 . gravity( 2 , 3 , 13 ),N1 . gravity_pot( 12 ) great job (6.7, 9.8, 0.2378698224852071, 117.60000000000001) N1 . gravity(m1 = 11 ,m2 = 12 ,d = 3 ) great job 98.26666666666667","title":"Class Gravity"},{"location":"FunctionClass/fnc/#class-dice","text":"Lets create a Class called Dice for fun class Dice ( object ): def __init__ ( self ,A_value,B_value,C_value): self . pi = 3.14 self . A = A_value self . B = B_value self . C = C_value def find_sum ( self ,n1,n2): S = n1 + n2 return S def find_product ( self ,n1,n2): P = n1 * n2 return P def poly ( self ,x): pl = self . A * self . find_product(x,x) + self . B * x + self . C return pl def roll_dice ( self ): side = random . choice([ 1 , 2 , 3 , 4 , 5 , 6 ]) return side def roll_two_dices ( self ): d1 = self . roll_dice() d2 = self . roll_dice() p = self . find_product(d1,d2) s = self . find_sum(d1,d2) return d1,d2,p,s To implement object created by class with predefined input A = 2.3 ; B = 4.5 ; C = 8.9 D = Dice(A,B,C) Can I ask this object for value of A, B and C? D . A, D . B, D . C (2.3, 4.5, 8.9) To roll a dice to get randum side D . roll_dice() 4 To roll two dice for two randum side. The roll_two_dices function implements find_sum() and find_product functions inside it. D . roll_two_dices() (2, 4, 8, 6) To roll a single dice and supply the output of single roll of dice to calculate polynomial function by implementing poly function d = D . roll_dice() D . poly(d) 43.1","title":"Class Dice"},{"location":"GettingStarted/anaconda/","text":"Installing Python To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python. Note- Linux: For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook Note - Cloud For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Guide to starting Python"},{"location":"GettingStarted/anaconda/#installing-python","text":"To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python.","title":"Installing Python"},{"location":"GettingStarted/anaconda/#note-linux","text":"For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook","title":"Note- Linux:"},{"location":"GettingStarted/anaconda/#note-cloud","text":"For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Note - Cloud"},{"location":"GettingStarted/env/","text":"Python Environment Basics To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = /Users/username/anaconda/bin: $PATH or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup Environments Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate Saving and loading environments A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml . Listing environments If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root . Removing environments If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ). Using environments One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican . Sharing environments When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda. More to learn To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"Setting up Python Environment"},{"location":"GettingStarted/env/#python-environment","text":"","title":"Python Environment"},{"location":"GettingStarted/env/#basics","text":"To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = /Users/username/anaconda/bin: $PATH or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup","title":"Basics"},{"location":"GettingStarted/env/#environments","text":"Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate","title":"Environments"},{"location":"GettingStarted/env/#saving-and-loading-environments","text":"A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml .","title":"Saving and loading environments"},{"location":"GettingStarted/env/#listing-environments","text":"If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root .","title":"Listing environments"},{"location":"GettingStarted/env/#removing-environments","text":"If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ).","title":"Removing environments"},{"location":"GettingStarted/env/#using-environments","text":"One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican .","title":"Using environments"},{"location":"GettingStarted/env/#sharing-environments","text":"When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda.","title":"Sharing environments"},{"location":"GettingStarted/env/#more-to-learn","text":"To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"More to learn"},{"location":"GettingStarted/git/","text":"How to git Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m First commit Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to Git"},{"location":"GettingStarted/git/#how-to-git","text":"Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m First commit Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to git"},{"location":"GettingStarted/jupyter/","text":"Installing Jupyter Notebook By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"GettingStarted/jupyter/#installing-jupyter-notebook","text":"By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"GettingStarted/lib/","text":"Python Libraries Following are the best Python Libraries: Numpy : For Algebraic Operation Matplotlib : For Plotting Scipy : For Scientific Computing IPython : For Python notebook Sympy : Symbolic Python Pandas : For Dataframe Seaborn : For Plotting PyData : For Pydata Plotly : For Frontend Plotting Bohek : For Front End Plotting Scikit : For Machine Learning TensorFlow : For Deep Learning","title":"Guide to Python Libraries"},{"location":"GettingStarted/lib/#python-libraries","text":"Following are the best Python Libraries: Numpy : For Algebraic Operation Matplotlib : For Plotting Scipy : For Scientific Computing IPython : For Python notebook Sympy : Symbolic Python Pandas : For Dataframe Seaborn : For Plotting PyData : For Pydata Plotly : For Frontend Plotting Bohek : For Front End Plotting Scikit : For Machine Learning TensorFlow : For Deep Learning","title":"Python Libraries"},{"location":"GettingStarted/note/","text":"Why Codes?","title":"Note"},{"location":"GettingStarted/note/#why-codes","text":"","title":"Why Codes?"},{"location":"Index/","text":"Index Why Codes? Getting started Guide to starting Python Guide to Python Libraries Introduction to Programming Fundamental DataStructure Loops and Condition Function and Class Input-Output Projects - Project Fern - Project Random Walk - Project N-charges - Project Diffusion Numpy Array and ND Array Product and Tensor Product Grid and MeshGrid Linear Algebra Statistics Scipy Integration Differential Equations Optimization Roots Interpolation Fitting Pandas Dataframe Indexing Data Exploration GroupBy Lambda Transform Basic Visualization Matplotlib Seaborn Pandas Bohek Plotly","title":"Index"},{"location":"Index/#index","text":"Why Codes? Getting started Guide to starting Python Guide to Python Libraries Introduction to Programming Fundamental DataStructure Loops and Condition Function and Class Input-Output Projects - Project Fern - Project Random Walk - Project N-charges - Project Diffusion Numpy Array and ND Array Product and Tensor Product Grid and MeshGrid Linear Algebra Statistics Scipy Integration Differential Equations Optimization Roots Interpolation Fitting Pandas Dataframe Indexing Data Exploration GroupBy Lambda Transform Basic Visualization Matplotlib Seaborn Pandas Bohek Plotly","title":"Index"},{"location":"LoopsConditions/lnc/","text":"Loops and conditions Loops provide the method of iteration while condition allows or blocks the code execution when specified condition is meet. For loop and While Loop To iterate over the List. Lets prin the items in the list L = [ apple , banana , kite , cellphone ] for item in L: print (item) apple banana kite cellphone What is range? range ( 5 ), range ( 1 , 100 ), sum ( range ( 100 )) (range(0, 5), range(1, 100), 4950) To iterate with for loop and adding the iterating index (the value of 10*k ) to a blank List L . L = [] for k in range ( 10 ): L . append( 10 * k) L [0, 10, 20, 30, 40, 50, 60, 70, 80, 90] To create a double loop also called nested for loop . Lets create double for loop with i and j with range 5 and also populate the dictionary with key as (i,j) and value as 10*i+j when i=j and 100*1+j when i!=j . D = {} for i in range ( 5 ): for j in range ( 5 ): if i == j : D . update({(i,j) : 10 * i + j}) elif i != j: D . update({(i,j) : 100 * i + j}) print (D) {(0, 0): 0, (0, 1): 1, (0, 2): 2, (0, 3): 3, (0, 4): 4, (1, 0): 100, (1, 1): 11, (1, 2): 102, (1, 3): 103, (1, 4): 104, (2, 0): 200, (2, 1): 201, (2, 2): 22, (2, 3): 203, (2, 4): 204, (3, 0): 300, (3, 1): 301, (3, 2): 302, (3, 3): 33, (3, 4): 304, (4, 0): 400, (4, 1): 401, (4, 2): 402, (4, 3): 403, (4, 4): 44} To iterate two elements from two seperate Lists. It is not like nested for loop. for item,j,k in zip ([ apple , banana , kite , cellphone , pen ],\\ range ( 5 ),[ 12 , 45 , 45 , 67 , 34 ]): print (item, | ,j, | ,k) apple | 0 | 12 banana | 1 | 45 kite | 2 | 45 cellphone | 3 | 67 pen | 4 | 34 To iterate and ennumerate both together. for i,item in enumerate ([ apple , banana , kite , cellphone ]): print ( The ,i, th element is: , item) The 0 th element is: apple The 1 th element is: banana The 2 th element is: kite The 3 th element is: cellphone To create a list with for loop A = [ 10 * k ** 2 + 5 * k + 1 for k in range ( 10 )] print (A) [1, 16, 51, 106, 181, 276, 391, 526, 681, 856] AA = [[ 10 * x ** 2 + 5 * y + 1 for x in range ( 3 )] for y in range ( 3 )] print (AA) [[1, 11, 41], [6, 16, 46], [11, 21, 51]] To iterate over List of List for i in range ( 3 ): for j in range ( 3 ): print ( The , ( ,i, , ,j, ) , th element is: ,AA[i][j]) The ( 0 , 0 ) th element is: 1 The ( 0 , 1 ) th element is: 11 The ( 0 , 2 ) th element is: 41 The ( 1 , 0 ) th element is: 6 The ( 1 , 1 ) th element is: 16 The ( 1 , 2 ) th element is: 46 The ( 2 , 0 ) th element is: 11 The ( 2 , 1 ) th element is: 21 The ( 2 , 2 ) th element is: 51 To use while loop. i = 0 while i 5 : print ( i, th turn ) i = i + 1 0 th turn 1 th turn 2 th turn 3 th turn 4 th turn To break for loop implementing if condition for i in range ( 10 ): print (i) if i == 3 : break 0 1 2 3 To test the if conditions: import random as random for i in range ( 10 ): r = random . uniform( 1 , 10 ) if r 2 and r 0 : print ( It is samaller then 2 and greater then 1 , | , r) elif r 4 and r 2 : print ( It is samaller then 4 and greater then 2 , | , r) elif r 6 and r 4 : print ( It is samaller then 6 and greater then 4 , | , r) elif r 8 and r 6 : print ( It is samaller then 8 and greater then 6 , | , r) elif r 10 and r 8 : print ( It is samaller then 10 and greater then 8 , | , r) It is samaller then 10 and greater then 8 | 8.910435750481426 It is samaller then 8 and greater then 6 | 6.616669779231224 It is samaller then 4 and greater then 2 | 3.8009645328925896 It is samaller then 4 and greater then 2 | 3.3039198434839117 It is samaller then 4 and greater then 2 | 3.2192327041596696 It is samaller then 10 and greater then 8 | 8.658302824387317 It is samaller then 10 and greater then 8 | 9.048987906482312 It is samaller then 10 and greater then 8 | 8.061577985253708 It is samaller then 8 and greater then 6 | 6.301327115111054 It is samaller then 6 and greater then 4 | 5.316492901781898 To find sum from 0 to 1000 s = 0 for i in range ( 1000 + 1 ): s = s + i s 500500 To find sum from 0 to 1000 (only even) s = 0 LE = [] for i in range ( 1001 ): if i % 2 == 0 : LE . append(i) s = s + i s, sum (LE) (250500, 250500)","title":"Loops and Conditions"},{"location":"LoopsConditions/lnc/#loops-and-conditions","text":"Loops provide the method of iteration while condition allows or blocks the code execution when specified condition is meet.","title":"Loops and conditions"},{"location":"LoopsConditions/lnc/#for-loop-and-while-loop","text":"To iterate over the List. Lets prin the items in the list L = [ apple , banana , kite , cellphone ] for item in L: print (item) apple banana kite cellphone What is range? range ( 5 ), range ( 1 , 100 ), sum ( range ( 100 )) (range(0, 5), range(1, 100), 4950) To iterate with for loop and adding the iterating index (the value of 10*k ) to a blank List L . L = [] for k in range ( 10 ): L . append( 10 * k) L [0, 10, 20, 30, 40, 50, 60, 70, 80, 90] To create a double loop also called nested for loop . Lets create double for loop with i and j with range 5 and also populate the dictionary with key as (i,j) and value as 10*i+j when i=j and 100*1+j when i!=j . D = {} for i in range ( 5 ): for j in range ( 5 ): if i == j : D . update({(i,j) : 10 * i + j}) elif i != j: D . update({(i,j) : 100 * i + j}) print (D) {(0, 0): 0, (0, 1): 1, (0, 2): 2, (0, 3): 3, (0, 4): 4, (1, 0): 100, (1, 1): 11, (1, 2): 102, (1, 3): 103, (1, 4): 104, (2, 0): 200, (2, 1): 201, (2, 2): 22, (2, 3): 203, (2, 4): 204, (3, 0): 300, (3, 1): 301, (3, 2): 302, (3, 3): 33, (3, 4): 304, (4, 0): 400, (4, 1): 401, (4, 2): 402, (4, 3): 403, (4, 4): 44} To iterate two elements from two seperate Lists. It is not like nested for loop. for item,j,k in zip ([ apple , banana , kite , cellphone , pen ],\\ range ( 5 ),[ 12 , 45 , 45 , 67 , 34 ]): print (item, | ,j, | ,k) apple | 0 | 12 banana | 1 | 45 kite | 2 | 45 cellphone | 3 | 67 pen | 4 | 34 To iterate and ennumerate both together. for i,item in enumerate ([ apple , banana , kite , cellphone ]): print ( The ,i, th element is: , item) The 0 th element is: apple The 1 th element is: banana The 2 th element is: kite The 3 th element is: cellphone To create a list with for loop A = [ 10 * k ** 2 + 5 * k + 1 for k in range ( 10 )] print (A) [1, 16, 51, 106, 181, 276, 391, 526, 681, 856] AA = [[ 10 * x ** 2 + 5 * y + 1 for x in range ( 3 )] for y in range ( 3 )] print (AA) [[1, 11, 41], [6, 16, 46], [11, 21, 51]] To iterate over List of List for i in range ( 3 ): for j in range ( 3 ): print ( The , ( ,i, , ,j, ) , th element is: ,AA[i][j]) The ( 0 , 0 ) th element is: 1 The ( 0 , 1 ) th element is: 11 The ( 0 , 2 ) th element is: 41 The ( 1 , 0 ) th element is: 6 The ( 1 , 1 ) th element is: 16 The ( 1 , 2 ) th element is: 46 The ( 2 , 0 ) th element is: 11 The ( 2 , 1 ) th element is: 21 The ( 2 , 2 ) th element is: 51 To use while loop. i = 0 while i 5 : print ( i, th turn ) i = i + 1 0 th turn 1 th turn 2 th turn 3 th turn 4 th turn To break for loop implementing if condition for i in range ( 10 ): print (i) if i == 3 : break 0 1 2 3 To test the if conditions: import random as random for i in range ( 10 ): r = random . uniform( 1 , 10 ) if r 2 and r 0 : print ( It is samaller then 2 and greater then 1 , | , r) elif r 4 and r 2 : print ( It is samaller then 4 and greater then 2 , | , r) elif r 6 and r 4 : print ( It is samaller then 6 and greater then 4 , | , r) elif r 8 and r 6 : print ( It is samaller then 8 and greater then 6 , | , r) elif r 10 and r 8 : print ( It is samaller then 10 and greater then 8 , | , r) It is samaller then 10 and greater then 8 | 8.910435750481426 It is samaller then 8 and greater then 6 | 6.616669779231224 It is samaller then 4 and greater then 2 | 3.8009645328925896 It is samaller then 4 and greater then 2 | 3.3039198434839117 It is samaller then 4 and greater then 2 | 3.2192327041596696 It is samaller then 10 and greater then 8 | 8.658302824387317 It is samaller then 10 and greater then 8 | 9.048987906482312 It is samaller then 10 and greater then 8 | 8.061577985253708 It is samaller then 8 and greater then 6 | 6.301327115111054 It is samaller then 6 and greater then 4 | 5.316492901781898 To find sum from 0 to 1000 s = 0 for i in range ( 1000 + 1 ): s = s + i s 500500 To find sum from 0 to 1000 (only even) s = 0 LE = [] for i in range ( 1001 ): if i % 2 == 0 : LE . append(i) s = s + i s, sum (LE) (250500, 250500)","title":"For loop and While Loop"},{"location":"Numpy/numpy/","text":"Introduction to Numpy Course Track: Array MeshGrid Algebra Statistics","title":"Introduction"},{"location":"Numpy/numpy/#introduction-to-numpy","text":"Course Track: Array MeshGrid Algebra Statistics","title":"Introduction to Numpy"},{"location":"Numpy/algebra/algebra/","text":"Algebra: transpose , dot , linalg Read more about algebra library here import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() Dot Product $$ u = M.v $$ v = np . random . rand( 5 ) v array([ 0.61880652, 0.16277711, 0.77725885, 0.39357105, 0.72518988]) M = np . random . rand( 5 , 5 ) M array([[ 0.44722927, 0.75871176, 0.74971577, 0.83610699, 0.18085266], [ 0.00121306, 0.84271476, 0.65241612, 0.27094445, 0.63364293], [ 0.07906587, 0.85301928, 0.62214839, 0.59205861, 0.70427723], [ 0.88162665, 0.76250728, 0.15724579, 0.63985535, 0.04617605], [ 0.57250482, 0.6551876 , 0.562632 , 0.29052545, 0.29159418]]) u = np . dot(M,v) u array([ 1.44319253, 1.21116885, 1.41510068, 1.07721068, 1.22403352]) Transpose of a matrix plt . figure(figsize = [ 15 , 6 ]) plt . subplot( 1 , 2 , 1 ) sns . heatmap(M, annot = True ) plt . subplot( 1 , 2 , 2 ) sns . heatmap(M . T, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x11ce902b0 Solve import numpy.linalg as LA M = np . random . rand( 5 , 5 ) v = np . random . rand( 5 ) LA . solve(M, v) array([-0.70443073, 0.00920272, 1.79273467, 0.28129874, 0.0351515 ]) Inverse MI = LA . inv(M) np . dot(MI,M) array([[ 1.00000000e+00, 1.11022302e-16, -2.22044605e-16, -2.77555756e-17, -5.55111512e-17], [ -4.44089210e-16, 1.00000000e+00, -4.44089210e-16, -3.74700271e-16, -2.22044605e-16], [ 1.11022302e-16, 1.11022302e-16, 1.00000000e+00, 2.08166817e-17, 1.38777878e-16], [ 0.00000000e+00, 2.22044605e-16, 2.22044605e-16, 1.00000000e+00, 5.55111512e-17], [ 4.44089210e-16, 1.11022302e-16, 2.22044605e-16, 4.16333634e-17, 1.00000000e+00]]) Determinant LA . det(M) -0.045069829276640772 Singular Value Decomposition U,s,v = LA . svd(M) U array([[-0.36955796, 0.82623516, -0.10506496, -0.38322577, 0.15120101], [-0.40915055, -0.52825188, 0.07308364, -0.58566133, 0.45299599], [-0.27156968, -0.02207665, -0.5227498 , 0.57959325, 0.56264272], [-0.70259694, -0.01970269, 0.54356007, 0.39190428, -0.23858507], [-0.35865051, -0.19341623, -0.64412362, -0.14360195, -0.63122359]]) s array([ 2.22951719, 1.04725056, 0.39529212, 0.2559056 , 0.19082116]) v array([[-0.5796746 , -0.39152082, -0.43864895, -0.32442397, -0.46154631], [-0.5284475 , 0.42628206, -0.3319487 , 0.63137979, 0.1737713 ], [ 0.36619987, -0.57923042, -0.56088856, 0.3066463 , 0.3489439 ], [-0.23678668, 0.14559935, -0.16403051, -0.58705857, 0.74242112], [-0.44107859, -0.55523689, 0.59656951, 0.2396642 , 0.28952991]])","title":"Algebra"},{"location":"Numpy/algebra/algebra/#algebra-transpose-dot-linalg","text":"Read more about algebra library here import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"Algebra: transpose,    dot,    linalg"},{"location":"Numpy/algebra/algebra/#dot-product","text":"$$ u = M.v $$ v = np . random . rand( 5 ) v array([ 0.61880652, 0.16277711, 0.77725885, 0.39357105, 0.72518988]) M = np . random . rand( 5 , 5 ) M array([[ 0.44722927, 0.75871176, 0.74971577, 0.83610699, 0.18085266], [ 0.00121306, 0.84271476, 0.65241612, 0.27094445, 0.63364293], [ 0.07906587, 0.85301928, 0.62214839, 0.59205861, 0.70427723], [ 0.88162665, 0.76250728, 0.15724579, 0.63985535, 0.04617605], [ 0.57250482, 0.6551876 , 0.562632 , 0.29052545, 0.29159418]]) u = np . dot(M,v) u array([ 1.44319253, 1.21116885, 1.41510068, 1.07721068, 1.22403352])","title":"Dot Product"},{"location":"Numpy/algebra/algebra/#transpose-of-a-matrix","text":"plt . figure(figsize = [ 15 , 6 ]) plt . subplot( 1 , 2 , 1 ) sns . heatmap(M, annot = True ) plt . subplot( 1 , 2 , 2 ) sns . heatmap(M . T, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x11ce902b0","title":"Transpose of a matrix"},{"location":"Numpy/algebra/algebra/#solve","text":"import numpy.linalg as LA M = np . random . rand( 5 , 5 ) v = np . random . rand( 5 ) LA . solve(M, v) array([-0.70443073, 0.00920272, 1.79273467, 0.28129874, 0.0351515 ])","title":"Solve"},{"location":"Numpy/algebra/algebra/#inverse","text":"MI = LA . inv(M) np . dot(MI,M) array([[ 1.00000000e+00, 1.11022302e-16, -2.22044605e-16, -2.77555756e-17, -5.55111512e-17], [ -4.44089210e-16, 1.00000000e+00, -4.44089210e-16, -3.74700271e-16, -2.22044605e-16], [ 1.11022302e-16, 1.11022302e-16, 1.00000000e+00, 2.08166817e-17, 1.38777878e-16], [ 0.00000000e+00, 2.22044605e-16, 2.22044605e-16, 1.00000000e+00, 5.55111512e-17], [ 4.44089210e-16, 1.11022302e-16, 2.22044605e-16, 4.16333634e-17, 1.00000000e+00]])","title":"Inverse"},{"location":"Numpy/algebra/algebra/#determinant","text":"LA . det(M) -0.045069829276640772","title":"Determinant"},{"location":"Numpy/algebra/algebra/#singular-value-decomposition","text":"U,s,v = LA . svd(M) U array([[-0.36955796, 0.82623516, -0.10506496, -0.38322577, 0.15120101], [-0.40915055, -0.52825188, 0.07308364, -0.58566133, 0.45299599], [-0.27156968, -0.02207665, -0.5227498 , 0.57959325, 0.56264272], [-0.70259694, -0.01970269, 0.54356007, 0.39190428, -0.23858507], [-0.35865051, -0.19341623, -0.64412362, -0.14360195, -0.63122359]]) s array([ 2.22951719, 1.04725056, 0.39529212, 0.2559056 , 0.19082116]) v array([[-0.5796746 , -0.39152082, -0.43864895, -0.32442397, -0.46154631], [-0.5284475 , 0.42628206, -0.3319487 , 0.63137979, 0.1737713 ], [ 0.36619987, -0.57923042, -0.56088856, 0.3066463 , 0.3489439 ], [-0.23678668, 0.14559935, -0.16403051, -0.58705857, 0.74242112], [-0.44107859, -0.55523689, 0.59656951, 0.2396642 , 0.28952991]])","title":"Singular Value Decomposition"},{"location":"Numpy/array/array/","text":"Numpy tutorial : Array numpy.array , numpy.array.shape , numpy.reshape , numpy.concatenate How to import Numpy library in python import numpy as np array : creating array from list np . array([ 1 , 2 , 3 , 4 ]) array([1, 2, 3, 4]) np . zeros([ 3 , 4 ]) array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) np . ones([ 3 , 3 ]) array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) Creating random matrix of size 10,10 X = np . random . rand( 10 , 10 ) X array([[0.9311515 , 0.67884177, 0.76163691, 0.28748043, 0.06952019, 0.57756085, 0.94357278, 0.66863999, 0.24938489, 0.99347099], [0.76764289, 0.18683651, 0.78127182, 0.8623092 , 0.94597186, 0.9789824 , 0.85675548, 0.86551995, 0.99206322, 0.15268812], [0.981708 , 0.47869981, 0.77828502, 0.76757002, 0.33535944, 0.53592128, 0.40202929, 0.52178243, 0.15259798, 0.94683227], [0.65286918, 0.27848771, 0.32560513, 0.45056069, 0.18100504, 0.84261218, 0.422149 , 0.21301687, 0.57554343, 0.07971878], [0.57691729, 0.16052797, 0.02820894, 0.66050066, 0.56261128, 0.32582041, 0.87131161, 0.36877167, 0.21222514, 0.47938826], [0.32899391, 0.31987521, 0.89478609, 0.90458122, 0.00820214, 0.96769399, 0.56621307, 0.70947586, 0.64261577, 0.61137201], [0.79006349, 0.89937467, 0.46190865, 0.90491822, 0.66487736, 0.24496253, 0.16261092, 0.31506249, 0.0064727 , 0.42401798], [0.99436863, 0.6323061 , 0.4935466 , 0.912547 , 0.38500243, 0.4960181 , 0.71025453, 0.79576306, 0.03396949, 0.71088413], [0.26799206, 0.41849134, 0.72926964, 0.57710126, 0.36234733, 0.85170595, 0.91298546, 0.8891687 , 0.4984441 , 0.23131008], [0.86864829, 0.0859265 , 0.44055358, 0.92151801, 0.65870714, 0.0021256 , 0.49167628, 0.47508668, 0.48659742, 0.92269232]]) Visualization of array : Heat map import matplotlib.pyplot as plt import seaborn as sns sns . set() plt . figure(figsize = [ 15 , 10 ]) sns . heatmap(X, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x7f3dcc89b9b0 Find subarray : splitting to 4 subarrays plt . figure(figsize = [ 15 , 10 ]) plt . subplot( 2 , 2 , 1 ) sns . heatmap(X[ 0 : 5 , 0 : 5 ], annot = True ) plt . subplot( 2 , 2 , 2 ) sns . heatmap(X[ 5 : 10 , 0 : 5 ], annot = True ) plt . subplot( 2 , 2 , 3 ) sns . heatmap(X[ 0 : 5 , 5 : 10 ], annot = True ) plt . subplot( 2 , 2 , 4 ) sns . heatmap(X[ 5 : 10 , 5 : 10 ], annot = True ) plt . show() Change shape of array: from [10 by 10] to [20 by 5] X . shape = ( 20 , 5 ) X array([[0.3188929 , 0.6959524 , 0.73093736, 0.43628291, 0.49014931], [0.67804229, 0.26945929, 0.6787637 , 0.49544915, 0.28129553], [0.75672154, 0.09647321, 0.46344621, 0.57988862, 0.0843775 ], [0.21978525, 0.99238676, 0.80045437, 0.83230711, 0.1300036 ], [0.18533263, 0.85867317, 0.4496527 , 0.72355778, 0.97670987], [0.03893615, 0.41116845, 0.61798222, 0.67051191, 0.53543659], [0.95259274, 0.14566815, 0.74642352, 0.92240214, 0.02270644], [0.82583077, 0.22513541, 0.68126091, 0.80503395, 0.20994175], [0.5572094 , 0.61159805, 0.23046078, 0.9423228 , 0.34073382], [0.55237701, 0.56379448, 0.99317082, 0.27824713, 0.75344767], [0.90546342, 0.3534449 , 0.83919252, 0.03603223, 0.56586636], [0.54411187, 0.10881733, 0.29566636, 0.49793917, 0.66915791], [0.23681423, 0.23852226, 0.84623021, 0.2428092 , 0.04609895], [0.42833986, 0.05091374, 0.69665706, 0.29589828, 0.52183274], [0.03402203, 0.23676124, 0.87017633, 0.3862823 , 0.48184487], [0.2613791 , 0.52247716, 0.98673513, 0.35632249, 0.62492285], [0.3047382 , 0.6577787 , 0.10553745, 0.37968368, 0.45684338], [0.86127512, 0.72617042, 0.79811008, 0.71744026, 0.01710278], [0.97486086, 0.3659719 , 0.68581511, 0.85199672, 0.15147913], [0.38602888, 0.60889842, 0.43274503, 0.49652464, 0.55742177]]) plt . figure(figsize = [ 15 , 10 ]) sns . heatmap(X, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x7f3dccc2e4a8 Reshaping the Array X = np . arange( 35 ) X array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]) XX = np . reshape(X, ( 7 , 5 )) plt . figure(figsize = [ 8 , 6 ]) sns . heatmap(XX, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x7f3dcca794e0 Flatten the Array X = np . random . rand( 4 , 5 ) X . shape (4, 5) X array([[0.46425663, 0.26273357, 0.76715497, 0.02803551, 0.06077554], [0.45085724, 0.20021709, 0.83866571, 0.93010498, 0.82287586], [0.64015274, 0.40214994, 0.46140888, 0.10875569, 0.90314464], [0.1996534 , 0.00575243, 0.19888495, 0.80968552, 0.66819322]]) Y = X . flatten() Y . shape (20,) Y array([0.46425663, 0.26273357, 0.76715497, 0.02803551, 0.06077554, 0.45085724, 0.20021709, 0.83866571, 0.93010498, 0.82287586, 0.64015274, 0.40214994, 0.46140888, 0.10875569, 0.90314464, 0.1996534 , 0.00575243, 0.19888495, 0.80968552, 0.66819322]) Concatenate the Array A = np . random . rand( 3 , 4 ) B = np . random . rand( 3 , 4 ) Verticle addition C = np . concatenate((A,B),axis = 0 ) Horizontal Addition D = np . concatenate((A,B),axis = 1 ) Array Disply plt . figure(figsize = [ 15 , 10 ]) plt . subplot( 2 , 2 , 1 ) sns . heatmap(A, annot = True ) plt . subplot( 2 , 2 , 2 ) sns . heatmap(B, annot = True ) plt . subplot( 2 , 2 , 3 ) sns . heatmap(C, annot = True ) plt . subplot( 2 , 2 , 4 ) sns . heatmap(D, annot = True ) plt . show() Row sum and column sum X = np . random . rand( 8 , 6 ) sum of all elements X . sum() 24.566949569026413 Row sum np . sum(X,axis = 1 ) array([4.20288936, 2.3996539 , 2.46388761, 4.30291271, 2.60671914, 2.23461285, 2.68832592, 3.6679481 ]) Column sum np . sum(X,axis = 0 ) array([3.69453055, 3.84555591, 5.87500707, 2.90605569, 4.41441644, 3.83138392])","title":"Array"},{"location":"Numpy/array/array/#numpy-tutorial-array","text":"numpy.array , numpy.array.shape , numpy.reshape , numpy.concatenate","title":"Numpy tutorial : Array"},{"location":"Numpy/array/array/#how-to-import-numpy-library-in-python","text":"import numpy as np","title":"How to import Numpy library in python"},{"location":"Numpy/array/array/#array-creating-array-from-list","text":"np . array([ 1 , 2 , 3 , 4 ]) array([1, 2, 3, 4]) np . zeros([ 3 , 4 ]) array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) np . ones([ 3 , 3 ]) array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]])","title":"array : creating array from list"},{"location":"Numpy/array/array/#creating-random-matrix-of-size-1010","text":"X = np . random . rand( 10 , 10 ) X array([[0.9311515 , 0.67884177, 0.76163691, 0.28748043, 0.06952019, 0.57756085, 0.94357278, 0.66863999, 0.24938489, 0.99347099], [0.76764289, 0.18683651, 0.78127182, 0.8623092 , 0.94597186, 0.9789824 , 0.85675548, 0.86551995, 0.99206322, 0.15268812], [0.981708 , 0.47869981, 0.77828502, 0.76757002, 0.33535944, 0.53592128, 0.40202929, 0.52178243, 0.15259798, 0.94683227], [0.65286918, 0.27848771, 0.32560513, 0.45056069, 0.18100504, 0.84261218, 0.422149 , 0.21301687, 0.57554343, 0.07971878], [0.57691729, 0.16052797, 0.02820894, 0.66050066, 0.56261128, 0.32582041, 0.87131161, 0.36877167, 0.21222514, 0.47938826], [0.32899391, 0.31987521, 0.89478609, 0.90458122, 0.00820214, 0.96769399, 0.56621307, 0.70947586, 0.64261577, 0.61137201], [0.79006349, 0.89937467, 0.46190865, 0.90491822, 0.66487736, 0.24496253, 0.16261092, 0.31506249, 0.0064727 , 0.42401798], [0.99436863, 0.6323061 , 0.4935466 , 0.912547 , 0.38500243, 0.4960181 , 0.71025453, 0.79576306, 0.03396949, 0.71088413], [0.26799206, 0.41849134, 0.72926964, 0.57710126, 0.36234733, 0.85170595, 0.91298546, 0.8891687 , 0.4984441 , 0.23131008], [0.86864829, 0.0859265 , 0.44055358, 0.92151801, 0.65870714, 0.0021256 , 0.49167628, 0.47508668, 0.48659742, 0.92269232]])","title":"Creating random matrix of size 10,10"},{"location":"Numpy/array/array/#visualization-of-array-heat-map","text":"import matplotlib.pyplot as plt import seaborn as sns sns . set() plt . figure(figsize = [ 15 , 10 ]) sns . heatmap(X, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x7f3dcc89b9b0","title":"Visualization of array : Heat map"},{"location":"Numpy/array/array/#find-subarray-splitting-to-4-subarrays","text":"plt . figure(figsize = [ 15 , 10 ]) plt . subplot( 2 , 2 , 1 ) sns . heatmap(X[ 0 : 5 , 0 : 5 ], annot = True ) plt . subplot( 2 , 2 , 2 ) sns . heatmap(X[ 5 : 10 , 0 : 5 ], annot = True ) plt . subplot( 2 , 2 , 3 ) sns . heatmap(X[ 0 : 5 , 5 : 10 ], annot = True ) plt . subplot( 2 , 2 , 4 ) sns . heatmap(X[ 5 : 10 , 5 : 10 ], annot = True ) plt . show()","title":"Find subarray : splitting to 4 subarrays"},{"location":"Numpy/array/array/#change-shape-of-array-from-10-by-10-to-20-by-5","text":"X . shape = ( 20 , 5 ) X array([[0.3188929 , 0.6959524 , 0.73093736, 0.43628291, 0.49014931], [0.67804229, 0.26945929, 0.6787637 , 0.49544915, 0.28129553], [0.75672154, 0.09647321, 0.46344621, 0.57988862, 0.0843775 ], [0.21978525, 0.99238676, 0.80045437, 0.83230711, 0.1300036 ], [0.18533263, 0.85867317, 0.4496527 , 0.72355778, 0.97670987], [0.03893615, 0.41116845, 0.61798222, 0.67051191, 0.53543659], [0.95259274, 0.14566815, 0.74642352, 0.92240214, 0.02270644], [0.82583077, 0.22513541, 0.68126091, 0.80503395, 0.20994175], [0.5572094 , 0.61159805, 0.23046078, 0.9423228 , 0.34073382], [0.55237701, 0.56379448, 0.99317082, 0.27824713, 0.75344767], [0.90546342, 0.3534449 , 0.83919252, 0.03603223, 0.56586636], [0.54411187, 0.10881733, 0.29566636, 0.49793917, 0.66915791], [0.23681423, 0.23852226, 0.84623021, 0.2428092 , 0.04609895], [0.42833986, 0.05091374, 0.69665706, 0.29589828, 0.52183274], [0.03402203, 0.23676124, 0.87017633, 0.3862823 , 0.48184487], [0.2613791 , 0.52247716, 0.98673513, 0.35632249, 0.62492285], [0.3047382 , 0.6577787 , 0.10553745, 0.37968368, 0.45684338], [0.86127512, 0.72617042, 0.79811008, 0.71744026, 0.01710278], [0.97486086, 0.3659719 , 0.68581511, 0.85199672, 0.15147913], [0.38602888, 0.60889842, 0.43274503, 0.49652464, 0.55742177]]) plt . figure(figsize = [ 15 , 10 ]) sns . heatmap(X, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x7f3dccc2e4a8","title":"Change shape of array:  from [10 by 10] to [20 by 5]"},{"location":"Numpy/array/array/#reshaping-the-array","text":"X = np . arange( 35 ) X array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]) XX = np . reshape(X, ( 7 , 5 )) plt . figure(figsize = [ 8 , 6 ]) sns . heatmap(XX, annot = True ) matplotlib.axes._subplots.AxesSubplot at 0x7f3dcca794e0","title":"Reshaping the Array"},{"location":"Numpy/array/array/#flatten-the-array","text":"X = np . random . rand( 4 , 5 ) X . shape (4, 5) X array([[0.46425663, 0.26273357, 0.76715497, 0.02803551, 0.06077554], [0.45085724, 0.20021709, 0.83866571, 0.93010498, 0.82287586], [0.64015274, 0.40214994, 0.46140888, 0.10875569, 0.90314464], [0.1996534 , 0.00575243, 0.19888495, 0.80968552, 0.66819322]]) Y = X . flatten() Y . shape (20,) Y array([0.46425663, 0.26273357, 0.76715497, 0.02803551, 0.06077554, 0.45085724, 0.20021709, 0.83866571, 0.93010498, 0.82287586, 0.64015274, 0.40214994, 0.46140888, 0.10875569, 0.90314464, 0.1996534 , 0.00575243, 0.19888495, 0.80968552, 0.66819322])","title":"Flatten the Array"},{"location":"Numpy/array/array/#concatenate-the-array","text":"A = np . random . rand( 3 , 4 ) B = np . random . rand( 3 , 4 )","title":"Concatenate the Array"},{"location":"Numpy/array/array/#verticle-addition","text":"C = np . concatenate((A,B),axis = 0 )","title":"Verticle addition"},{"location":"Numpy/array/array/#horizontal-addition","text":"D = np . concatenate((A,B),axis = 1 )","title":"Horizontal Addition"},{"location":"Numpy/array/array/#array-disply","text":"plt . figure(figsize = [ 15 , 10 ]) plt . subplot( 2 , 2 , 1 ) sns . heatmap(A, annot = True ) plt . subplot( 2 , 2 , 2 ) sns . heatmap(B, annot = True ) plt . subplot( 2 , 2 , 3 ) sns . heatmap(C, annot = True ) plt . subplot( 2 , 2 , 4 ) sns . heatmap(D, annot = True ) plt . show()","title":"Array Disply"},{"location":"Numpy/array/array/#row-sum-and-column-sum","text":"X = np . random . rand( 8 , 6 )","title":"Row sum and column sum"},{"location":"Numpy/array/array/#sum-of-all-elements","text":"X . sum() 24.566949569026413","title":"sum of all elements"},{"location":"Numpy/array/array/#row-sum","text":"np . sum(X,axis = 1 ) array([4.20288936, 2.3996539 , 2.46388761, 4.30291271, 2.60671914, 2.23461285, 2.68832592, 3.6679481 ])","title":"Row sum"},{"location":"Numpy/array/array/#column-sum","text":"np . sum(X,axis = 0 ) array([3.69453055, 3.84555591, 5.87500707, 2.90605569, 4.41441644, 3.83138392])","title":"Column sum"},{"location":"Numpy/grid/meshgrid/","text":"Numpy tutorial : arange , meshgrid How to import Numpy library in python import numpy as np 1. arange : How to generate integers from n1 to n2 X = np . arange( 10 ) X array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) X * X array([ 0, 1, 4, 9, 16, 25, 36, 49, 64, 81]) np . arange( 3 , 12 ) array([ 3, 4, 5, 6, 7, 8, 9, 10, 11]) np . arange( 1 , 10 , 2 ) array([1, 3, 5, 7, 9]) np . arange( 10 , 11 , 0.01 ) array([10. , 10.01, 10.02, 10.03, 10.04, 10.05, 10.06, 10.07, 10.08, 10.09, 10.1 , 10.11, 10.12, 10.13, 10.14, 10.15, 10.16, 10.17, 10.18, 10.19, 10.2 , 10.21, 10.22, 10.23, 10.24, 10.25, 10.26, 10.27, 10.28, 10.29, 10.3 , 10.31, 10.32, 10.33, 10.34, 10.35, 10.36, 10.37, 10.38, 10.39, 10.4 , 10.41, 10.42, 10.43, 10.44, 10.45, 10.46, 10.47, 10.48, 10.49, 10.5 , 10.51, 10.52, 10.53, 10.54, 10.55, 10.56, 10.57, 10.58, 10.59, 10.6 , 10.61, 10.62, 10.63, 10.64, 10.65, 10.66, 10.67, 10.68, 10.69, 10.7 , 10.71, 10.72, 10.73, 10.74, 10.75, 10.76, 10.77, 10.78, 10.79, 10.8 , 10.81, 10.82, 10.83, 10.84, 10.85, 10.86, 10.87, 10.88, 10.89, 10.9 , 10.91, 10.92, 10.93, 10.94, 10.95, 10.96, 10.97, 10.98, 10.99]) 1.1 Application import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline sns . set() x = np . arange( 0 , 1 , 0.01 ) plt . figure(figsize = [ 10 , 10 ]) plt . plot(x,x ** 2 ,\\ x,x ** 3 ,\\ x,x ** 4 ,\\ x,x ** 5 ,\\ x,x ** 6 ,\\ x,x ** 7 ,\\ x,x ** 8 ,\\ x,x ** 9 ,\\ x,x ** 10 ) plt . grid( True ) plt . xlabel( x ,fontsize = 20 ) plt . ylabel( x^n ,fontsize = 20 ) plt . show() Creating Numpy array data_array = np . array([x,x ** 2 ,x ** 3 ,x ** 4 ,x ** 5 ,x ** 6 ,x ** 7 ,x ** 8 ,x ** 9 ,x ** 10 ]) data_array[ 0 : 5 , 0 : 5 ] array([[0.000e+00, 1.000e-02, 2.000e-02, 3.000e-02, 4.000e-02], [0.000e+00, 1.000e-04, 4.000e-04, 9.000e-04, 1.600e-03], [0.000e+00, 1.000e-06, 8.000e-06, 2.700e-05, 6.400e-05], [0.000e+00, 1.000e-08, 1.600e-07, 8.100e-07, 2.560e-06], [0.000e+00, 1.000e-10, 3.200e-09, 2.430e-08, 1.024e-07]]) data_array . shape (10, 100) 2. meshgrid : How to create a grid and it's application to ploting cost functions x = np . arange( - 6 , 6 , 0.05 ) y = np . arange( - 6 , 6 , 0.05 ) grid = np . meshgrid(x,y) 1. Example Cost function $\\large{Z = \\frac{sin(x^2+y^2).cos(x^2-y^2)}{x^2+y^2}}$ xx, yy = np . meshgrid(x, y, sparse = True ) # --------------------------------------------- z = np . sin(xx ** 2 + yy ** 2 ) * np . cos(xx ** 2 - yy ** 2 ) / (xx ** 2 + yy ** 2 ) plt . figure(figsize = [ 15 , 10 ]) h = plt . contour(x,y,z) # Label contours plt . clabel(CS, inline = 1 , fontsize = 10 ) a list of 147 text.Text objects from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator, FormatStrFormatter import numpy as np fig = plt . figure(figsize = [ 15 , 10 ]) ax = fig . gca(projection = 3d ) # Make data. x = np . arange( - 3 , 3 , 0.01 ) y = np . arange( - 3 , 3 , 0.01 ) xx, yy = np . meshgrid(x, y) # ------------------------------- z = np . sin(xx ** 2 + yy ** 2 ) * np . cos(xx ** 2 - yy ** 2 ) / (xx ** 2 + yy ** 2 ) # Plot the surface. surf = ax . plot_surface(xx, yy, z, cmap = cm . coolwarm,linewidth = 0 , antialiased = False ) # Customize the z axis. #ax.set_zlim(-1.01, 1.01) ax . zaxis . set_major_locator(LinearLocator( 10 )) ax . zaxis . set_major_formatter(FormatStrFormatter( %.02f )) # Add a color bar which maps values to colors. fig . colorbar(surf, shrink = 0.5 , aspect = 5 ) plt . show() Example 2: Simulated annealing import math as math $\\large{Z = 0.2 + x^2 + y^2 -0.1 \\cos(6 \\pi x) - 0.1\\cos(6 \\pi y)}$ # Design variables at mesh points x = np . arange( - 1.0 , 1.0 , 0.01 ) y = np . arange( - 1.0 , 1.0 , 0.01 ) xx, yy = np . meshgrid(x, y) # ----------------------------- z = 0.2 + xx ** 2 + yy ** 2 \\ - 0.5 * np . cos( 6.0 * math . pi * xx)\\ - 0.5 * np . cos( 6.0 * math . pi * yy) # Create a contour plot plt . figure(figsize = [ 15 , 10 ]) CS = plt . contour(xx, yy, z) # Label contours plt . clabel(CS, inline = 1 , fontsize = 10 ) plt . title( Non-Convex Function ) plt . xlabel( x1 ) plt . ylabel( x2 ) Text(0,0.5, x2 ) from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator, FormatStrFormatter import numpy as np fig = plt . figure(figsize = [ 15 , 10 ]) ax = fig . gca(projection = 3d ) # Make data. x = np . arange( - 1 , 1 , 0.01 ) y = np . arange( - 1 , 1 , 0.01 ) xx, yy = np . meshgrid(x, y) # ------------------------------- z = 0.2 + xx ** 2 + yy ** 2 \\ - 0.5 * np . cos( 6.0 * math . pi * xx)\\ - 0.5 * np . cos( 6.0 * math . pi * yy) # Plot the surface. surf = ax . plot_surface(xx, yy, z, cmap = cm . coolwarm,linewidth = 0 , antialiased = False ) # Customize the z axis. #ax.set_zlim(-1.01, 1.01) ax . zaxis . set_major_locator(LinearLocator( 10 )) ax . zaxis . set_major_formatter(FormatStrFormatter( %.02f )) # Add a color bar which maps values to colors. fig . colorbar(surf, shrink = 0.5 , aspect = 5 ) plt . show()","title":"MeshGrid"},{"location":"Numpy/grid/meshgrid/#numpy-tutorial-arangemeshgrid","text":"","title":"Numpy tutorial : arange,meshgrid"},{"location":"Numpy/grid/meshgrid/#how-to-import-numpy-library-in-python","text":"import numpy as np","title":"How to import Numpy library in python"},{"location":"Numpy/grid/meshgrid/#1-arange-how-to-generate-integers-from-n1-to-n2","text":"X = np . arange( 10 ) X array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) X * X array([ 0, 1, 4, 9, 16, 25, 36, 49, 64, 81]) np . arange( 3 , 12 ) array([ 3, 4, 5, 6, 7, 8, 9, 10, 11]) np . arange( 1 , 10 , 2 ) array([1, 3, 5, 7, 9]) np . arange( 10 , 11 , 0.01 ) array([10. , 10.01, 10.02, 10.03, 10.04, 10.05, 10.06, 10.07, 10.08, 10.09, 10.1 , 10.11, 10.12, 10.13, 10.14, 10.15, 10.16, 10.17, 10.18, 10.19, 10.2 , 10.21, 10.22, 10.23, 10.24, 10.25, 10.26, 10.27, 10.28, 10.29, 10.3 , 10.31, 10.32, 10.33, 10.34, 10.35, 10.36, 10.37, 10.38, 10.39, 10.4 , 10.41, 10.42, 10.43, 10.44, 10.45, 10.46, 10.47, 10.48, 10.49, 10.5 , 10.51, 10.52, 10.53, 10.54, 10.55, 10.56, 10.57, 10.58, 10.59, 10.6 , 10.61, 10.62, 10.63, 10.64, 10.65, 10.66, 10.67, 10.68, 10.69, 10.7 , 10.71, 10.72, 10.73, 10.74, 10.75, 10.76, 10.77, 10.78, 10.79, 10.8 , 10.81, 10.82, 10.83, 10.84, 10.85, 10.86, 10.87, 10.88, 10.89, 10.9 , 10.91, 10.92, 10.93, 10.94, 10.95, 10.96, 10.97, 10.98, 10.99])","title":"1. arange : How to generate integers from n1 to n2"},{"location":"Numpy/grid/meshgrid/#11-application","text":"import matplotlib.pyplot as plt import seaborn as sns % matplotlib inline sns . set() x = np . arange( 0 , 1 , 0.01 ) plt . figure(figsize = [ 10 , 10 ]) plt . plot(x,x ** 2 ,\\ x,x ** 3 ,\\ x,x ** 4 ,\\ x,x ** 5 ,\\ x,x ** 6 ,\\ x,x ** 7 ,\\ x,x ** 8 ,\\ x,x ** 9 ,\\ x,x ** 10 ) plt . grid( True ) plt . xlabel( x ,fontsize = 20 ) plt . ylabel( x^n ,fontsize = 20 ) plt . show()","title":"1.1 Application"},{"location":"Numpy/grid/meshgrid/#creating-numpy-array","text":"data_array = np . array([x,x ** 2 ,x ** 3 ,x ** 4 ,x ** 5 ,x ** 6 ,x ** 7 ,x ** 8 ,x ** 9 ,x ** 10 ]) data_array[ 0 : 5 , 0 : 5 ] array([[0.000e+00, 1.000e-02, 2.000e-02, 3.000e-02, 4.000e-02], [0.000e+00, 1.000e-04, 4.000e-04, 9.000e-04, 1.600e-03], [0.000e+00, 1.000e-06, 8.000e-06, 2.700e-05, 6.400e-05], [0.000e+00, 1.000e-08, 1.600e-07, 8.100e-07, 2.560e-06], [0.000e+00, 1.000e-10, 3.200e-09, 2.430e-08, 1.024e-07]]) data_array . shape (10, 100)","title":"Creating Numpy array"},{"location":"Numpy/grid/meshgrid/#2-meshgrid-how-to-create-a-grid-and-its-application-to-ploting-cost-functions","text":"x = np . arange( - 6 , 6 , 0.05 ) y = np . arange( - 6 , 6 , 0.05 ) grid = np . meshgrid(x,y)","title":"2. meshgrid :  How to create a grid and it's application to ploting cost functions"},{"location":"Numpy/grid/meshgrid/#1-example-cost-function","text":"$\\large{Z = \\frac{sin(x^2+y^2).cos(x^2-y^2)}{x^2+y^2}}$ xx, yy = np . meshgrid(x, y, sparse = True ) # --------------------------------------------- z = np . sin(xx ** 2 + yy ** 2 ) * np . cos(xx ** 2 - yy ** 2 ) / (xx ** 2 + yy ** 2 ) plt . figure(figsize = [ 15 , 10 ]) h = plt . contour(x,y,z) # Label contours plt . clabel(CS, inline = 1 , fontsize = 10 ) a list of 147 text.Text objects from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator, FormatStrFormatter import numpy as np fig = plt . figure(figsize = [ 15 , 10 ]) ax = fig . gca(projection = 3d ) # Make data. x = np . arange( - 3 , 3 , 0.01 ) y = np . arange( - 3 , 3 , 0.01 ) xx, yy = np . meshgrid(x, y) # ------------------------------- z = np . sin(xx ** 2 + yy ** 2 ) * np . cos(xx ** 2 - yy ** 2 ) / (xx ** 2 + yy ** 2 ) # Plot the surface. surf = ax . plot_surface(xx, yy, z, cmap = cm . coolwarm,linewidth = 0 , antialiased = False ) # Customize the z axis. #ax.set_zlim(-1.01, 1.01) ax . zaxis . set_major_locator(LinearLocator( 10 )) ax . zaxis . set_major_formatter(FormatStrFormatter( %.02f )) # Add a color bar which maps values to colors. fig . colorbar(surf, shrink = 0.5 , aspect = 5 ) plt . show()","title":"1. Example Cost function"},{"location":"Numpy/grid/meshgrid/#example-2-simulated-annealing","text":"import math as math $\\large{Z = 0.2 + x^2 + y^2 -0.1 \\cos(6 \\pi x) - 0.1\\cos(6 \\pi y)}$ # Design variables at mesh points x = np . arange( - 1.0 , 1.0 , 0.01 ) y = np . arange( - 1.0 , 1.0 , 0.01 ) xx, yy = np . meshgrid(x, y) # ----------------------------- z = 0.2 + xx ** 2 + yy ** 2 \\ - 0.5 * np . cos( 6.0 * math . pi * xx)\\ - 0.5 * np . cos( 6.0 * math . pi * yy) # Create a contour plot plt . figure(figsize = [ 15 , 10 ]) CS = plt . contour(xx, yy, z) # Label contours plt . clabel(CS, inline = 1 , fontsize = 10 ) plt . title( Non-Convex Function ) plt . xlabel( x1 ) plt . ylabel( x2 ) Text(0,0.5, x2 ) from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator, FormatStrFormatter import numpy as np fig = plt . figure(figsize = [ 15 , 10 ]) ax = fig . gca(projection = 3d ) # Make data. x = np . arange( - 1 , 1 , 0.01 ) y = np . arange( - 1 , 1 , 0.01 ) xx, yy = np . meshgrid(x, y) # ------------------------------- z = 0.2 + xx ** 2 + yy ** 2 \\ - 0.5 * np . cos( 6.0 * math . pi * xx)\\ - 0.5 * np . cos( 6.0 * math . pi * yy) # Plot the surface. surf = ax . plot_surface(xx, yy, z, cmap = cm . coolwarm,linewidth = 0 , antialiased = False ) # Customize the z axis. #ax.set_zlim(-1.01, 1.01) ax . zaxis . set_major_locator(LinearLocator( 10 )) ax . zaxis . set_major_formatter(FormatStrFormatter( %.02f )) # Add a color bar which maps values to colors. fig . colorbar(surf, shrink = 0.5 , aspect = 5 ) plt . show()","title":"Example 2: Simulated annealing"},{"location":"Numpy/stat/stat/","text":"Numpy Tutorial: Sattistics import numpy as np A = np . random . rand( 10 , 10 ) A array([[ 0.14686345, 0.4890597 , 0.95867873, 0.70684257, 0.4571942 , 0.88999371, 0.94088925, 0.39260288, 0.63593196, 0.91229658], [ 0.48868386, 0.12750921, 0.53490442, 0.85215575, 0.68973691, 0.86751533, 0.10078796, 0.570043 , 0.57702153, 0.82067194], [ 0.36724515, 0.44952882, 0.14455048, 0.92813935, 0.82722792, 0.15527858, 0.72646211, 0.78073294, 0.07039077, 0.02742469], [ 0.93215519, 0.78939341, 0.05433345, 0.63077664, 0.12257019, 0.38620259, 0.50937441, 0.5286639 , 0.13651584, 0.08476626], [ 0.02843688, 0.87159643, 0.58489852, 0.51735115, 0.5759214 , 0.74431949, 0.55435673, 0.28474752, 0.77936953, 0.39612921], [ 0.73733762, 0.90077575, 0.86999616, 0.69950308, 0.68703817, 0.5340441 , 0.42895176, 0.99739758, 0.05244868, 0.30736319], [ 0.43320514, 0.29546614, 0.70165549, 0.07203503, 0.58150789, 0.64377815, 0.4401386 , 0.14734496, 0.43707321, 0.7376671 ], [ 0.32679964, 0.39911744, 0.82063392, 0.42401808, 0.95892193, 0.72902086, 0.90609457, 0.66556375, 0.00359741, 0.51747374], [ 0.8956028 , 0.32121392, 0.77467549, 0.53642615, 0.85494789, 0.56736366, 0.54043267, 0.26757794, 0.68840931, 0.47665347], [ 0.13547503, 0.36567291, 0.28543209, 0.91452908, 0.57162599, 0.34107302, 0.14420041, 0.87902944, 0.68964655, 0.42688096]]) A . shape (10, 10) A . max() 0.9973975789240529 A . min() 0.0035974071135107533 A . mean() 0.53281080467131514 np . median(A) 0.53842941044090042 A . std() 0.30117722286159915 Mean and std of row np . mean(A,axis = 0 ) array([ 0.39053118, 0.38187714, 0.45877901, 0.61380263, 0.64927112, 0.46921661, 0.60222378, 0.50624244, 0.27490776, 0.54313828]) np . std(A,axis = 0 ) array([ 0.32438441, 0.29543643, 0.35045695, 0.27228791, 0.2178827 , 0.26696293, 0.32834441, 0.1804856 , 0.18123375, 0.31624931]) Mean and std of col np . mean(A,axis = 1 ) array([ 0.24116424, 0.48699354, 0.4219599 , 0.43972281, 0.47657735, 0.57537948, 0.55289209, 0.66313705, 0.46013377, 0.57202973]) np . std(A,axis = 1 ) array([ 0.19852809, 0.33144078, 0.28219183, 0.27736838, 0.22851456, 0.33649951, 0.31209182, 0.20212544, 0.27845001, 0.31922731]) Standard scalar : feature scaling A_ss = A - A . min() / A . max() - A . min() A_ss array([[ 4.10527053e-01, 7.54472423e-01, 7.94834247e-01, 7.30222536e-01, 2.05492062e-01, 7.26892063e-01, 7.31928243e-01, 5.75438370e-01, 5.93092716e-01, 3.64078100e-01], [ 6.91227074e-01, 3.26851066e-01, 6.93898234e-01, 5.00701344e-02, 7.09305332e-01, 8.38725771e-02, 7.42069173e-03, 7.35359172e-01, 2.95379821e-01, 6.85238478e-01], [ 7.79833365e-01, 7.41786430e-01, 3.19212366e-01, 6.81133292e-01, 8.84713319e-01, 6.79371426e-01, 5.60580679e-01, 1.38029784e-01, 8.13389121e-02, 8.39869709e-01], [ 4.95468619e-01, 8.24202013e-01, -5.68858232e-04, 4.31268827e-01, 3.38998416e-01, 9.81193130e-01, 4.35576371e-01, 6.44445825e-02, 4.62408333e-02, 6.89168348e-01], [ 4.83093638e-01, 4.35554299e-01, 8.99866132e-01, 9.27827109e-01, 2.75868637e-01, 2.11364337e-01, 5.98421053e-01, 4.63481490e-01, 5.65166049e-01, 4.00957652e-01], [ 6.48396649e-01, 8.91158478e-01, 2.62023883e-01, 4.97729268e-01, 4.86885273e-01, 1.39092208e-01, 3.41289269e-01, 3.48342574e-01, 4.56935240e-01, 4.67606744e-01], [ 2.80349932e-01, 6.49334474e-01, 6.69037668e-01, 5.85372776e-01, 7.04975765e-01, 8.00871254e-01, 5.35627470e-01, 9.70136155e-01, 1.16631608e-01, 2.79515900e-01], [ 9.08763495e-01, 3.00196542e-02, 5.99466774e-02, 6.81881968e-01, 7.96816096e-01, 2.63795132e-01, 9.82016613e-02, 8.91612556e-01, 4.33903568e-01, 1.27023490e-02], [ 2.62261736e-01, -4.47661111e-03, 4.01181988e-01, 6.78168605e-01, 9.14777758e-01, 7.66458761e-01, 1.03201876e-01, 9.73263369e-01, 5.80404084e-01, 1.51452341e-01], [ 5.09890394e-01, 6.55040004e-01, 1.14783059e-01, 1.22995637e-02, 2.48635616e-01, 8.57963655e-01, 9.79050239e-01, 7.73205705e-01, 8.14437099e-01, 2.42875670e-01]]) Normalization : sample Normalization B = np . random . rand( 5 , 5 ) Bn = B - B . mean() / B . std() Bn array([[-1.50414377, -1.87642236, -1.57282944, -1.72966009, -1.87154951], [-1.55166607, -1.52753634, -1.52791948, -1.46539342, -1.37820295], [-1.93716316, -1.53215212, -1.40664146, -1.72826488, -1.89673994], [-1.45251097, -1.46672865, -1.58718485, -1.3702699 , -1.17691599], [-1.98244464, -1.73232164, -1.75732137, -1.74607803, -1.64767919]]) Normal Distribution x = np . arange( - 20 , 20 , 0.01 ) import matplotlib.pyplot as plt % matplotlib inline import seaborn as sns import math as math sns . set() $$f(x,\\mu,\\sigma^{2}) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} e ^{\\frac{-(x-\\mu)^{2}}{2\\sigma^{2}}}$$ def normal (x,m,s): f = ( 1 / np . sqrt( 2 * np . pi * s)) * np . exp( - (x - m) ** 2 / ( 2 * s ** 2 )) return f plt . figure(figsize = [ 15 , 10 ]) plt . plot(x,normal(x, 1.0 , 1.0 ),\\ x,normal(x, 2.0 , 2.0 ),\\ x,normal(x, 3.0 , 3.0 ),\\ x,normal(x, 4.0 , 4.0 ),\\ x,normal(x, 5.0 , 5.0 ),\\ x,normal(x, 6.0 , 6.0 )) plt . show()","title":"Statistics"},{"location":"Numpy/stat/stat/#numpy-tutorial-sattistics","text":"import numpy as np A = np . random . rand( 10 , 10 ) A array([[ 0.14686345, 0.4890597 , 0.95867873, 0.70684257, 0.4571942 , 0.88999371, 0.94088925, 0.39260288, 0.63593196, 0.91229658], [ 0.48868386, 0.12750921, 0.53490442, 0.85215575, 0.68973691, 0.86751533, 0.10078796, 0.570043 , 0.57702153, 0.82067194], [ 0.36724515, 0.44952882, 0.14455048, 0.92813935, 0.82722792, 0.15527858, 0.72646211, 0.78073294, 0.07039077, 0.02742469], [ 0.93215519, 0.78939341, 0.05433345, 0.63077664, 0.12257019, 0.38620259, 0.50937441, 0.5286639 , 0.13651584, 0.08476626], [ 0.02843688, 0.87159643, 0.58489852, 0.51735115, 0.5759214 , 0.74431949, 0.55435673, 0.28474752, 0.77936953, 0.39612921], [ 0.73733762, 0.90077575, 0.86999616, 0.69950308, 0.68703817, 0.5340441 , 0.42895176, 0.99739758, 0.05244868, 0.30736319], [ 0.43320514, 0.29546614, 0.70165549, 0.07203503, 0.58150789, 0.64377815, 0.4401386 , 0.14734496, 0.43707321, 0.7376671 ], [ 0.32679964, 0.39911744, 0.82063392, 0.42401808, 0.95892193, 0.72902086, 0.90609457, 0.66556375, 0.00359741, 0.51747374], [ 0.8956028 , 0.32121392, 0.77467549, 0.53642615, 0.85494789, 0.56736366, 0.54043267, 0.26757794, 0.68840931, 0.47665347], [ 0.13547503, 0.36567291, 0.28543209, 0.91452908, 0.57162599, 0.34107302, 0.14420041, 0.87902944, 0.68964655, 0.42688096]]) A . shape (10, 10) A . max() 0.9973975789240529 A . min() 0.0035974071135107533 A . mean() 0.53281080467131514 np . median(A) 0.53842941044090042 A . std() 0.30117722286159915","title":"Numpy Tutorial: Sattistics"},{"location":"Numpy/stat/stat/#mean-and-std-of-row","text":"np . mean(A,axis = 0 ) array([ 0.39053118, 0.38187714, 0.45877901, 0.61380263, 0.64927112, 0.46921661, 0.60222378, 0.50624244, 0.27490776, 0.54313828]) np . std(A,axis = 0 ) array([ 0.32438441, 0.29543643, 0.35045695, 0.27228791, 0.2178827 , 0.26696293, 0.32834441, 0.1804856 , 0.18123375, 0.31624931])","title":"Mean and std of row"},{"location":"Numpy/stat/stat/#mean-and-std-of-col","text":"np . mean(A,axis = 1 ) array([ 0.24116424, 0.48699354, 0.4219599 , 0.43972281, 0.47657735, 0.57537948, 0.55289209, 0.66313705, 0.46013377, 0.57202973]) np . std(A,axis = 1 ) array([ 0.19852809, 0.33144078, 0.28219183, 0.27736838, 0.22851456, 0.33649951, 0.31209182, 0.20212544, 0.27845001, 0.31922731])","title":"Mean and std of col"},{"location":"Numpy/stat/stat/#standard-scalar-feature-scaling","text":"A_ss = A - A . min() / A . max() - A . min() A_ss array([[ 4.10527053e-01, 7.54472423e-01, 7.94834247e-01, 7.30222536e-01, 2.05492062e-01, 7.26892063e-01, 7.31928243e-01, 5.75438370e-01, 5.93092716e-01, 3.64078100e-01], [ 6.91227074e-01, 3.26851066e-01, 6.93898234e-01, 5.00701344e-02, 7.09305332e-01, 8.38725771e-02, 7.42069173e-03, 7.35359172e-01, 2.95379821e-01, 6.85238478e-01], [ 7.79833365e-01, 7.41786430e-01, 3.19212366e-01, 6.81133292e-01, 8.84713319e-01, 6.79371426e-01, 5.60580679e-01, 1.38029784e-01, 8.13389121e-02, 8.39869709e-01], [ 4.95468619e-01, 8.24202013e-01, -5.68858232e-04, 4.31268827e-01, 3.38998416e-01, 9.81193130e-01, 4.35576371e-01, 6.44445825e-02, 4.62408333e-02, 6.89168348e-01], [ 4.83093638e-01, 4.35554299e-01, 8.99866132e-01, 9.27827109e-01, 2.75868637e-01, 2.11364337e-01, 5.98421053e-01, 4.63481490e-01, 5.65166049e-01, 4.00957652e-01], [ 6.48396649e-01, 8.91158478e-01, 2.62023883e-01, 4.97729268e-01, 4.86885273e-01, 1.39092208e-01, 3.41289269e-01, 3.48342574e-01, 4.56935240e-01, 4.67606744e-01], [ 2.80349932e-01, 6.49334474e-01, 6.69037668e-01, 5.85372776e-01, 7.04975765e-01, 8.00871254e-01, 5.35627470e-01, 9.70136155e-01, 1.16631608e-01, 2.79515900e-01], [ 9.08763495e-01, 3.00196542e-02, 5.99466774e-02, 6.81881968e-01, 7.96816096e-01, 2.63795132e-01, 9.82016613e-02, 8.91612556e-01, 4.33903568e-01, 1.27023490e-02], [ 2.62261736e-01, -4.47661111e-03, 4.01181988e-01, 6.78168605e-01, 9.14777758e-01, 7.66458761e-01, 1.03201876e-01, 9.73263369e-01, 5.80404084e-01, 1.51452341e-01], [ 5.09890394e-01, 6.55040004e-01, 1.14783059e-01, 1.22995637e-02, 2.48635616e-01, 8.57963655e-01, 9.79050239e-01, 7.73205705e-01, 8.14437099e-01, 2.42875670e-01]])","title":"Standard scalar :  feature scaling"},{"location":"Numpy/stat/stat/#normalization-sample-normalization","text":"B = np . random . rand( 5 , 5 ) Bn = B - B . mean() / B . std() Bn array([[-1.50414377, -1.87642236, -1.57282944, -1.72966009, -1.87154951], [-1.55166607, -1.52753634, -1.52791948, -1.46539342, -1.37820295], [-1.93716316, -1.53215212, -1.40664146, -1.72826488, -1.89673994], [-1.45251097, -1.46672865, -1.58718485, -1.3702699 , -1.17691599], [-1.98244464, -1.73232164, -1.75732137, -1.74607803, -1.64767919]])","title":"Normalization :  sample Normalization"},{"location":"Numpy/stat/stat/#normal-distribution","text":"x = np . arange( - 20 , 20 , 0.01 ) import matplotlib.pyplot as plt % matplotlib inline import seaborn as sns import math as math sns . set() $$f(x,\\mu,\\sigma^{2}) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} e ^{\\frac{-(x-\\mu)^{2}}{2\\sigma^{2}}}$$ def normal (x,m,s): f = ( 1 / np . sqrt( 2 * np . pi * s)) * np . exp( - (x - m) ** 2 / ( 2 * s ** 2 )) return f plt . figure(figsize = [ 15 , 10 ]) plt . plot(x,normal(x, 1.0 , 1.0 ),\\ x,normal(x, 2.0 , 2.0 ),\\ x,normal(x, 3.0 , 3.0 ),\\ x,normal(x, 4.0 , 4.0 ),\\ x,normal(x, 5.0 , 5.0 ),\\ x,normal(x, 6.0 , 6.0 )) plt . show()","title":"Normal Distribution"},{"location":"Pandas/pandas/","text":"Introduction to Pandas Course Track: DataFrame Indexing Data Exploration GroupBy Lambda Transformation","title":"Introduction"},{"location":"Pandas/pandas/#introduction-to-pandas","text":"Course Track: DataFrame Indexing Data Exploration GroupBy Lambda Transformation","title":"Introduction to Pandas"},{"location":"Pandas/DataFrame/dataframe/","text":"Data View with Titanic dataset import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() Load data titanic = pd . read_csv( data/titanic.csv ) titanic . head( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 5 6 0 3 Moran, Mr. James male NaN 0 0 330877 8.4583 NaN Q 6 7 0 1 McCarthy, Mr. Timothy J male 54.0 0 0 17463 51.8625 E46 S 7 8 0 3 Palsson, Master. Gosta Leonard male 2.0 3 1 349909 21.0750 NaN S 8 9 1 3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) female 27.0 0 2 347742 11.1333 NaN S 9 10 1 2 Nasser, Mrs. Nicholas (Adele Achem) female 14.0 1 0 237736 30.0708 NaN C titanic . shape (891, 12) titanic . columns Index([ PassengerId , Survived , Pclass , Name , Sex , Age , SibSp , Parch , Ticket , Fare , Cabin , Embarked ], dtype= object ) titanic . index RangeIndex(start=0, stop=891, step=1) Preliminary Satatistics titanic . describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 Setting Name column as index titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C DataFrame Creation (Numpy Array) From Numpy array = Dataframe import random as random A = np . random . rand( 100 , 20 ) A . shape (100, 20) letter = [ A , B , C , D , E , F , G , H , X ] col_names = [ random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter) for i in range (A . shape[ 1 ])] col_names [ BHBE , FCEX , HCDC , BABH , DHCC , BEAH , CGCA , CBFF , GDBX , GDBD , GCXG , EBAF , FHFC , ADXF , XGDB , FDCB , BGGD , CXXC , GBDE , HGXX ] df = pd . DataFrame(A, columns = col_names ) df . to_csv( data/test.csv ) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } BHBE FCEX HCDC BABH DHCC BEAH CGCA CBFF GDBX GDBD GCXG EBAF FHFC ADXF XGDB FDCB BGGD CXXC GBDE HGXX 0 0.505613 0.863802 0.064671 0.044665 0.661631 0.010504 0.441470 0.749321 0.389375 0.468762 0.061095 0.779629 0.262696 0.834874 0.762955 0.464253 0.762709 0.425008 0.131542 0.791414 1 0.722504 0.465511 0.555621 0.843348 0.987537 0.955876 0.788946 0.461034 0.278317 0.269186 0.616559 0.095630 0.552730 0.531865 0.056233 0.796237 0.705609 0.683914 0.168146 0.312616 2 0.577487 0.355478 0.939323 0.547315 0.158492 0.226048 0.941994 0.025595 0.291006 0.549547 0.157811 0.358243 0.297590 0.767994 0.804289 0.349676 0.786392 0.806113 0.386147 0.766741 3 0.612300 0.610556 0.141520 0.657244 0.694400 0.555290 0.912868 0.350494 0.203160 0.703884 0.873016 0.420604 0.361509 0.380023 0.819483 0.988239 0.455447 0.732307 0.063254 0.123586 4 0.476368 0.890201 0.923328 0.931688 0.481882 0.411059 0.540152 0.831890 0.737365 0.681351 0.620813 0.018067 0.794526 0.491711 0.116032 0.096085 0.086113 0.813632 0.828594 0.063989 Data Frame = Numpy Array Data Frame (List of Dictionary) LD = [] for i in range ( 100 ): LD . append({ Player : random . choice(letter) + random . choice(letter) + random . choice(letter) + random . choice(letter),\\ game1 : random . uniform( 0 , 1 ),\\ game2 : random . uniform( 0 , 1 ),\\ game3 : random . uniform( 0 , 1 ), game4 : random . uniform( 0 , 1 ), game5 : random . uniform( 0 , 1 )}) DF = pd . DataFrame(LD) DF . head( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Player game1 game2 game3 game4 game5 0 CGHX 0.222859 0.370064 0.966385 0.350200 0.294583 1 FFHX 0.390963 0.339934 0.614410 0.251014 0.132956 2 BACC 0.143930 0.217735 0.117256 0.999636 0.566992 3 BCGH 0.499326 0.749363 0.457431 0.087111 0.385008 4 HBCH 0.944682 0.199605 0.372076 0.745106 0.278212 5 DAEE 0.491847 0.137834 0.517073 0.175743 0.289975 6 DCBA 0.747629 0.920831 0.151625 0.168380 0.153710 7 FGBB 0.964832 0.963819 0.465629 0.928988 0.448380 8 EHBF 0.727150 0.743628 0.510928 0.363017 0.856924 9 CXDB 0.448294 0.261936 0.147476 0.539172 0.736563 DF = DF . set_index( Player ) DF . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } game1 game2 game3 game4 game5 Player CGBG 0.030258 0.018657 0.932341 0.586397 0.089513 DXHD 0.759187 0.309100 0.862211 0.094455 0.169772 FDHF 0.058685 0.568902 0.405327 0.592841 0.244399 CGCE 0.130951 0.806490 0.185252 0.341298 0.262757 XHAC 0.433210 0.658711 0.680462 0.682604 0.179386 Data View DF . plot(figsize = [ 18 , 10 ]) matplotlib.axes._subplots.AxesSubplot at 0x1a19fd8860 DF[ 0 : 50 ] . plot . bar(stacked = True ,figsize = ( 20 , 15 ),fontsize = 10 ) matplotlib.axes._subplots.AxesSubplot at 0x107cd7198 DF[ 0 : 10 ] . plot . bar(stacked = False ,figsize = ( 20 , 15 ),fontsize = 10 ) matplotlib.axes._subplots.AxesSubplot at 0x1a1a0b9cf8 from pandas.plotting import scatter_matrix scatter_matrix(DF, alpha = 0.2 , figsize = ( 18 , 15 ), diagonal = kde ) plt . show() DF . plot . hexbin(x = game1 , y = game2 ,figsize = ( 12 , 10 ), gridsize = 25 ) matplotlib.axes._subplots.AxesSubplot at 0x1a242a7550 A = np . array([ 1 , 2 , 3 , 4 , 5 ]) type (A) numpy.ndarray A * 2 array([ 2, 4, 6, 8, 10])","title":"Dataframe"},{"location":"Pandas/DataFrame/dataframe/#data-view-with-titanic-dataset","text":"import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"Data View with Titanic dataset"},{"location":"Pandas/DataFrame/dataframe/#load-data","text":"titanic = pd . read_csv( data/titanic.csv ) titanic . head( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 5 6 0 3 Moran, Mr. James male NaN 0 0 330877 8.4583 NaN Q 6 7 0 1 McCarthy, Mr. Timothy J male 54.0 0 0 17463 51.8625 E46 S 7 8 0 3 Palsson, Master. Gosta Leonard male 2.0 3 1 349909 21.0750 NaN S 8 9 1 3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) female 27.0 0 2 347742 11.1333 NaN S 9 10 1 2 Nasser, Mrs. Nicholas (Adele Achem) female 14.0 1 0 237736 30.0708 NaN C titanic . shape (891, 12) titanic . columns Index([ PassengerId , Survived , Pclass , Name , Sex , Age , SibSp , Parch , Ticket , Fare , Cabin , Embarked ], dtype= object ) titanic . index RangeIndex(start=0, stop=891, step=1)","title":"Load data"},{"location":"Pandas/DataFrame/dataframe/#preliminary-satatistics","text":"titanic . describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200","title":"Preliminary Satatistics"},{"location":"Pandas/DataFrame/dataframe/#setting-name-column-as-index","text":"titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C","title":"Setting Name column as index"},{"location":"Pandas/DataFrame/dataframe/#dataframe-creation-numpy-array","text":"","title":"DataFrame Creation (Numpy Array)"},{"location":"Pandas/DataFrame/dataframe/#from-numpy-array-dataframe","text":"import random as random A = np . random . rand( 100 , 20 ) A . shape (100, 20) letter = [ A , B , C , D , E , F , G , H , X ] col_names = [ random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter)\\ + random . choice(letter) for i in range (A . shape[ 1 ])] col_names [ BHBE , FCEX , HCDC , BABH , DHCC , BEAH , CGCA , CBFF , GDBX , GDBD , GCXG , EBAF , FHFC , ADXF , XGDB , FDCB , BGGD , CXXC , GBDE , HGXX ] df = pd . DataFrame(A, columns = col_names ) df . to_csv( data/test.csv ) df . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } BHBE FCEX HCDC BABH DHCC BEAH CGCA CBFF GDBX GDBD GCXG EBAF FHFC ADXF XGDB FDCB BGGD CXXC GBDE HGXX 0 0.505613 0.863802 0.064671 0.044665 0.661631 0.010504 0.441470 0.749321 0.389375 0.468762 0.061095 0.779629 0.262696 0.834874 0.762955 0.464253 0.762709 0.425008 0.131542 0.791414 1 0.722504 0.465511 0.555621 0.843348 0.987537 0.955876 0.788946 0.461034 0.278317 0.269186 0.616559 0.095630 0.552730 0.531865 0.056233 0.796237 0.705609 0.683914 0.168146 0.312616 2 0.577487 0.355478 0.939323 0.547315 0.158492 0.226048 0.941994 0.025595 0.291006 0.549547 0.157811 0.358243 0.297590 0.767994 0.804289 0.349676 0.786392 0.806113 0.386147 0.766741 3 0.612300 0.610556 0.141520 0.657244 0.694400 0.555290 0.912868 0.350494 0.203160 0.703884 0.873016 0.420604 0.361509 0.380023 0.819483 0.988239 0.455447 0.732307 0.063254 0.123586 4 0.476368 0.890201 0.923328 0.931688 0.481882 0.411059 0.540152 0.831890 0.737365 0.681351 0.620813 0.018067 0.794526 0.491711 0.116032 0.096085 0.086113 0.813632 0.828594 0.063989","title":"From Numpy array =&gt; Dataframe"},{"location":"Pandas/DataFrame/dataframe/#data-frame-numpy-array","text":"","title":"Data Frame =&gt; Numpy Array"},{"location":"Pandas/DataFrame/dataframe/#data-frame-list-of-dictionary","text":"LD = [] for i in range ( 100 ): LD . append({ Player : random . choice(letter) + random . choice(letter) + random . choice(letter) + random . choice(letter),\\ game1 : random . uniform( 0 , 1 ),\\ game2 : random . uniform( 0 , 1 ),\\ game3 : random . uniform( 0 , 1 ), game4 : random . uniform( 0 , 1 ), game5 : random . uniform( 0 , 1 )}) DF = pd . DataFrame(LD) DF . head( 10 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Player game1 game2 game3 game4 game5 0 CGHX 0.222859 0.370064 0.966385 0.350200 0.294583 1 FFHX 0.390963 0.339934 0.614410 0.251014 0.132956 2 BACC 0.143930 0.217735 0.117256 0.999636 0.566992 3 BCGH 0.499326 0.749363 0.457431 0.087111 0.385008 4 HBCH 0.944682 0.199605 0.372076 0.745106 0.278212 5 DAEE 0.491847 0.137834 0.517073 0.175743 0.289975 6 DCBA 0.747629 0.920831 0.151625 0.168380 0.153710 7 FGBB 0.964832 0.963819 0.465629 0.928988 0.448380 8 EHBF 0.727150 0.743628 0.510928 0.363017 0.856924 9 CXDB 0.448294 0.261936 0.147476 0.539172 0.736563 DF = DF . set_index( Player ) DF . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } game1 game2 game3 game4 game5 Player CGBG 0.030258 0.018657 0.932341 0.586397 0.089513 DXHD 0.759187 0.309100 0.862211 0.094455 0.169772 FDHF 0.058685 0.568902 0.405327 0.592841 0.244399 CGCE 0.130951 0.806490 0.185252 0.341298 0.262757 XHAC 0.433210 0.658711 0.680462 0.682604 0.179386","title":"Data Frame (List of Dictionary)"},{"location":"Pandas/DataFrame/dataframe/#data-view","text":"DF . plot(figsize = [ 18 , 10 ]) matplotlib.axes._subplots.AxesSubplot at 0x1a19fd8860 DF[ 0 : 50 ] . plot . bar(stacked = True ,figsize = ( 20 , 15 ),fontsize = 10 ) matplotlib.axes._subplots.AxesSubplot at 0x107cd7198 DF[ 0 : 10 ] . plot . bar(stacked = False ,figsize = ( 20 , 15 ),fontsize = 10 ) matplotlib.axes._subplots.AxesSubplot at 0x1a1a0b9cf8 from pandas.plotting import scatter_matrix scatter_matrix(DF, alpha = 0.2 , figsize = ( 18 , 15 ), diagonal = kde ) plt . show() DF . plot . hexbin(x = game1 , y = game2 ,figsize = ( 12 , 10 ), gridsize = 25 ) matplotlib.axes._subplots.AxesSubplot at 0x1a242a7550 A = np . array([ 1 , 2 , 3 , 4 , 5 ]) type (A) numpy.ndarray A * 2 array([ 2, 4, 6, 8, 10])","title":"Data View"},{"location":"Pandas/Explor/explor/","text":"Data Exploration With Pandas import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() Load data titanic = pd . read_csv( data/titanic.csv ) Setting Name column as index titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Data Exploration: Titanic Dataset titanic_df1 . describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 plt . figure(figsize = [ 15 , 15 ]) plt . subplot( 2 , 2 , 1 ) plt . xlabel( Sex ) titanic_df1[ Sex ] . hist() plt . subplot( 2 , 2 , 2 ) plt . xlabel( Age ) titanic_df1[ Age ] . hist(bins = 50 ) plt . subplot( 2 , 2 , 3 ) plt . xlabel( Fare ) titanic_df1[ Fare ] . hist(bins = 50 ) plt . subplot( 2 , 2 , 4 ) plt . xlabel( Age ) plt . ylabel( Fare ) plt . scatter(titanic_df1[ Age ],titanic_df1[ Fare ]) plt . show() Data Exploration with Charity Dataset charitydf = pd . read_csv( data/charity.csv ) charitydf . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age workclass education_level education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country income 0 39 State-gov Bachelors 13.0 Never-married Adm-clerical Not-in-family White Male 2174.0 0.0 40.0 United-States =50K 1 50 Self-emp-not-inc Bachelors 13.0 Married-civ-spouse Exec-managerial Husband White Male 0.0 0.0 13.0 United-States =50K 2 38 Private HS-grad 9.0 Divorced Handlers-cleaners Not-in-family White Male 0.0 0.0 40.0 United-States =50K 3 53 Private 11th 7.0 Married-civ-spouse Handlers-cleaners Husband Black Male 0.0 0.0 40.0 United-States =50K 4 28 Private Bachelors 13.0 Married-civ-spouse Prof-specialty Wife Black Female 0.0 0.0 40.0 Cuba =50K charitydf . describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age education-num capital-gain capital-loss hours-per-week count 45222.000000 45222.000000 45222.000000 45222.000000 45222.000000 mean 38.547941 10.118460 1101.430344 88.595418 40.938017 std 13.217870 2.552881 7506.430084 404.956092 12.007508 min 17.000000 1.000000 0.000000 0.000000 1.000000 25% 28.000000 9.000000 0.000000 0.000000 40.000000 50% 37.000000 10.000000 0.000000 0.000000 40.000000 75% 47.000000 13.000000 0.000000 0.000000 45.000000 max 90.000000 16.000000 99999.000000 4356.000000 99.000000 charitydf . info() class pandas.core.frame.DataFrame RangeIndex: 45222 entries, 0 to 45221 Data columns (total 14 columns): age 45222 non-null int64 workclass 45222 non-null object education_level 45222 non-null object education-num 45222 non-null float64 marital-status 45222 non-null object occupation 45222 non-null object relationship 45222 non-null object race 45222 non-null object sex 45222 non-null object capital-gain 45222 non-null float64 capital-loss 45222 non-null float64 hours-per-week 45222 non-null float64 native-country 45222 non-null object income 45222 non-null object dtypes: float64(4), int64(1), object(9) memory usage: 4.8+ MB import matplotlib.pyplot as plt plt . figure(figsize = ( 14 , 10 )) plt . subplot( 2 , 3 , 1 ) plt . title( distribution of age ) charitydf[ age ] . hist(bins = 100 ) plt . subplot( 2 , 3 , 2 ) plt . title( distribution of education-num ) charitydf[ education-num ] . hist(bins = 40 ) plt . subplot( 2 , 3 , 3 ) plt . title( distribution of capital-gain ) charitydf[ capital-gain ] . hist(bins = 100 ) plt . subplot( 2 , 3 , 4 ) plt . title( distribution of hours-per-week ) charitydf[ hours-per-week ] . hist(bins = 50 ) plt . subplot( 2 , 3 , 5 ) plt . title( distribution of capital-loss ) charitydf[ capital-loss ] . hist(bins = 50 ) plt . show() matplotlib.axes._subplots.AxesSubplot at 0x7efd84af9358 plt . figure(figsize = ( 16 , 21 )) sns . set() sns . pairplot(charitydf, hue = income ) seaborn.axisgrid.PairGrid at 0x7efd84b28ba8 matplotlib.figure.Figure at 0x7efd84b197b8 sns . countplot(y = marital-status , hue = income , data = charitydf, palette = Greens_d ); plt . figure(figsize = ( 16 , 21 )) sns . set(style = whitegrid , color_codes = True ) sns . factorplot( sex , col = marital-status , data = charitydf, hue = income , kind = count , col_wrap = 2 ); matplotlib.figure.Figure at 0x7efd860fd9b0 plt . figure(figsize = ( 15 , 21 )) plt . subplot( 1 , 2 , 1 ) sns . countplot(y = age , hue = income , data = charitydf, palette = Greens_d ); plt . subplot( 1 , 2 , 2 ) sns . countplot(y = hours-per-week , hue = income , data = charitydf, palette = Greens_d ); plt . figure(figsize = ( 15 , 21 )) sns . jointplot(x = age , y = hours-per-week , data = charitydf,size = 15 ,kind = reg ); matplotlib.figure.Figure at 0x7efd7ee362b0 plt . figure(figsize = ( 10 , 10 )) sns . barplot(x = education-num , y = education_level , data = charitydf); plt . figure(figsize = ( 16 , 16 )) plt . subplot( 1 , 2 , 1 ) sns . countplot(y = education-num , hue = income , data = charitydf, palette = Greens_d ); plt . subplot( 1 , 2 , 2 ) sns . countplot(y = education_level , hue = income , data = charitydf, palette = Greens_d );","title":"Data Exploration"},{"location":"Pandas/Explor/explor/#data-exploration-with-pandas","text":"import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"Data Exploration With Pandas"},{"location":"Pandas/Explor/explor/#load-data","text":"titanic = pd . read_csv( data/titanic.csv )","title":"Load data"},{"location":"Pandas/Explor/explor/#setting-name-column-as-index","text":"titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C","title":"Setting Name column as index"},{"location":"Pandas/Explor/explor/#data-exploration-titanic-dataset","text":"titanic_df1 . describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 plt . figure(figsize = [ 15 , 15 ]) plt . subplot( 2 , 2 , 1 ) plt . xlabel( Sex ) titanic_df1[ Sex ] . hist() plt . subplot( 2 , 2 , 2 ) plt . xlabel( Age ) titanic_df1[ Age ] . hist(bins = 50 ) plt . subplot( 2 , 2 , 3 ) plt . xlabel( Fare ) titanic_df1[ Fare ] . hist(bins = 50 ) plt . subplot( 2 , 2 , 4 ) plt . xlabel( Age ) plt . ylabel( Fare ) plt . scatter(titanic_df1[ Age ],titanic_df1[ Fare ]) plt . show()","title":"Data Exploration: Titanic Dataset"},{"location":"Pandas/Explor/explor/#data-exploration-with-charity-dataset","text":"charitydf = pd . read_csv( data/charity.csv ) charitydf . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age workclass education_level education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country income 0 39 State-gov Bachelors 13.0 Never-married Adm-clerical Not-in-family White Male 2174.0 0.0 40.0 United-States =50K 1 50 Self-emp-not-inc Bachelors 13.0 Married-civ-spouse Exec-managerial Husband White Male 0.0 0.0 13.0 United-States =50K 2 38 Private HS-grad 9.0 Divorced Handlers-cleaners Not-in-family White Male 0.0 0.0 40.0 United-States =50K 3 53 Private 11th 7.0 Married-civ-spouse Handlers-cleaners Husband Black Male 0.0 0.0 40.0 United-States =50K 4 28 Private Bachelors 13.0 Married-civ-spouse Prof-specialty Wife Black Female 0.0 0.0 40.0 Cuba =50K charitydf . describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age education-num capital-gain capital-loss hours-per-week count 45222.000000 45222.000000 45222.000000 45222.000000 45222.000000 mean 38.547941 10.118460 1101.430344 88.595418 40.938017 std 13.217870 2.552881 7506.430084 404.956092 12.007508 min 17.000000 1.000000 0.000000 0.000000 1.000000 25% 28.000000 9.000000 0.000000 0.000000 40.000000 50% 37.000000 10.000000 0.000000 0.000000 40.000000 75% 47.000000 13.000000 0.000000 0.000000 45.000000 max 90.000000 16.000000 99999.000000 4356.000000 99.000000 charitydf . info() class pandas.core.frame.DataFrame RangeIndex: 45222 entries, 0 to 45221 Data columns (total 14 columns): age 45222 non-null int64 workclass 45222 non-null object education_level 45222 non-null object education-num 45222 non-null float64 marital-status 45222 non-null object occupation 45222 non-null object relationship 45222 non-null object race 45222 non-null object sex 45222 non-null object capital-gain 45222 non-null float64 capital-loss 45222 non-null float64 hours-per-week 45222 non-null float64 native-country 45222 non-null object income 45222 non-null object dtypes: float64(4), int64(1), object(9) memory usage: 4.8+ MB import matplotlib.pyplot as plt plt . figure(figsize = ( 14 , 10 )) plt . subplot( 2 , 3 , 1 ) plt . title( distribution of age ) charitydf[ age ] . hist(bins = 100 ) plt . subplot( 2 , 3 , 2 ) plt . title( distribution of education-num ) charitydf[ education-num ] . hist(bins = 40 ) plt . subplot( 2 , 3 , 3 ) plt . title( distribution of capital-gain ) charitydf[ capital-gain ] . hist(bins = 100 ) plt . subplot( 2 , 3 , 4 ) plt . title( distribution of hours-per-week ) charitydf[ hours-per-week ] . hist(bins = 50 ) plt . subplot( 2 , 3 , 5 ) plt . title( distribution of capital-loss ) charitydf[ capital-loss ] . hist(bins = 50 ) plt . show() matplotlib.axes._subplots.AxesSubplot at 0x7efd84af9358 plt . figure(figsize = ( 16 , 21 )) sns . set() sns . pairplot(charitydf, hue = income ) seaborn.axisgrid.PairGrid at 0x7efd84b28ba8 matplotlib.figure.Figure at 0x7efd84b197b8 sns . countplot(y = marital-status , hue = income , data = charitydf, palette = Greens_d ); plt . figure(figsize = ( 16 , 21 )) sns . set(style = whitegrid , color_codes = True ) sns . factorplot( sex , col = marital-status , data = charitydf, hue = income , kind = count , col_wrap = 2 ); matplotlib.figure.Figure at 0x7efd860fd9b0 plt . figure(figsize = ( 15 , 21 )) plt . subplot( 1 , 2 , 1 ) sns . countplot(y = age , hue = income , data = charitydf, palette = Greens_d ); plt . subplot( 1 , 2 , 2 ) sns . countplot(y = hours-per-week , hue = income , data = charitydf, palette = Greens_d ); plt . figure(figsize = ( 15 , 21 )) sns . jointplot(x = age , y = hours-per-week , data = charitydf,size = 15 ,kind = reg ); matplotlib.figure.Figure at 0x7efd7ee362b0 plt . figure(figsize = ( 10 , 10 )) sns . barplot(x = education-num , y = education_level , data = charitydf); plt . figure(figsize = ( 16 , 16 )) plt . subplot( 1 , 2 , 1 ) sns . countplot(y = education-num , hue = income , data = charitydf, palette = Greens_d ); plt . subplot( 1 , 2 , 2 ) sns . countplot(y = education_level , hue = income , data = charitydf, palette = Greens_d );","title":"Data Exploration with Charity Dataset"},{"location":"Pandas/GroupBy/groupby/","text":"Data Handeling: Groupby, Merge, Split import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set() Load data titanic = pd . read_csv( data/titanic.csv ) Setting Name column as index titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Group By : groupby.aggregate() , groupby.size() , groupby.mean() , The groupby operation (split-apply-combine) The \"group by\" concept: we want to apply the same function on subsets of your dataframe, based on some key to split the dataframe in subsets This operation is also referred to as the \"split-apply-combine\" operation, involving the following steps: Splitting the data into groups based on some criteria Applying a function to each group independently Combining the results into a data structure df = pd . DataFrame({ key :[ A , B , C , A , B , C , A , B , C ], data : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data 0 A 0 1 B 5 2 C 10 3 A 5 4 B 10 5 C 15 6 A 10 7 B 15 8 C 20 df . groupby( key ) . aggregate(np . sum) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data key A 15 B 30 C 45 Exercise with Titanic Dataset titanic_df1 . groupby( Sex ) . size() Sex female 314 male 577 dtype: int64 EXERCISE : Using groupby(), calculate the average age for each sex. titanic_df1 . groupby( Sex )[ Age ] . mean() Sex female 27.915709 male 30.726645 Name: Age, dtype: float64 EXERCISE : Calculate the average survival ratio for all passengers. titanic_df1[ Survived ] . sum() / len (titanic_df1[ Survived ]) 0.3838383838383838 EXERCISE : Calculate this survival ratio for all passengers younger that 25 (remember: filtering/boolean indexing). df25 = titanic_df1[titanic_df1[ Age ] = 25 ] df25[ Survived ] . sum() / len (df25[ Survived ]) 0.4119601328903654 EXERCISE : Is there a difference in this survival ratio between the sexes? (tip: write the above calculation of the survival ratio as a function) def survival_ratio (survived): return survived . sum() / len (survived) titanic_df1 . groupby( Sex )[ Survived ] . aggregate(survival_ratio) Sex female 0.742038 male 0.188908 Name: Survived, dtype: float64 EXERCISE : Make a bar plot of the survival ratio for the different classes ('Pclass' column). titanic_df1 . groupby( Pclass )[ Survived ] . aggregate(survival_ratio) . plot(kind = bar ) matplotlib.axes._subplots.AxesSubplot at 0x7fb321d163c8 Advanced Groupby Operations EXERCISE : Find data for age distribution. type ( 10 // 2 ) int df = titanic_df1 . copy(deep = True ) df . groupby(df . Age // 10 * 10 ) . size() . plot(kind = bar ,figsize = [ 10 , 10 ]) matplotlib.axes._subplots.AxesSubplot at 0x7fb31d63f2b0 EXERCISE : Find data for male age distribution. Male = df[df[ Sex ] == male ] Male . groupby(Male . Age // 10 * 10 ) . size() . plot(kind = bar ,figsize = [ 10 , 10 ]) matplotlib.axes._subplots.AxesSubplot at 0x7fb31d524dd8 EXERCISE : List data with Fare size greater then 50. Fare50 = df[df . Fare 50 ] Fare50 . groupby([ Sex ]) . size() Sex female 87 male 73 dtype: int64 Fare50 . groupby([ Age , Sex , Survived ]) . size() Age Sex Survived 0.92 male 1 1 2.00 female 0 1 4.00 male 1 1 11.00 male 1 1 14.00 female 1 1 15.00 female 1 1 16.00 female 1 2 17.00 female 1 2 male 1 1 18.00 female 1 3 male 0 2 19.00 female 1 1 male 0 2 21.00 female 1 2 male 0 3 22.00 female 1 3 male 0 1 23.00 female 1 2 male 1 1 24.00 female 1 5 male 0 3 25.00 female 0 1 male 1 2 26.00 female 1 1 male 1 1 27.00 male 0 1 1 2 28.00 male 0 2 29.00 female 1 1 male 0 1 .. 45.00 female 1 1 male 0 1 46.00 male 0 2 47.00 female 1 1 male 0 1 48.00 female 1 1 male 1 2 49.00 female 1 1 male 0 1 1 2 50.00 female 1 1 male 0 2 1 1 51.00 female 1 1 male 0 1 52.00 female 1 2 male 0 1 53.00 female 1 1 54.00 female 1 2 male 0 2 56.00 female 1 1 58.00 female 1 2 male 0 1 60.00 female 1 1 male 1 1 62.00 female 1 1 63.00 female 1 1 64.00 male 0 1 65.00 male 0 1 70.00 male 0 1 Length: 87, dtype: int64 Group by followed by Transformation: groupby.transform() df = pd . DataFrame({ key :[ A , B , C , A , B , C , A , B , C ], data : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data key 0 0 A 1 5 B 2 10 C 3 5 A 4 10 B 5 15 C 6 10 A 7 15 B 8 20 C df . groupby( key ) . transform( mean ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 5 1 10 2 15 3 5 4 10 5 15 6 5 7 10 8 15 def normalize (group): return (group - group . mean()) / group . std() df . groupby( key ) . transform(normalize) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 -1.0 1 -1.0 2 -1.0 3 0.0 4 0.0 5 0.0 6 1.0 7 1.0 8 1.0 df . groupby( key ) . transform( sum ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 15 1 30 2 45 3 15 4 30 5 45 6 15 7 30 8 45","title":"GroupBy"},{"location":"Pandas/GroupBy/groupby/#data-handeling-groupby-merge-split","text":"import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline sns . set()","title":"Data Handeling: Groupby, Merge, Split"},{"location":"Pandas/GroupBy/groupby/#load-data","text":"titanic = pd . read_csv( data/titanic.csv )","title":"Load data"},{"location":"Pandas/GroupBy/groupby/#setting-name-column-as-index","text":"titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C","title":"Setting Name column as index"},{"location":"Pandas/GroupBy/groupby/#group-by-groupbyaggregate-groupbysizegroupbymean","text":"","title":"Group By : groupby.aggregate(), groupby.size(),groupby.mean(),"},{"location":"Pandas/GroupBy/groupby/#the-groupby-operation-split-apply-combine","text":"The \"group by\" concept: we want to apply the same function on subsets of your dataframe, based on some key to split the dataframe in subsets This operation is also referred to as the \"split-apply-combine\" operation, involving the following steps: Splitting the data into groups based on some criteria Applying a function to each group independently Combining the results into a data structure df = pd . DataFrame({ key :[ A , B , C , A , B , C , A , B , C ], data : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data 0 A 0 1 B 5 2 C 10 3 A 5 4 B 10 5 C 15 6 A 10 7 B 15 8 C 20 df . groupby( key ) . aggregate(np . sum) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data key A 15 B 30 C 45","title":"The groupby operation (split-apply-combine)"},{"location":"Pandas/GroupBy/groupby/#exercise-with-titanic-dataset","text":"titanic_df1 . groupby( Sex ) . size() Sex female 314 male 577 dtype: int64 EXERCISE : Using groupby(), calculate the average age for each sex. titanic_df1 . groupby( Sex )[ Age ] . mean() Sex female 27.915709 male 30.726645 Name: Age, dtype: float64 EXERCISE : Calculate the average survival ratio for all passengers. titanic_df1[ Survived ] . sum() / len (titanic_df1[ Survived ]) 0.3838383838383838 EXERCISE : Calculate this survival ratio for all passengers younger that 25 (remember: filtering/boolean indexing). df25 = titanic_df1[titanic_df1[ Age ] = 25 ] df25[ Survived ] . sum() / len (df25[ Survived ]) 0.4119601328903654 EXERCISE : Is there a difference in this survival ratio between the sexes? (tip: write the above calculation of the survival ratio as a function) def survival_ratio (survived): return survived . sum() / len (survived) titanic_df1 . groupby( Sex )[ Survived ] . aggregate(survival_ratio) Sex female 0.742038 male 0.188908 Name: Survived, dtype: float64 EXERCISE : Make a bar plot of the survival ratio for the different classes ('Pclass' column). titanic_df1 . groupby( Pclass )[ Survived ] . aggregate(survival_ratio) . plot(kind = bar ) matplotlib.axes._subplots.AxesSubplot at 0x7fb321d163c8","title":"Exercise with Titanic Dataset"},{"location":"Pandas/GroupBy/groupby/#advanced-groupby-operations","text":"EXERCISE : Find data for age distribution. type ( 10 // 2 ) int df = titanic_df1 . copy(deep = True ) df . groupby(df . Age // 10 * 10 ) . size() . plot(kind = bar ,figsize = [ 10 , 10 ]) matplotlib.axes._subplots.AxesSubplot at 0x7fb31d63f2b0 EXERCISE : Find data for male age distribution. Male = df[df[ Sex ] == male ] Male . groupby(Male . Age // 10 * 10 ) . size() . plot(kind = bar ,figsize = [ 10 , 10 ]) matplotlib.axes._subplots.AxesSubplot at 0x7fb31d524dd8 EXERCISE : List data with Fare size greater then 50. Fare50 = df[df . Fare 50 ] Fare50 . groupby([ Sex ]) . size() Sex female 87 male 73 dtype: int64 Fare50 . groupby([ Age , Sex , Survived ]) . size() Age Sex Survived 0.92 male 1 1 2.00 female 0 1 4.00 male 1 1 11.00 male 1 1 14.00 female 1 1 15.00 female 1 1 16.00 female 1 2 17.00 female 1 2 male 1 1 18.00 female 1 3 male 0 2 19.00 female 1 1 male 0 2 21.00 female 1 2 male 0 3 22.00 female 1 3 male 0 1 23.00 female 1 2 male 1 1 24.00 female 1 5 male 0 3 25.00 female 0 1 male 1 2 26.00 female 1 1 male 1 1 27.00 male 0 1 1 2 28.00 male 0 2 29.00 female 1 1 male 0 1 .. 45.00 female 1 1 male 0 1 46.00 male 0 2 47.00 female 1 1 male 0 1 48.00 female 1 1 male 1 2 49.00 female 1 1 male 0 1 1 2 50.00 female 1 1 male 0 2 1 1 51.00 female 1 1 male 0 1 52.00 female 1 2 male 0 1 53.00 female 1 1 54.00 female 1 2 male 0 2 56.00 female 1 1 58.00 female 1 2 male 0 1 60.00 female 1 1 male 1 1 62.00 female 1 1 63.00 female 1 1 64.00 male 0 1 65.00 male 0 1 70.00 male 0 1 Length: 87, dtype: int64","title":"Advanced Groupby Operations"},{"location":"Pandas/GroupBy/groupby/#group-by-followed-by-transformation-groupbytransform","text":"df = pd . DataFrame({ key :[ A , B , C , A , B , C , A , B , C ], data : [ 0 , 5 , 10 , 5 , 10 , 15 , 10 , 15 , 20 ]}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data key 0 0 A 1 5 B 2 10 C 3 5 A 4 10 B 5 15 C 6 10 A 7 15 B 8 20 C df . groupby( key ) . transform( mean ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 5 1 10 2 15 3 5 4 10 5 15 6 5 7 10 8 15 def normalize (group): return (group - group . mean()) / group . std() df . groupby( key ) . transform(normalize) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 -1.0 1 -1.0 2 -1.0 3 0.0 4 0.0 5 0.0 6 1.0 7 1.0 8 1.0 df . groupby( key ) . transform( sum ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data 0 15 1 30 2 45 3 15 4 30 5 45 6 15 7 30 8 45","title":"Group by followed by Transformation: groupby.transform()"},{"location":"Pandas/Indexing/Indexing/","text":"Data Iteration and Indexing import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline titanic = pd . read_csv( data/titanic.csv ) titanic . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S Setting Name column as index titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Heikkinen, Miss. Laina 3 1 3 female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35.0 1 0 113803 53.1000 C123 S Allen, Mr. William Henry 5 0 3 male 35.0 0 0 373450 8.0500 NaN S Data Frame item iteration sample = titanic_df1[ 0 : 5 ] iterrows for index,row in sample . iterrows(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, male , 22.0, 1, 0, A/5 21171 , 7.25, nan, S ] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, female , 38.0, 1, 0, PC 17599 , 71.2833, C85 , C ] Heikkinen, Miss. Laina [3, 1, 3, female , 26.0, 0, 0, STON/O2. 3101282 , 7.925, nan, S ] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, female , 35.0, 1, 0, 113803 , 53.1, C123 , S ] Allen, Mr. William Henry [5, 0, 3, male , 35.0, 0, 0, 373450 , 8.05, nan, S ] for index,row in sample . iterrows(): print (index,row[ Sex ],row[ Age ]) Braund, Mr. Owen Harris male 22.0 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0 Heikkinen, Miss. Laina female 26.0 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 Allen, Mr. William Henry male 35.0 iteritems for index,row in sample . T . iteritems(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, male , 22.0, 1, 0, A/5 21171 , 7.25, nan, S ] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, female , 38.0, 1, 0, PC 17599 , 71.2833, C85 , C ] Heikkinen, Miss. Laina [3, 1, 3, female , 26.0, 0, 0, STON/O2. 3101282 , 7.925, nan, S ] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, female , 35.0, 1, 0, 113803 , 53.1, C123 , S ] Allen, Mr. William Henry [5, 0, 3, male , 35.0, 0, 0, 373450 , 8.05, nan, S ] for index,row in sample . iteritems(): print (index,row[ 0 ],row[ 1 ],row[ 2 ]) PassengerId 1 2 3 Survived 0 1 1 Pclass 3 1 3 Sex male female female Age 22.0 38.0 26.0 SibSp 1 1 0 Parch 0 0 0 Ticket A/5 21171 PC 17599 STON/O2. 3101282 Fare 7.25 71.2833 7.925 Cabin nan C85 nan Embarked S C S Indexing Data Source: Using iloc, loc, ix to select rows and columns in Pandas DataFrames loc and iloc : The iloc indexer for Pandas Dataframe is used for integer-location based indexing / selection by position. The Pandas loc indexer can be used with DataFrames for two different use cases: a.) Selecting rows by label/index b.) Selecting rows with a boolean / conditional lookup sample . iloc[ 0 : 2 ,:] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C sample . iloc[ 1 , 0 : 3 ] PassengerId 2 Survived 1 Pclass 1 Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer), dtype: object sample . loc[:, Survived : Ticket ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Ticket Name Braund, Mr. Owen Harris 0 3 male 22.0 1 0 A/5 21171 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 1 1 female 38.0 1 0 PC 17599 Heikkinen, Miss. Laina 1 3 female 26.0 0 0 STON/O2. 3101282 Futrelle, Mrs. Jacques Heath (Lily May Peel) 1 1 female 35.0 1 0 113803 Allen, Mr. William Henry 0 3 male 35.0 0 0 373450 sample . loc[ Braund, Mr. Owen Harris ,:] PassengerId 1 Survived 0 Pclass 3 Sex male Age 22 SibSp 1 Parch 0 Ticket A/5 21171 Fare 7.25 Cabin NaN Embarked S Name: Braund, Mr. Owen Harris, dtype: object Data Filters Dictionary to DataFrame data = { country : [ Belgium , France , Germany , Netherlands , United Kingdom ], population : [ 11.3 , 64.3 , 81.3 , 16.9 , 64.9 ], area : [ 30510 , 671308 , 357050 , 41526 , 244820 ], capital : [ Brussels , Paris , Berlin , Amsterdam , London ]} countries = pd . DataFrame(data) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } country population area capital 0 Belgium 11.3 30510 Brussels 1 France 64.3 671308 Paris 2 Germany 81.3 357050 Berlin 3 Netherlands 16.9 41526 Amsterdam 4 United Kingdom 64.9 244820 London countries = countries . set_index( country ) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country Belgium 11.3 30510 Brussels France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam United Kingdom 64.9 244820 London countries[ area ] country Belgium 30510 France 671308 Germany 357050 Netherlands 41526 United Kingdom 244820 Name: area, dtype: int64 countries[[ area , population ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country Belgium 30510 11.3 France 671308 64.3 Germany 357050 81.3 Netherlands 41526 16.9 United Kingdom 244820 64.9 countries[ France : Netherlands ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam countries . loc[ Germany , area ] 357050 countries . loc[ France : Germany , [ area , population ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country France 671308 64.3 Germany 357050 81.3 countries . iloc[ 0 : 2 , 1 : 3 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area capital country Belgium 30510 Brussels France 671308 Paris countries2 = countries . copy() countries2 . loc[ Belgium : Germany , population ] = 10 countries2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country Belgium 10.0 30510 Brussels France 10.0 671308 Paris Germany 10.0 357050 Berlin Netherlands 16.9 41526 Amsterdam United Kingdom 64.9 244820 London countries[ area ] 100000 country Belgium False France True Germany True Netherlands False United Kingdom True Name: area, dtype: bool countries[countries[ area ] 100000 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin United Kingdom 64.9 244820 London EXERCISE : Add a column `density` with the population density (note: population column is expressed in millions) countries[ density ] = countries[ population ] * 1000000 / countries[ area ] countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density country Belgium 11.3 30510 Brussels 370.370370 France 64.3 671308 Paris 95.783158 Germany 81.3 357050 Berlin 227.699202 Netherlands 16.9 41526 Amsterdam 406.973944 United Kingdom 64.9 244820 London 265.092721 EXERCISE : Select the capital and the population column of those countries where the density is larger than 300 countries . loc[countries[ density ] 300 , [ capital , population ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } capital population country Belgium Brussels 11.3 Netherlands Amsterdam 16.9 EXERCISE : Add a column 'density_ratio' with the ratio of the density to the mean density countries[ density_ratio ] = countries[ density ] / countries[ density ] . mean() countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 London 265.092721 0.970382 EXERCISE : Change the capital of the UK to Cambridge countries . loc[ United Kingdom , capital ] = Cambridge countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382 EXERCISE : Select all countries whose population density is between 100 and 300 people/km\u00b2 countries[(countries[ density ] 100 ) (countries[ density ] 300 )] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Germany 81.3 357050 Berlin 227.699202 0.833502 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382","title":"Indexing"},{"location":"Pandas/Indexing/Indexing/#data-iteration-and-indexing","text":"import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline titanic = pd . read_csv( data/titanic.csv ) titanic . head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S","title":"Data Iteration and Indexing"},{"location":"Pandas/Indexing/Indexing/#setting-name-column-as-index","text":"titanic_df1 = titanic . copy(deep = True ) titanic_df1 = titanic . set_index( Name ) titanic_df1 . head( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Heikkinen, Miss. Laina 3 1 3 female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S Futrelle, Mrs. Jacques Heath (Lily May Peel) 4 1 1 female 35.0 1 0 113803 53.1000 C123 S Allen, Mr. William Henry 5 0 3 male 35.0 0 0 373450 8.0500 NaN S","title":"Setting Name column as index"},{"location":"Pandas/Indexing/Indexing/#data-frame-item-iteration","text":"sample = titanic_df1[ 0 : 5 ]","title":"Data Frame item iteration"},{"location":"Pandas/Indexing/Indexing/#iterrows","text":"for index,row in sample . iterrows(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, male , 22.0, 1, 0, A/5 21171 , 7.25, nan, S ] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, female , 38.0, 1, 0, PC 17599 , 71.2833, C85 , C ] Heikkinen, Miss. Laina [3, 1, 3, female , 26.0, 0, 0, STON/O2. 3101282 , 7.925, nan, S ] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, female , 35.0, 1, 0, 113803 , 53.1, C123 , S ] Allen, Mr. William Henry [5, 0, 3, male , 35.0, 0, 0, 373450 , 8.05, nan, S ] for index,row in sample . iterrows(): print (index,row[ Sex ],row[ Age ]) Braund, Mr. Owen Harris male 22.0 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0 Heikkinen, Miss. Laina female 26.0 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 Allen, Mr. William Henry male 35.0","title":"iterrows"},{"location":"Pandas/Indexing/Indexing/#iteritems","text":"for index,row in sample . T . iteritems(): print (index, list (row)) Braund, Mr. Owen Harris [1, 0, 3, male , 22.0, 1, 0, A/5 21171 , 7.25, nan, S ] Cumings, Mrs. John Bradley (Florence Briggs Thayer) [2, 1, 1, female , 38.0, 1, 0, PC 17599 , 71.2833, C85 , C ] Heikkinen, Miss. Laina [3, 1, 3, female , 26.0, 0, 0, STON/O2. 3101282 , 7.925, nan, S ] Futrelle, Mrs. Jacques Heath (Lily May Peel) [4, 1, 1, female , 35.0, 1, 0, 113803 , 53.1, C123 , S ] Allen, Mr. William Henry [5, 0, 3, male , 35.0, 0, 0, 373450 , 8.05, nan, S ] for index,row in sample . iteritems(): print (index,row[ 0 ],row[ 1 ],row[ 2 ]) PassengerId 1 2 3 Survived 0 1 1 Pclass 3 1 3 Sex male female female Age 22.0 38.0 26.0 SibSp 1 1 0 Parch 0 0 0 Ticket A/5 21171 PC 17599 STON/O2. 3101282 Fare 7.25 71.2833 7.925 Cabin nan C85 nan Embarked S C S","title":"iteritems"},{"location":"Pandas/Indexing/Indexing/#indexing-data","text":"Source: Using iloc, loc, ix to select rows and columns in Pandas DataFrames","title":"Indexing Data"},{"location":"Pandas/Indexing/Indexing/#loc-and-iloc","text":"The iloc indexer for Pandas Dataframe is used for integer-location based indexing / selection by position. The Pandas loc indexer can be used with DataFrames for two different use cases: a.) Selecting rows by label/index b.) Selecting rows with a boolean / conditional lookup sample . iloc[ 0 : 2 ,:] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C sample . iloc[ 1 , 0 : 3 ] PassengerId 2 Survived 1 Pclass 1 Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer), dtype: object sample . loc[:, Survived : Ticket ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Ticket Name Braund, Mr. Owen Harris 0 3 male 22.0 1 0 A/5 21171 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 1 1 female 38.0 1 0 PC 17599 Heikkinen, Miss. Laina 1 3 female 26.0 0 0 STON/O2. 3101282 Futrelle, Mrs. Jacques Heath (Lily May Peel) 1 1 female 35.0 1 0 113803 Allen, Mr. William Henry 0 3 male 35.0 0 0 373450 sample . loc[ Braund, Mr. Owen Harris ,:] PassengerId 1 Survived 0 Pclass 3 Sex male Age 22 SibSp 1 Parch 0 Ticket A/5 21171 Fare 7.25 Cabin NaN Embarked S Name: Braund, Mr. Owen Harris, dtype: object","title":"loc and iloc :"},{"location":"Pandas/Indexing/Indexing/#data-filters","text":"","title":"Data Filters"},{"location":"Pandas/Indexing/Indexing/#dictionary-to-dataframe","text":"data = { country : [ Belgium , France , Germany , Netherlands , United Kingdom ], population : [ 11.3 , 64.3 , 81.3 , 16.9 , 64.9 ], area : [ 30510 , 671308 , 357050 , 41526 , 244820 ], capital : [ Brussels , Paris , Berlin , Amsterdam , London ]} countries = pd . DataFrame(data) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } country population area capital 0 Belgium 11.3 30510 Brussels 1 France 64.3 671308 Paris 2 Germany 81.3 357050 Berlin 3 Netherlands 16.9 41526 Amsterdam 4 United Kingdom 64.9 244820 London countries = countries . set_index( country ) countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country Belgium 11.3 30510 Brussels France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam United Kingdom 64.9 244820 London countries[ area ] country Belgium 30510 France 671308 Germany 357050 Netherlands 41526 United Kingdom 244820 Name: area, dtype: int64 countries[[ area , population ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country Belgium 30510 11.3 France 671308 64.3 Germany 357050 81.3 Netherlands 41526 16.9 United Kingdom 244820 64.9 countries[ France : Netherlands ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin Netherlands 16.9 41526 Amsterdam countries . loc[ Germany , area ] 357050 countries . loc[ France : Germany , [ area , population ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area population country France 671308 64.3 Germany 357050 81.3 countries . iloc[ 0 : 2 , 1 : 3 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } area capital country Belgium 30510 Brussels France 671308 Paris countries2 = countries . copy() countries2 . loc[ Belgium : Germany , population ] = 10 countries2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country Belgium 10.0 30510 Brussels France 10.0 671308 Paris Germany 10.0 357050 Berlin Netherlands 16.9 41526 Amsterdam United Kingdom 64.9 244820 London countries[ area ] 100000 country Belgium False France True Germany True Netherlands False United Kingdom True Name: area, dtype: bool countries[countries[ area ] 100000 ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital country France 64.3 671308 Paris Germany 81.3 357050 Berlin United Kingdom 64.9 244820 London EXERCISE : Add a column `density` with the population density (note: population column is expressed in millions) countries[ density ] = countries[ population ] * 1000000 / countries[ area ] countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density country Belgium 11.3 30510 Brussels 370.370370 France 64.3 671308 Paris 95.783158 Germany 81.3 357050 Berlin 227.699202 Netherlands 16.9 41526 Amsterdam 406.973944 United Kingdom 64.9 244820 London 265.092721 EXERCISE : Select the capital and the population column of those countries where the density is larger than 300 countries . loc[countries[ density ] 300 , [ capital , population ]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } capital population country Belgium Brussels 11.3 Netherlands Amsterdam 16.9 EXERCISE : Add a column 'density_ratio' with the ratio of the density to the mean density countries[ density_ratio ] = countries[ density ] / countries[ density ] . mean() countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 London 265.092721 0.970382 EXERCISE : Change the capital of the UK to Cambridge countries . loc[ United Kingdom , capital ] = Cambridge countries .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Belgium 11.3 30510 Brussels 370.370370 1.355755 France 64.3 671308 Paris 95.783158 0.350618 Germany 81.3 357050 Berlin 227.699202 0.833502 Netherlands 16.9 41526 Amsterdam 406.973944 1.489744 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382 EXERCISE : Select all countries whose population density is between 100 and 300 people/km\u00b2 countries[(countries[ density ] 100 ) (countries[ density ] 300 )] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } population area capital density density_ratio country Germany 81.3 357050 Berlin 227.699202 0.833502 United Kingdom 64.9 244820 Cambridge 265.092721 0.970382","title":"Dictionary to DataFrame"},{"location":"Pandas/Lambda/lambda/","text":"Lambda Transformation import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline Load data titanic = pd . read_csv( data/titanic.csv ) Setting Name column as index df1 = titanic . copy(deep = True ) df1 = titanic . set_index( Name ) df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C Lambda Transformation df1[ Fare ] . apply( lambda x: ( 10 * x ** 2 + 2 * x + 4 ) / 10 ) Name Braund, Mr. Owen Harris 0.72500 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 7.12833 Heikkinen, Miss. Laina 0.79250 Futrelle, Mrs. Jacques Heath (Lily May Peel) 5.31000 Allen, Mr. William Henry 0.80500 Moran, Mr. James 0.84583 McCarthy, Mr. Timothy J 5.18625 Palsson, Master. Gosta Leonard 2.10750 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) 1.11333 Nasser, Mrs. Nicholas (Adele Achem) 3.00708 Sandstrom, Miss. Marguerite Rut 1.67000 Bonnell, Miss. Elizabeth 2.65500 Saundercock, Mr. William Henry 0.80500 Andersson, Mr. Anders Johan 3.12750 Vestrom, Miss. Hulda Amanda Adolfina 0.78542 Hewlett, Mrs. (Mary D Kingcome) 1.60000 Rice, Master. Eugene 2.91250 Williams, Mr. Charles Eugene 1.30000 Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele) 1.80000 Masselmani, Mrs. Fatima 0.72250 Fynney, Mr. Joseph J 2.60000 Beesley, Mr. Lawrence 1.30000 McGowan, Miss. Anna Annie 0.80292 Sloper, Mr. William Thompson 3.55000 Palsson, Miss. Torborg Danira 2.10750 Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson) 3.13875 Emir, Mr. Farred Chehab 0.72250 Fortune, Mr. Charles Alexander 26.30000 O Dwyer, Miss. Ellen Nellie 0.78792 Todoroff, Mr. Lalio 0.78958 ... Giles, Mr. Frederick Edward 1.15000 Swift, Mrs. Frederick Joel (Margaret Welles Barron) 2.59292 Sage, Miss. Dorothy Edith Dolly 6.95500 Gill, Mr. John William 1.30000 Bystrom, Mrs. (Karolina) 1.30000 Duran y More, Miss. Asuncion 1.38583 Roebling, Mr. Washington Augustus II 5.04958 van Melkebeke, Mr. Philemon 0.95000 Johnson, Master. Harold Theodor 1.11333 Balkic, Mr. Cerin 0.78958 Beckwith, Mrs. Richard Leonard (Sallie Monypeny) 5.25542 Carlsson, Mr. Frans Olof 0.50000 Vander Cruyssen, Mr. Victor 0.90000 Abelson, Mrs. Samuel (Hannah Wizosky) 2.40000 Najib, Miss. Adele Kiamie Jane 0.72250 Gustafsson, Mr. Alfred Ossian 0.98458 Petroff, Mr. Nedelio 0.78958 Laleff, Mr. Kristo 0.78958 Potter, Mrs. Thomas Jr (Lily Alexenia Wilson) 8.31583 Shelley, Mrs. William (Imanita Parrish Hall) 2.60000 Markun, Mr. Johann 0.78958 Dahlberg, Miss. Gerda Ulrika 1.05167 Banfield, Mr. Frederick James 1.05000 Sutehall, Mr. Henry Jr 0.70500 Rice, Mrs. William (Margaret Norton) 2.91250 Montvila, Rev. Juozas 1.30000 Graham, Miss. Margaret Edith 3.00000 Johnston, Miss. Catherine Helen Carrie 2.34500 Behr, Mr. Karl Howell 3.00000 Dooley, Mr. Patrick 0.77500 Name: Fare, Length: 891, dtype: float64 def newfeature (x): return 10 + x / 3 + x ** 2 df1[ Fare ] . apply(newfeature) Name Braund, Mr. Owen Harris 64.979167 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 5115.069959 Heikkinen, Miss. Laina 75.447292 Futrelle, Mrs. Jacques Heath (Lily May Peel) 2847.310000 Allen, Mr. William Henry 77.485833 Moran, Mr. James 84.362272 McCarthy, Mr. Timothy J 2717.006406 Palsson, Master. Gosta Leonard 461.180625 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) 137.661469 Nasser, Mrs. Nicholas (Adele Achem) 924.276613 Sandstrom, Miss. Marguerite Rut 294.456667 Bonnell, Miss. Elizabeth 723.752500 Saundercock, Mr. William Henry 77.485833 Andersson, Mr. Anders Johan 998.550625 Vestrom, Miss. Hulda Amanda Adolfina 74.306524 Hewlett, Mrs. (Mary D Kingcome) 271.333333 Rice, Master. Eugene 867.973958 Williams, Mr. Charles Eugene 183.333333 Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele) 340.000000 Masselmani, Mrs. Fatima 64.608958 Fynney, Mr. Joseph J 694.666667 Beesley, Mr. Lawrence 183.333333 McGowan, Miss. Anna Annie 77.144453 Sloper, Mr. William Thompson 1282.083333 Palsson, Miss. Torborg Danira 461.180625 Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson) 1005.637656 Emir, Mr. Farred Chehab 64.608958 Fortune, Mr. Charles Alexander 69266.666667 O Dwyer, Miss. Ellen Nellie 74.708193 Todoroff, Mr. Lalio 74.975591 ... Giles, Mr. Frederick Edward 146.083333 Swift, Mrs. Frederick Joel (Margaret Welles Barron) 690.966479 Sage, Miss. Dorothy Edith Dolly 4870.385833 Gill, Mr. John William 183.333333 Bystrom, Mrs. (Karolina) 183.333333 Duran y More, Miss. Asuncion 206.671912 Roebling, Mr. Washington Augustus II 2576.657751 van Melkebeke, Mr. Philemon 103.416667 Johnson, Master. Harold Theodor 137.661469 Balkic, Mr. Cerin 74.975591 Beckwith, Mrs. Richard Leonard (Sallie Monypeny) 2789.462004 Carlsson, Mr. Frans Olof 36.666667 Vander Cruyssen, Mr. Victor 94.000000 Abelson, Mrs. Samuel (Hannah Wizosky) 594.000000 Najib, Miss. Adele Kiamie Jane 64.608958 Gustafsson, Mr. Alfred Ossian 110.221711 Petroff, Mr. Nedelio 74.975591 Laleff, Mr. Kristo 74.975591 Potter, Mrs. Thomas Jr (Lily Alexenia Wilson) 6953.022292 Shelley, Mrs. William (Imanita Parrish Hall) 694.666667 Markun, Mr. Johann 74.975591 Dahlberg, Miss. Gerda Ulrika 124.106546 Banfield, Mr. Frederick James 123.750000 Sutehall, Mr. Henry Jr 62.052500 Rice, Mrs. William (Margaret Norton) 867.973958 Montvila, Rev. Juozas 183.333333 Graham, Miss. Margaret Edith 920.000000 Johnston, Miss. Catherine Helen Carrie 567.719167 Behr, Mr. Karl Howell 920.000000 Dooley, Mr. Patrick 72.645833 Name: Fare, Length: 891, dtype: float64","title":"Lambda Transform"},{"location":"Pandas/Lambda/lambda/#lambda-transformation","text":"import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt % matplotlib inline","title":"Lambda Transformation"},{"location":"Pandas/Lambda/lambda/#load-data","text":"titanic = pd . read_csv( data/titanic.csv )","title":"Load data"},{"location":"Pandas/Lambda/lambda/#setting-name-column-as-index","text":"df1 = titanic . copy(deep = True ) df1 = titanic . set_index( Name ) df1 . head( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Sex Age SibSp Parch Ticket Fare Cabin Embarked Name Braund, Mr. Owen Harris 1 0 3 male 22.0 1 0 A/5 21171 7.2500 NaN S Cumings, Mrs. John Bradley (Florence Briggs Thayer) 2 1 1 female 38.0 1 0 PC 17599 71.2833 C85 C","title":"Setting Name column as index"},{"location":"Pandas/Lambda/lambda/#lambda-transformation_1","text":"df1[ Fare ] . apply( lambda x: ( 10 * x ** 2 + 2 * x + 4 ) / 10 ) Name Braund, Mr. Owen Harris 0.72500 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 7.12833 Heikkinen, Miss. Laina 0.79250 Futrelle, Mrs. Jacques Heath (Lily May Peel) 5.31000 Allen, Mr. William Henry 0.80500 Moran, Mr. James 0.84583 McCarthy, Mr. Timothy J 5.18625 Palsson, Master. Gosta Leonard 2.10750 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) 1.11333 Nasser, Mrs. Nicholas (Adele Achem) 3.00708 Sandstrom, Miss. Marguerite Rut 1.67000 Bonnell, Miss. Elizabeth 2.65500 Saundercock, Mr. William Henry 0.80500 Andersson, Mr. Anders Johan 3.12750 Vestrom, Miss. Hulda Amanda Adolfina 0.78542 Hewlett, Mrs. (Mary D Kingcome) 1.60000 Rice, Master. Eugene 2.91250 Williams, Mr. Charles Eugene 1.30000 Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele) 1.80000 Masselmani, Mrs. Fatima 0.72250 Fynney, Mr. Joseph J 2.60000 Beesley, Mr. Lawrence 1.30000 McGowan, Miss. Anna Annie 0.80292 Sloper, Mr. William Thompson 3.55000 Palsson, Miss. Torborg Danira 2.10750 Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson) 3.13875 Emir, Mr. Farred Chehab 0.72250 Fortune, Mr. Charles Alexander 26.30000 O Dwyer, Miss. Ellen Nellie 0.78792 Todoroff, Mr. Lalio 0.78958 ... Giles, Mr. Frederick Edward 1.15000 Swift, Mrs. Frederick Joel (Margaret Welles Barron) 2.59292 Sage, Miss. Dorothy Edith Dolly 6.95500 Gill, Mr. John William 1.30000 Bystrom, Mrs. (Karolina) 1.30000 Duran y More, Miss. Asuncion 1.38583 Roebling, Mr. Washington Augustus II 5.04958 van Melkebeke, Mr. Philemon 0.95000 Johnson, Master. Harold Theodor 1.11333 Balkic, Mr. Cerin 0.78958 Beckwith, Mrs. Richard Leonard (Sallie Monypeny) 5.25542 Carlsson, Mr. Frans Olof 0.50000 Vander Cruyssen, Mr. Victor 0.90000 Abelson, Mrs. Samuel (Hannah Wizosky) 2.40000 Najib, Miss. Adele Kiamie Jane 0.72250 Gustafsson, Mr. Alfred Ossian 0.98458 Petroff, Mr. Nedelio 0.78958 Laleff, Mr. Kristo 0.78958 Potter, Mrs. Thomas Jr (Lily Alexenia Wilson) 8.31583 Shelley, Mrs. William (Imanita Parrish Hall) 2.60000 Markun, Mr. Johann 0.78958 Dahlberg, Miss. Gerda Ulrika 1.05167 Banfield, Mr. Frederick James 1.05000 Sutehall, Mr. Henry Jr 0.70500 Rice, Mrs. William (Margaret Norton) 2.91250 Montvila, Rev. Juozas 1.30000 Graham, Miss. Margaret Edith 3.00000 Johnston, Miss. Catherine Helen Carrie 2.34500 Behr, Mr. Karl Howell 3.00000 Dooley, Mr. Patrick 0.77500 Name: Fare, Length: 891, dtype: float64 def newfeature (x): return 10 + x / 3 + x ** 2 df1[ Fare ] . apply(newfeature) Name Braund, Mr. Owen Harris 64.979167 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 5115.069959 Heikkinen, Miss. Laina 75.447292 Futrelle, Mrs. Jacques Heath (Lily May Peel) 2847.310000 Allen, Mr. William Henry 77.485833 Moran, Mr. James 84.362272 McCarthy, Mr. Timothy J 2717.006406 Palsson, Master. Gosta Leonard 461.180625 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) 137.661469 Nasser, Mrs. Nicholas (Adele Achem) 924.276613 Sandstrom, Miss. Marguerite Rut 294.456667 Bonnell, Miss. Elizabeth 723.752500 Saundercock, Mr. William Henry 77.485833 Andersson, Mr. Anders Johan 998.550625 Vestrom, Miss. Hulda Amanda Adolfina 74.306524 Hewlett, Mrs. (Mary D Kingcome) 271.333333 Rice, Master. Eugene 867.973958 Williams, Mr. Charles Eugene 183.333333 Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele) 340.000000 Masselmani, Mrs. Fatima 64.608958 Fynney, Mr. Joseph J 694.666667 Beesley, Mr. Lawrence 183.333333 McGowan, Miss. Anna Annie 77.144453 Sloper, Mr. William Thompson 1282.083333 Palsson, Miss. Torborg Danira 461.180625 Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson) 1005.637656 Emir, Mr. Farred Chehab 64.608958 Fortune, Mr. Charles Alexander 69266.666667 O Dwyer, Miss. Ellen Nellie 74.708193 Todoroff, Mr. Lalio 74.975591 ... Giles, Mr. Frederick Edward 146.083333 Swift, Mrs. Frederick Joel (Margaret Welles Barron) 690.966479 Sage, Miss. Dorothy Edith Dolly 4870.385833 Gill, Mr. John William 183.333333 Bystrom, Mrs. (Karolina) 183.333333 Duran y More, Miss. Asuncion 206.671912 Roebling, Mr. Washington Augustus II 2576.657751 van Melkebeke, Mr. Philemon 103.416667 Johnson, Master. Harold Theodor 137.661469 Balkic, Mr. Cerin 74.975591 Beckwith, Mrs. Richard Leonard (Sallie Monypeny) 2789.462004 Carlsson, Mr. Frans Olof 36.666667 Vander Cruyssen, Mr. Victor 94.000000 Abelson, Mrs. Samuel (Hannah Wizosky) 594.000000 Najib, Miss. Adele Kiamie Jane 64.608958 Gustafsson, Mr. Alfred Ossian 110.221711 Petroff, Mr. Nedelio 74.975591 Laleff, Mr. Kristo 74.975591 Potter, Mrs. Thomas Jr (Lily Alexenia Wilson) 6953.022292 Shelley, Mrs. William (Imanita Parrish Hall) 694.666667 Markun, Mr. Johann 74.975591 Dahlberg, Miss. Gerda Ulrika 124.106546 Banfield, Mr. Frederick James 123.750000 Sutehall, Mr. Henry Jr 62.052500 Rice, Mrs. William (Margaret Norton) 867.973958 Montvila, Rev. Juozas 183.333333 Graham, Miss. Margaret Edith 920.000000 Johnston, Miss. Catherine Helen Carrie 567.719167 Behr, Mr. Karl Howell 920.000000 Dooley, Mr. Patrick 72.645833 Name: Fare, Length: 891, dtype: float64","title":"Lambda Transformation"},{"location":"Projects/Diffusion/Diffusion/","text":"Diffusion Patterns The 2D Diffusion problem is : \\( \\large{ \\frac{\\partial U}{\\partial t} = D\\left(\\frac{\\partial^2U}{\\partial x^2} + \\frac{\\partial^2U}{\\partial y^2}\\right)} \\) Source import numpy as np import random as random import math as math import matplotlib.pyplot as plt import seaborn as sns sns . set() Consider a 2D lattice of length L L = 10 Create initial configuration: We can use a vacant list to create initial configuration where initially particle is at middle of the lattice. def start (L): create a vacant list of list P = [[ 0 for i in range (L)] for j in range (L)] put particle at center P[ int (L / 2 )][ int (L / 2 )] = 1 return P P = start(L) P [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] Make a plot of the lattice. plt . figure(figsize = [ 4 , 3 ]) sns . heatmap(P,annot = True ,cmap = YlGn ) matplotlib.axes._subplots.AxesSubplot at 0x7fc8fdae7790 Create a function to diffuse a particle: \\( P[i,j] = P[i+1,j] + P[i-1,j] + P[i,j+1] + P[i,j-1] \\) def diffuse_primitive (P,L): create vacant list of list PP = [[ 0 for i in range (L)] for j in range (L)] for i in range (L): for j in range (L): diffuse one step PP[i][j] = P[i + 1 ][j] + P[i - 1 ][j] + P[i][j + 1 ] + P[i][j - 1 ] normalize PP = PP / np . sum(PP) return PP L = 10 P = start(L) Set boundary conditons Lower limit P[0-1,j] = P[L,j] P[I,0-1] = P[i,L] Upper limit P[L+1,j] = P[o,j] P[i,L+1] = P[i,0] def diffuse (P,L): create vacant list of list PP = [[ 0 for i in range (L)] for j in range (L)] diffuse 1-step over supplied configuration for i in range (L): for j in range (L): set boundary condition at bottom and left ni = 0 ; nj = 0 if i == 0 :ni = L if j == 0 :nj = L add modulo to control boundary at top and right PP[i][j] = P[(i + 1 ) % L][j] + P[(i - 1 ) + ni][j]\\ + P[i][(j + 1 ) % L] + P[i][(j - 1 ) + nj] normalize PP = PP / np . sum(PP) return PP L = 10 P = start(L) plt . figure(figsize = [ 12 , 10 ]) plt . subplot( 3 , 3 , 1 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 2 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 3 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 4 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 5 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 6 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 7 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 8 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 9 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . show() Run the diffusion step with desire no of running steps def run_diffuse (P,nrun,L): run = 0 diffuse N times while run nrun: P = diffuse(P,L) run = run + 1 return P We can make a plot of arbitraty diffusion step by selecting irun in function runner. set parameters L = 100 ; nrun = 1000 ; P = start(L) run diffusion P = run_diffuse(P,nrun,L) plt . figure(figsize = [ 12 , 10 ]) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . axis( False ) plt . show() Much Finner L = 200 nrun = 1000 P = start(L) run diffusion P = run_diffuse(P,nrun,L) plt . figure(figsize = [ 12 , 10 ]) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . axis( False ) plt . show()","title":"Project Diffusion"},{"location":"Projects/Diffusion/Diffusion/#diffusion-patterns","text":"The 2D Diffusion problem is : \\( \\large{ \\frac{\\partial U}{\\partial t} = D\\left(\\frac{\\partial^2U}{\\partial x^2} + \\frac{\\partial^2U}{\\partial y^2}\\right)} \\) Source import numpy as np import random as random import math as math import matplotlib.pyplot as plt import seaborn as sns sns . set() Consider a 2D lattice of length L L = 10 Create initial configuration: We can use a vacant list to create initial configuration where initially particle is at middle of the lattice. def start (L): create a vacant list of list P = [[ 0 for i in range (L)] for j in range (L)] put particle at center P[ int (L / 2 )][ int (L / 2 )] = 1 return P P = start(L) P [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] Make a plot of the lattice. plt . figure(figsize = [ 4 , 3 ]) sns . heatmap(P,annot = True ,cmap = YlGn ) matplotlib.axes._subplots.AxesSubplot at 0x7fc8fdae7790 Create a function to diffuse a particle: \\( P[i,j] = P[i+1,j] + P[i-1,j] + P[i,j+1] + P[i,j-1] \\) def diffuse_primitive (P,L): create vacant list of list PP = [[ 0 for i in range (L)] for j in range (L)] for i in range (L): for j in range (L): diffuse one step PP[i][j] = P[i + 1 ][j] + P[i - 1 ][j] + P[i][j + 1 ] + P[i][j - 1 ] normalize PP = PP / np . sum(PP) return PP L = 10 P = start(L) Set boundary conditons Lower limit P[0-1,j] = P[L,j] P[I,0-1] = P[i,L] Upper limit P[L+1,j] = P[o,j] P[i,L+1] = P[i,0] def diffuse (P,L): create vacant list of list PP = [[ 0 for i in range (L)] for j in range (L)] diffuse 1-step over supplied configuration for i in range (L): for j in range (L): set boundary condition at bottom and left ni = 0 ; nj = 0 if i == 0 :ni = L if j == 0 :nj = L add modulo to control boundary at top and right PP[i][j] = P[(i + 1 ) % L][j] + P[(i - 1 ) + ni][j]\\ + P[i][(j + 1 ) % L] + P[i][(j - 1 ) + nj] normalize PP = PP / np . sum(PP) return PP L = 10 P = start(L) plt . figure(figsize = [ 12 , 10 ]) plt . subplot( 3 , 3 , 1 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 2 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 3 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 4 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 5 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 6 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 7 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 8 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . subplot( 3 , 3 , 9 ) P = diffuse(P,L) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . show() Run the diffusion step with desire no of running steps def run_diffuse (P,nrun,L): run = 0 diffuse N times while run nrun: P = diffuse(P,L) run = run + 1 return P We can make a plot of arbitraty diffusion step by selecting irun in function runner. set parameters L = 100 ; nrun = 1000 ; P = start(L) run diffusion P = run_diffuse(P,nrun,L) plt . figure(figsize = [ 12 , 10 ]) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . axis( False ) plt . show()","title":"Diffusion Patterns"},{"location":"Projects/Diffusion/Diffusion/#much-finner","text":"L = 200 nrun = 1000 P = start(L) run diffusion P = run_diffuse(P,nrun,L) plt . figure(figsize = [ 12 , 10 ]) sns . heatmap(P,annot = False ,cmap = YlGn ) plt . axis( False ) plt . show()","title":"Much Finner"},{"location":"Projects/Fern/fern/","text":"Project: Fractals Fern : Fern can be created by implementation of if loops and while loop . We will discuss three different approaches to create fern. Method 1: Direct implementation import matplotlib.pyplot as plt import seaborn as sns import random as random % matplotlib inline sns . set() import random as random x = 0 y = 0 X = [x] Y = [y] n = 1 isprint = False while n 1000000 : r = random . uniform( 0 , 100 ) if r 1.0 : x = 0 y = 0.16 * Y[n - 1 ] X . append(x) ; Y . append(y) elif r 1.0 and r 86.0 : x = 0.85 * X[n - 1 ] + 0.04 * Y[n - 1 ] y = - 0.04 * X[n - 1 ] + 0.85 * Y[n - 1 ] + 1.6 X . append(x);Y . append(y) elif r 86.0 and r 93.0 : x = 0.2 * X[n - 1 ] - 0.26 * Y[n - 1 ] y = 0.23 * X[n - 1 ] + 0.22 * Y[n - 1 ] + 1.6 X . append(x);Y . append(y) elif r 93.0 and r 100.0 : x = - 0.15 * X[n - 1 ] + 0.28 * Y[n - 1 ] y = 0.26 * X[n - 1 ] + 0.24 * Y[n - 1 ] + 0.44 X . append(x);Y . append(y) if isprint: print ( step: ,n, random number is: , r, coordinate is : , x,y) n = n + 1 plt . figure(figsize = [ 5 , 8 ]) plt . scatter(X,Y,color = g ,marker = . ) plt . show() Method-2 : Manual Matrix Multiplication In this method we first define matrices. Then we will manually multiply these matrices to get desired plot of fern. This correspond to the following transformations: \\( f_{1}(x,y)={\\begin{bmatrix}\\ 0.00 \\ 0.00\\ \\\\ 0.00 \\ 0.16\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}} \\) \\( f_{2}(x,y)={\\begin{bmatrix}\\ 0.85 \\ 0.04\\ \\\\ -0.04 \\ 0.85\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}}+{\\begin{bmatrix}\\ 0.00 \\\\ 1.60\\end{bmatrix}} \\) \\( f_{3}(x,y)={\\begin{bmatrix}\\ 0.20 \\ -0.26\\ \\\\ 0.23 \\ 0.22\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}}+{\\begin{bmatrix}\\ 0.00 \\\\ 1.60\\end{bmatrix}} \\) \\( f_{4}(x,y)={\\begin{bmatrix}\\ -0.15 \\ 0.28\\ \\\\ 0.26 \\ 0.24\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}}+{\\begin{bmatrix}\\ 0.00 \\\\ 0.44\\end{bmatrix}} \\) import numpy as np To define number of iteration. ITR = 100000 To define matrices using numpy x = np . array([[ 0.0 , 0.0 ] for k in range (ITR)]) A = np . array([[ 0.0 , 0.0 ],[ 0.0 , 0.16 ]]) B = np . array([[ 0.85 , 0.04 ],[ - 0.04 , 0.85 ]]) C = np . array([[ 0.20 , - 0.26 ],[ 0.23 , 0.22 ]]) D = np . array([[ - 0.15 , 0.28 ],[ 0.26 , 0.24 ]]) AD = np . array([[ 0.0 , 0.0 ], [ 0.0 , 1.6 ], [ 0.0 , 1.6 ], [ 0.0 , 0.44 ]]) To implement transformation X = [] Y = [] x[ 0 , 0 ] = 0.0 x[ 0 , 1 ] = 0.0 t = 0 while t ITR: ct = random . uniform( 0 , 100 ) First condition if ct 1.0 : for p in range ( 2 ): x[t,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + A[p,q] * x[t - 1 ,q] second condition elif ct 1.0 and ct 86.0 : for p in range ( 2 ): x[t,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + B[p,q] * x[t - 1 ,q] for p in range ( 2 ): x[t,p] = x[t,p] + AD[ 1 ,p] third condition elif ct 86.0 and ct 93.0 : for p in range ( 2 ): x[t,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + C[p,q] * x[t - 1 ,q] for p in range ( 2 ): x[t,p] = x[t,p] + AD[ 2 ,p] fourth condition elif ct 93.0 and ct 100.0 : for p in range ( 2 ): x[ 1 ,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + D[p,q] * x[t - 1 ,q] for p in range ( 2 ): x[t,p] = x[t,p] + AD[ 3 ,p] X . append(x[t, 0 ]) Y . append(x[t, 1 ]) t = t + 1 To get the plot plt . figure(figsize = [ 5 , 8 ]) plt . scatter(X,Y,color = blue ,marker = . ) plt . show() Method 3-Numpy In this case we first define the matrices and implement numpy library to make products. To define Matrices Matrices A = np . array([[ 0.0 , 0.0 ],[ 0.0 , 0.16 ]]) B = np . array([[ 0.85 , 0.04 ],[ - 0.04 , 0.85 ]]) C = np . array([[ 0.20 , - 0.26 ],[ 0.23 , 0.22 ]]) D = np . array([[ - 0.15 , 0.28 ],[ 0.26 , 0.24 ]]) AD = np . array([[ 0.0 , 0.0 ], [ 0.0 , 1.6 ], [ 0.0 , 1.6 ], [ 0.0 , 0.44 ]]) To implement transformation u = np . array([ 0 , 0 ]) U = [u] n = 1 while n 1000 : generate a random number r = random . uniform( 0 , 100 ) 1rst condition if r 1.0 : u = np . dot(A,u) U . append(u) second condition elif r 1.0 and r 86.0 : u = np . dot(B,u) + AD[ 1 ] U . append(u) third condition elif r 86.0 and r 93.0 : u = np . dot(C,u) + AD[ 2 ] U . append(u) fourth condition elif r 93.0 and r 100.0 : u = np . dot(D,u) + AD[ 3 ] U . append(u) update n n = n + 1 To get plot plt . figure(figsize = [ 5 , 8 ]) for item in U: plt . scatter(item[ 0 ],item[ 1 ],color = orange ,marker = . ) plt . show()","title":"Project Fern"},{"location":"Projects/Fern/fern/#project-fractals","text":"","title":"Project: Fractals"},{"location":"Projects/Fern/fern/#fern","text":"Fern can be created by implementation of if loops and while loop . We will discuss three different approaches to create fern.","title":"Fern :"},{"location":"Projects/Fern/fern/#method-1-direct-implementation","text":"import matplotlib.pyplot as plt import seaborn as sns import random as random % matplotlib inline sns . set() import random as random x = 0 y = 0 X = [x] Y = [y] n = 1 isprint = False while n 1000000 : r = random . uniform( 0 , 100 ) if r 1.0 : x = 0 y = 0.16 * Y[n - 1 ] X . append(x) ; Y . append(y) elif r 1.0 and r 86.0 : x = 0.85 * X[n - 1 ] + 0.04 * Y[n - 1 ] y = - 0.04 * X[n - 1 ] + 0.85 * Y[n - 1 ] + 1.6 X . append(x);Y . append(y) elif r 86.0 and r 93.0 : x = 0.2 * X[n - 1 ] - 0.26 * Y[n - 1 ] y = 0.23 * X[n - 1 ] + 0.22 * Y[n - 1 ] + 1.6 X . append(x);Y . append(y) elif r 93.0 and r 100.0 : x = - 0.15 * X[n - 1 ] + 0.28 * Y[n - 1 ] y = 0.26 * X[n - 1 ] + 0.24 * Y[n - 1 ] + 0.44 X . append(x);Y . append(y) if isprint: print ( step: ,n, random number is: , r, coordinate is : , x,y) n = n + 1 plt . figure(figsize = [ 5 , 8 ]) plt . scatter(X,Y,color = g ,marker = . ) plt . show()","title":"Method 1: Direct implementation"},{"location":"Projects/Fern/fern/#method-2-manual-matrix-multiplication","text":"In this method we first define matrices. Then we will manually multiply these matrices to get desired plot of fern. This correspond to the following transformations: \\( f_{1}(x,y)={\\begin{bmatrix}\\ 0.00 \\ 0.00\\ \\\\ 0.00 \\ 0.16\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}} \\) \\( f_{2}(x,y)={\\begin{bmatrix}\\ 0.85 \\ 0.04\\ \\\\ -0.04 \\ 0.85\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}}+{\\begin{bmatrix}\\ 0.00 \\\\ 1.60\\end{bmatrix}} \\) \\( f_{3}(x,y)={\\begin{bmatrix}\\ 0.20 \\ -0.26\\ \\\\ 0.23 \\ 0.22\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}}+{\\begin{bmatrix}\\ 0.00 \\\\ 1.60\\end{bmatrix}} \\) \\( f_{4}(x,y)={\\begin{bmatrix}\\ -0.15 \\ 0.28\\ \\\\ 0.26 \\ 0.24\\end{bmatrix}}{\\begin{bmatrix}\\ x \\\\ y\\end{bmatrix}}+{\\begin{bmatrix}\\ 0.00 \\\\ 0.44\\end{bmatrix}} \\) import numpy as np To define number of iteration. ITR = 100000 To define matrices using numpy x = np . array([[ 0.0 , 0.0 ] for k in range (ITR)]) A = np . array([[ 0.0 , 0.0 ],[ 0.0 , 0.16 ]]) B = np . array([[ 0.85 , 0.04 ],[ - 0.04 , 0.85 ]]) C = np . array([[ 0.20 , - 0.26 ],[ 0.23 , 0.22 ]]) D = np . array([[ - 0.15 , 0.28 ],[ 0.26 , 0.24 ]]) AD = np . array([[ 0.0 , 0.0 ], [ 0.0 , 1.6 ], [ 0.0 , 1.6 ], [ 0.0 , 0.44 ]]) To implement transformation X = [] Y = [] x[ 0 , 0 ] = 0.0 x[ 0 , 1 ] = 0.0 t = 0 while t ITR: ct = random . uniform( 0 , 100 ) First condition if ct 1.0 : for p in range ( 2 ): x[t,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + A[p,q] * x[t - 1 ,q] second condition elif ct 1.0 and ct 86.0 : for p in range ( 2 ): x[t,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + B[p,q] * x[t - 1 ,q] for p in range ( 2 ): x[t,p] = x[t,p] + AD[ 1 ,p] third condition elif ct 86.0 and ct 93.0 : for p in range ( 2 ): x[t,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + C[p,q] * x[t - 1 ,q] for p in range ( 2 ): x[t,p] = x[t,p] + AD[ 2 ,p] fourth condition elif ct 93.0 and ct 100.0 : for p in range ( 2 ): x[ 1 ,p] = 0.0 for q in range ( 2 ): x[t,p] = x[t,p] + D[p,q] * x[t - 1 ,q] for p in range ( 2 ): x[t,p] = x[t,p] + AD[ 3 ,p] X . append(x[t, 0 ]) Y . append(x[t, 1 ]) t = t + 1 To get the plot plt . figure(figsize = [ 5 , 8 ]) plt . scatter(X,Y,color = blue ,marker = . ) plt . show()","title":"Method-2 : Manual Matrix Multiplication"},{"location":"Projects/Fern/fern/#method-3-numpy","text":"In this case we first define the matrices and implement numpy library to make products. To define Matrices Matrices A = np . array([[ 0.0 , 0.0 ],[ 0.0 , 0.16 ]]) B = np . array([[ 0.85 , 0.04 ],[ - 0.04 , 0.85 ]]) C = np . array([[ 0.20 , - 0.26 ],[ 0.23 , 0.22 ]]) D = np . array([[ - 0.15 , 0.28 ],[ 0.26 , 0.24 ]]) AD = np . array([[ 0.0 , 0.0 ], [ 0.0 , 1.6 ], [ 0.0 , 1.6 ], [ 0.0 , 0.44 ]]) To implement transformation u = np . array([ 0 , 0 ]) U = [u] n = 1 while n 1000 : generate a random number r = random . uniform( 0 , 100 ) 1rst condition if r 1.0 : u = np . dot(A,u) U . append(u) second condition elif r 1.0 and r 86.0 : u = np . dot(B,u) + AD[ 1 ] U . append(u) third condition elif r 86.0 and r 93.0 : u = np . dot(C,u) + AD[ 2 ] U . append(u) fourth condition elif r 93.0 and r 100.0 : u = np . dot(D,u) + AD[ 3 ] U . append(u) update n n = n + 1 To get plot plt . figure(figsize = [ 5 , 8 ]) for item in U: plt . scatter(item[ 0 ],item[ 1 ],color = orange ,marker = . ) plt . show()","title":"Method 3-Numpy"},{"location":"Projects/Ncharges/Ncharges/","text":"N-charge system The electric field for a single charge is given by: \\( E = q * \\frac{\\hat{r}}{r} \\) The electric Potential: \\( V = q * \\frac{1}{r} \\). In cartesian coordinate: \\( \\frac{1}{r} = \\frac{1}{\\sqrt{((x-x^{'})^{2} + (y - y^{'})^{2})}} \\). import numpy as np import matplotlib.pyplot as plt from matplotlib import cm import seaborn as sns sns . set() Class Charge Lets create a class Charge with function line to calculate the distance between source and field point and function V_point_charge to calculate the electric potential ata fileld point x,y due to source poin at pos . class Charge : Data incapsulation def __init__ ( self , q, pos): self . q = q self . pos = pos def line ( self , x,y): create a vector from charge to observation point self . vector = [x - self . pos[ 0 ],y - self . pos[ 1 ]] norm of the vector self . norm = np . sqrt(( self . vector[ 0 ]) ** 2 + ( self . vector[ 1 ]) ** 2 ) def V_point_charge ( self , x, y): recall length self . line(x,y) Make sure to exclude source itself if self . norm 0 : self . V = self . q / self . norm if length is zero, set V equal to 0 elif self . norm == 0 : self . V = 0 return self . V Example : Lets use charge q = 100 at posiotion x =1 and y =1 to find electric potential at different points in 2D C = Charge( 100 , [ 1 , 1 ]) for x in range ( 3 ): for y in range ( 3 ): print (x,y, | , C . V_point_charge(x, y)) 0 0 | 70.71067811865474 0 1 | 100.0 0 2 | 70.71067811865474 1 0 | 100.0 1 1 | 0 1 2 | 100.0 2 0 | 70.71067811865474 2 1 | 100.0 2 2 | 70.71067811865474 Total Electric potential Total electric potential at a point x,y is the sum of contribution of all charges defined in class Charge . def V_total (x, y, charges): V = 0 for C in charges: Vp = C . V_point_charge(x, y) V = V + Vp return V Example: Lets use collection of charges to find a electric potential at point x = 4, y =4 sample_charges = [Charge(q = 20 , pos = [ 23 , 34 ]), Charge(q = 25 , pos = [ 13 , 48 ]), Charge(q = 40 , pos = [ 3 , 14 ]), Charge(q = 80 , pos = [ 88 , 60 ])] V_total(x = 4 , y = 4 , charges = sample_charges) 5.892446541150622 Lattice of charges ( scatter ) Now, we are going to implement Charge class to define charge distribution and calculate electric potential at several places. To create a lattice of charges. first charge to be at x=1,y=1 q = 100 Dictionary to collect charges, x and y xoordinates Qd = [] List to collect Charge objects charges = [] use for loops to construct collection of charges objects for i in range ( 5 ): for j in range ( 5 ): Collecting charges and their coordinates Qd . append({ q : q, x : i * 20 , y :j * 20 }) charge objects are being collected charges . append(Charge(q , [ 20 * i, 20 * j])) change the sign of charge alternatly q = - q To visualize lattice of charges Plot the lattice of charges plt . figure(figsize = [ 8 , 6 ]) for item in Qd: Sctaeer as red dot if charge is positive if item[ q ] 0 : plt . scatter(item[ x ], item[ y ], c = r ,s = 100 ) Scatter as blue dot if charge is negative else : plt . scatter(item[ x ], item[ y ], c = b ,s = 100 ) plt . xlabel( X-axis ) plt . ylabel( Y-asis ) plt . show() Electric Potential ( heatmap ) To find Electric Potential at several points due to lattice of charges Create X and Y coordinate X = np . arange( - 10 , 110 , 2 ) Y = np . arange( - 10 , 110 , 2 ) Initiate vacant V-list of list V = [[ 0.0 for i in range ( len (X))] for j in range ( len (Y))] Calculate Electric potential at each x,y coordinate for i,x in enumerate (X): for j,y in enumerate (Y): v = V_total(x, y, charges) V[i][j] = v VV = np . array(V) To plot Electric potential plt . figure(figsize = [ 12 , 10 ]) sns . heatmap(VV,annot = False ,cmap = YlGnBu ) plt . xlabel( X-axis ) plt . ylabel( Y-axis ) plt . title( Electric field of lattice of charges ) plt . show() Electric Field ( meshgrid ) from matplotlib.patches import Circle To calculate Electric Field at at point x,y due to charge q at r0 def E (q, r0, x, y): Return the electric field vector E=(Ex,Ey) due to charge q at r0. den = np . hypot(x - r0[ 0 ], y - r0[ 1 ]) ** 3 return q * (x - r0[ 0 ]) / den, q * (y - r0[ 1 ]) / den To define the number charge in the system nq = 2 ** int ( 2 ) To create the meshgrid to make a plot # Grid of x, y points nx, ny = 16 , 16 x = np . linspace( - 2 , 2 , nx) y = np . linspace( - 2 , 2 , ny) X, Y = np . meshgrid(x, y) To define charge touples (q,x0,y0) charges = [] for i in range (nq): q = i % 2 * 2 - 1 charges . append((q, (np . cos( 2 * np . pi * i / nq), np . sin( 2 * np . pi * i / nq)))) To calculate Electric Field at point x,y due to predefined charge distribution # Electric field vector, E=(Ex, Ey), as separate components Ex, Ey = np . zeros((ny, nx)), np . zeros((ny, nx)) for charge in charges: ex, ey = E( * charge, x = X, y = Y) Ex += ex Ey += ey To plot Vector Field for Electric Field using streamplot . fig = plt . figure(figsize = [ 12 , 10 ]) ax = fig . add_subplot( 111 ) # Plot the streamlines with an appropriate colormap and arrow style color = 2 * np . log(np . hypot(Ex, Ey)) ax . streamplot(x, y, Ex, Ey, color = color, linewidth = 1 , cmap = plt . cm . inferno, density = 2 , arrowstyle = - , arrowsize = 1.5 ) # Add filled circles for the charges themselves charge_colors = { True : #aa0000 , False : #0000aa } for q, pos in charges: ax . add_artist(Circle(pos, 0.05 , color = charge_colors[q 0 ])) ax . set_xlabel( $x-axis$ ) ax . set_ylabel( $y-axis$ ) ax . set_xlim( - 2 , 2 ) ax . set_ylim( - 2 , 2 ) ax . set_aspect( equal ) plt . show() Vector Field ( quiver ) To create a meshgrid for plot x,y = np . meshgrid(np . linspace( - 10 , 10 , 20 ),np . linspace( - 10 , 10 , 20 )) To set up parametric variables for vector field u = - y / np . sqrt(x ** 2 + y ** 2 ) v = x / np . sqrt(x ** 2 + y ** 2 ) To visualize vector field plt . figure(figsize = [ 12 , 10 ]) plt . quiver(x,y,u,v) plt . show() Vector Field ( quiver and quiverkey ) To set number of points and create space of x,y for vector field N = 25 x = np . arange( 0 , 2 * np . pi + 2 * np . pi / 20 , 2 * np . pi / N) y = np . arange( 0 , 2 * np . pi + 2 * np . pi / 20 , 2 * np . pi / N) To create meshgrid for plot X,Y = np . meshgrid(x,y) To create parametric variables for vector field U = np . sin(X) * np . cos(Y) V = - np . cos(X) * np . sin(Y) To create Plot fig3, ax3 = plt . subplots(figsize = [ 12 , 10 ]) ax3 . set_title( pivot= tip ; scales with x view ) M = np . hypot(U, V) Q = ax3 . quiver(X, Y, U, V, M,\\ units = x ,\\ pivot = tip , width = 0.022 , scale = 1 / 0.20 ) qk = ax3 . quiverkey(Q, 0.9 , 0.9 , 1 ,\\ r $1 \\frac {m}{s} $ ,\\ labelpos = E , coordinates = figure ) ax3 . scatter(X, Y, color = 0.5 , s = 1 ) plt . show()","title":"Project N-charges"},{"location":"Projects/Ncharges/Ncharges/#n-charge-system","text":"The electric field for a single charge is given by: \\( E = q * \\frac{\\hat{r}}{r} \\) The electric Potential: \\( V = q * \\frac{1}{r} \\). In cartesian coordinate: \\( \\frac{1}{r} = \\frac{1}{\\sqrt{((x-x^{'})^{2} + (y - y^{'})^{2})}} \\). import numpy as np import matplotlib.pyplot as plt from matplotlib import cm import seaborn as sns sns . set()","title":"N-charge system"},{"location":"Projects/Ncharges/Ncharges/#class-charge","text":"Lets create a class Charge with function line to calculate the distance between source and field point and function V_point_charge to calculate the electric potential ata fileld point x,y due to source poin at pos . class Charge : Data incapsulation def __init__ ( self , q, pos): self . q = q self . pos = pos def line ( self , x,y): create a vector from charge to observation point self . vector = [x - self . pos[ 0 ],y - self . pos[ 1 ]] norm of the vector self . norm = np . sqrt(( self . vector[ 0 ]) ** 2 + ( self . vector[ 1 ]) ** 2 ) def V_point_charge ( self , x, y): recall length self . line(x,y) Make sure to exclude source itself if self . norm 0 : self . V = self . q / self . norm if length is zero, set V equal to 0 elif self . norm == 0 : self . V = 0 return self . V","title":"Class Charge"},{"location":"Projects/Ncharges/Ncharges/#example","text":"Lets use charge q = 100 at posiotion x =1 and y =1 to find electric potential at different points in 2D C = Charge( 100 , [ 1 , 1 ]) for x in range ( 3 ): for y in range ( 3 ): print (x,y, | , C . V_point_charge(x, y)) 0 0 | 70.71067811865474 0 1 | 100.0 0 2 | 70.71067811865474 1 0 | 100.0 1 1 | 0 1 2 | 100.0 2 0 | 70.71067811865474 2 1 | 100.0 2 2 | 70.71067811865474","title":"Example :"},{"location":"Projects/Ncharges/Ncharges/#total-electric-potential","text":"Total electric potential at a point x,y is the sum of contribution of all charges defined in class Charge . def V_total (x, y, charges): V = 0 for C in charges: Vp = C . V_point_charge(x, y) V = V + Vp return V Example: Lets use collection of charges to find a electric potential at point x = 4, y =4 sample_charges = [Charge(q = 20 , pos = [ 23 , 34 ]), Charge(q = 25 , pos = [ 13 , 48 ]), Charge(q = 40 , pos = [ 3 , 14 ]), Charge(q = 80 , pos = [ 88 , 60 ])] V_total(x = 4 , y = 4 , charges = sample_charges) 5.892446541150622","title":"Total Electric potential"},{"location":"Projects/Ncharges/Ncharges/#lattice-of-charges-scatter","text":"Now, we are going to implement Charge class to define charge distribution and calculate electric potential at several places. To create a lattice of charges. first charge to be at x=1,y=1 q = 100 Dictionary to collect charges, x and y xoordinates Qd = [] List to collect Charge objects charges = [] use for loops to construct collection of charges objects for i in range ( 5 ): for j in range ( 5 ): Collecting charges and their coordinates Qd . append({ q : q, x : i * 20 , y :j * 20 }) charge objects are being collected charges . append(Charge(q , [ 20 * i, 20 * j])) change the sign of charge alternatly q = - q To visualize lattice of charges Plot the lattice of charges plt . figure(figsize = [ 8 , 6 ]) for item in Qd: Sctaeer as red dot if charge is positive if item[ q ] 0 : plt . scatter(item[ x ], item[ y ], c = r ,s = 100 ) Scatter as blue dot if charge is negative else : plt . scatter(item[ x ], item[ y ], c = b ,s = 100 ) plt . xlabel( X-axis ) plt . ylabel( Y-asis ) plt . show()","title":"Lattice of charges (scatter)"},{"location":"Projects/Ncharges/Ncharges/#electric-potential-heatmap","text":"To find Electric Potential at several points due to lattice of charges Create X and Y coordinate X = np . arange( - 10 , 110 , 2 ) Y = np . arange( - 10 , 110 , 2 ) Initiate vacant V-list of list V = [[ 0.0 for i in range ( len (X))] for j in range ( len (Y))] Calculate Electric potential at each x,y coordinate for i,x in enumerate (X): for j,y in enumerate (Y): v = V_total(x, y, charges) V[i][j] = v VV = np . array(V) To plot Electric potential plt . figure(figsize = [ 12 , 10 ]) sns . heatmap(VV,annot = False ,cmap = YlGnBu ) plt . xlabel( X-axis ) plt . ylabel( Y-axis ) plt . title( Electric field of lattice of charges ) plt . show()","title":"Electric Potential (heatmap)"},{"location":"Projects/Ncharges/Ncharges/#electric-field-meshgrid","text":"from matplotlib.patches import Circle To calculate Electric Field at at point x,y due to charge q at r0 def E (q, r0, x, y): Return the electric field vector E=(Ex,Ey) due to charge q at r0. den = np . hypot(x - r0[ 0 ], y - r0[ 1 ]) ** 3 return q * (x - r0[ 0 ]) / den, q * (y - r0[ 1 ]) / den To define the number charge in the system nq = 2 ** int ( 2 ) To create the meshgrid to make a plot # Grid of x, y points nx, ny = 16 , 16 x = np . linspace( - 2 , 2 , nx) y = np . linspace( - 2 , 2 , ny) X, Y = np . meshgrid(x, y) To define charge touples (q,x0,y0) charges = [] for i in range (nq): q = i % 2 * 2 - 1 charges . append((q, (np . cos( 2 * np . pi * i / nq), np . sin( 2 * np . pi * i / nq)))) To calculate Electric Field at point x,y due to predefined charge distribution # Electric field vector, E=(Ex, Ey), as separate components Ex, Ey = np . zeros((ny, nx)), np . zeros((ny, nx)) for charge in charges: ex, ey = E( * charge, x = X, y = Y) Ex += ex Ey += ey To plot Vector Field for Electric Field using streamplot . fig = plt . figure(figsize = [ 12 , 10 ]) ax = fig . add_subplot( 111 ) # Plot the streamlines with an appropriate colormap and arrow style color = 2 * np . log(np . hypot(Ex, Ey)) ax . streamplot(x, y, Ex, Ey, color = color, linewidth = 1 , cmap = plt . cm . inferno, density = 2 , arrowstyle = - , arrowsize = 1.5 ) # Add filled circles for the charges themselves charge_colors = { True : #aa0000 , False : #0000aa } for q, pos in charges: ax . add_artist(Circle(pos, 0.05 , color = charge_colors[q 0 ])) ax . set_xlabel( $x-axis$ ) ax . set_ylabel( $y-axis$ ) ax . set_xlim( - 2 , 2 ) ax . set_ylim( - 2 , 2 ) ax . set_aspect( equal ) plt . show()","title":"Electric Field (meshgrid)"},{"location":"Projects/Ncharges/Ncharges/#vector-field-quiver","text":"To create a meshgrid for plot x,y = np . meshgrid(np . linspace( - 10 , 10 , 20 ),np . linspace( - 10 , 10 , 20 )) To set up parametric variables for vector field u = - y / np . sqrt(x ** 2 + y ** 2 ) v = x / np . sqrt(x ** 2 + y ** 2 ) To visualize vector field plt . figure(figsize = [ 12 , 10 ]) plt . quiver(x,y,u,v) plt . show()","title":"Vector Field (quiver)"},{"location":"Projects/Ncharges/Ncharges/#vector-field-quiver-and-quiverkey","text":"To set number of points and create space of x,y for vector field N = 25 x = np . arange( 0 , 2 * np . pi + 2 * np . pi / 20 , 2 * np . pi / N) y = np . arange( 0 , 2 * np . pi + 2 * np . pi / 20 , 2 * np . pi / N) To create meshgrid for plot X,Y = np . meshgrid(x,y) To create parametric variables for vector field U = np . sin(X) * np . cos(Y) V = - np . cos(X) * np . sin(Y) To create Plot fig3, ax3 = plt . subplots(figsize = [ 12 , 10 ]) ax3 . set_title( pivot= tip ; scales with x view ) M = np . hypot(U, V) Q = ax3 . quiver(X, Y, U, V, M,\\ units = x ,\\ pivot = tip , width = 0.022 , scale = 1 / 0.20 ) qk = ax3 . quiverkey(Q, 0.9 , 0.9 , 1 ,\\ r $1 \\frac {m}{s} $ ,\\ labelpos = E , coordinates = figure ) ax3 . scatter(X, Y, color = 0.5 , s = 1 ) plt . show()","title":"Vector Field (quiver and quiverkey)"},{"location":"Projects/Rwalk/Rwalk/","text":"Random Walk import numpy as np import random as random import matplotlib.pyplot as plt import seaborn as sns sns . set() Random walk in one dimension To create reandom walk in 1D, we generate random step 1, -1 and move in one direction. Since we are taking one direction and time to create a plot. It is displayed in plot below. Lets try to implement random walk with direct implementation with for loop and with function walk1D . Random Walk 1D (Direct) X stores 1-D coordinate X = [] T stores time coordinate T = [] starting point x = 0 length of each step d = 1 iteratefor N steps for t in range ( 100 ): Walk one step ahead x = x + d * random . choice([ - 1 , 1 ]) collect time T . append(t) collect position X . append(x) Make a plot plt . figure(figsize = [ 15 , 4 ]) plt . scatter(T,X,marker = . ) plt . plot(T,X) plt . xlabel( Time ) plt . ylabel( Displacement ) plt . grid( True ) plt . show() Random Walk 1D (Function) def walk1D (x,N,d): This function returns the space X and time T for random walk in 1D x: initial position N: total number of steps d: step length X stores 1-D coordinate X = [] T stores time coordinate T = [] iteratefor N steps for t in range (N): Walk one step ahead x = x + d * random . choice([ - 1 , 1 ]) collect time T . append(t) collect position X . append(x) return X,T Implement function to get data X,T = walk1D(x = 0 ,N = 100 ,d = 1 ) Make a plot plt . figure(figsize = [ 15 , 4 ]) plt . scatter(T,X,marker = . ) plt . plot(T,X) plt . xlabel( Time ) plt . ylabel( Displacement ) plt . grid( True ) plt . show() Random Walk 1D (Class) class Walker1D ( object ): This is a class to create on dimentional walk: x0 : initial position d : step size N : number of steps in random walk def __init__ ( self ,N,d,x0): self . N = N self . X = [] self . d = d self . x0 = x0 def walk1D ( self ): note initial position x = self . x0 k = 0 while k self . N: Walk one step ahead x = x + self . d * random . choice([ - 1 , 1 ]) collect position self . X . append(x) k = k + 1 return self . X Let's generate 4 different random walks of step 1000 each X1 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() X2 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() X3 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() X4 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() T = [i for i in range ( len (X1))] import json with open ( data/rwalk4.json , w ) as f4: json . dump([X1,X2,X3,X4,T],f4) Let's visualize them plt . figure(figsize = [ 15 , 4 ]) plt . plot(T,X1) plt . plot(T,X2) plt . plot(T,X3) plt . plot(T,X4) plt . xlabel( Time ) plt . ylabel( Displacement ) plt . grid( True ) plt . show() Random Walk in 2D Lets repeat the function implementation for 2D Random Walk. Random Walk 2D (Function) We will create two functions move2D to move one step and walk2D to walk multiple steps. def move2D (xi,yi): This function choose a direction and walk one step in 2D direction = random . choice([ x , y ]) if direction == x : r = random . choice([ - 1 , 1 ]) if r == 1 :xf = xi + 1 else : xf = xi - 1 yf = yi if direction == y : r = random . choice([ - 1 , 1 ]) if r == 1 :yf = yi + 1 else : yf = yi - 1 xf = xi return xf,yf def walk2D (N,pos): This function walks N step in 2d implementing move2D coordinate collectors X = [] ; Y = [] from where to start x0 = pos[ 0 ] ; y0 = pos[ 0 ] k = 0 while k N: move a step x,y = move2D(x0,y0) collect X coordinate X . append(x) collect Y coordinate Y . append(y) set previous position for next step x0 = x y0 = y k = k + 1 return X,Y Lets create a 3 different Random walk in 2D N = 10000 U = walk2D(N,[ 0 , 0 ]) V = walk2D(N,[ 0 , 0 ]) W = walk2D(N,[ 0 , 0 ]) plt . figure(figsize = [ 8 , 8 ]) plt . plot(U[ 0 ],U[ 1 ], - ) plt . plot(V[ 0 ],V[ 1 ], - ) plt . plot(W[ 0 ],W[ 1 ], - ) #plt.axis([-100, 100, -100, 100]) plt . xlabel( x-axis ) plt . ylabel( y-axis ) plt . grid( True ) plt . title( Brownian motion in 2D ) plt . show() Random Walk in 3D Similarly Random Walk in 3D can be created and visualized with .gif file as shown below","title":"Project Random Walk"},{"location":"Projects/Rwalk/Rwalk/#random-walk","text":"import numpy as np import random as random import matplotlib.pyplot as plt import seaborn as sns sns . set()","title":"Random Walk"},{"location":"Projects/Rwalk/Rwalk/#random-walk-in-one-dimension","text":"To create reandom walk in 1D, we generate random step 1, -1 and move in one direction. Since we are taking one direction and time to create a plot. It is displayed in plot below. Lets try to implement random walk with direct implementation with for loop and with function walk1D .","title":"Random walk in one dimension"},{"location":"Projects/Rwalk/Rwalk/#random-walk-1d-direct","text":"X stores 1-D coordinate X = [] T stores time coordinate T = [] starting point x = 0 length of each step d = 1 iteratefor N steps for t in range ( 100 ): Walk one step ahead x = x + d * random . choice([ - 1 , 1 ]) collect time T . append(t) collect position X . append(x) Make a plot plt . figure(figsize = [ 15 , 4 ]) plt . scatter(T,X,marker = . ) plt . plot(T,X) plt . xlabel( Time ) plt . ylabel( Displacement ) plt . grid( True ) plt . show()","title":"Random Walk 1D (Direct)"},{"location":"Projects/Rwalk/Rwalk/#random-walk-1d-function","text":"def walk1D (x,N,d): This function returns the space X and time T for random walk in 1D x: initial position N: total number of steps d: step length X stores 1-D coordinate X = [] T stores time coordinate T = [] iteratefor N steps for t in range (N): Walk one step ahead x = x + d * random . choice([ - 1 , 1 ]) collect time T . append(t) collect position X . append(x) return X,T Implement function to get data X,T = walk1D(x = 0 ,N = 100 ,d = 1 ) Make a plot plt . figure(figsize = [ 15 , 4 ]) plt . scatter(T,X,marker = . ) plt . plot(T,X) plt . xlabel( Time ) plt . ylabel( Displacement ) plt . grid( True ) plt . show()","title":"Random Walk 1D (Function)"},{"location":"Projects/Rwalk/Rwalk/#random-walk-1d-class","text":"class Walker1D ( object ): This is a class to create on dimentional walk: x0 : initial position d : step size N : number of steps in random walk def __init__ ( self ,N,d,x0): self . N = N self . X = [] self . d = d self . x0 = x0 def walk1D ( self ): note initial position x = self . x0 k = 0 while k self . N: Walk one step ahead x = x + self . d * random . choice([ - 1 , 1 ]) collect position self . X . append(x) k = k + 1 return self . X Let's generate 4 different random walks of step 1000 each X1 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() X2 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() X3 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() X4 = Walker1D(N = 1000 ,d = 1 ,x0 = 0 ) . walk1D() T = [i for i in range ( len (X1))] import json with open ( data/rwalk4.json , w ) as f4: json . dump([X1,X2,X3,X4,T],f4) Let's visualize them plt . figure(figsize = [ 15 , 4 ]) plt . plot(T,X1) plt . plot(T,X2) plt . plot(T,X3) plt . plot(T,X4) plt . xlabel( Time ) plt . ylabel( Displacement ) plt . grid( True ) plt . show()","title":"Random Walk 1D (Class)"},{"location":"Projects/Rwalk/Rwalk/#random-walk-in-2d","text":"Lets repeat the function implementation for 2D Random Walk.","title":"Random Walk in 2D"},{"location":"Projects/Rwalk/Rwalk/#random-walk-2d-function","text":"We will create two functions move2D to move one step and walk2D to walk multiple steps. def move2D (xi,yi): This function choose a direction and walk one step in 2D direction = random . choice([ x , y ]) if direction == x : r = random . choice([ - 1 , 1 ]) if r == 1 :xf = xi + 1 else : xf = xi - 1 yf = yi if direction == y : r = random . choice([ - 1 , 1 ]) if r == 1 :yf = yi + 1 else : yf = yi - 1 xf = xi return xf,yf def walk2D (N,pos): This function walks N step in 2d implementing move2D coordinate collectors X = [] ; Y = [] from where to start x0 = pos[ 0 ] ; y0 = pos[ 0 ] k = 0 while k N: move a step x,y = move2D(x0,y0) collect X coordinate X . append(x) collect Y coordinate Y . append(y) set previous position for next step x0 = x y0 = y k = k + 1 return X,Y Lets create a 3 different Random walk in 2D N = 10000 U = walk2D(N,[ 0 , 0 ]) V = walk2D(N,[ 0 , 0 ]) W = walk2D(N,[ 0 , 0 ]) plt . figure(figsize = [ 8 , 8 ]) plt . plot(U[ 0 ],U[ 1 ], - ) plt . plot(V[ 0 ],V[ 1 ], - ) plt . plot(W[ 0 ],W[ 1 ], - ) #plt.axis([-100, 100, -100, 100]) plt . xlabel( x-axis ) plt . ylabel( y-axis ) plt . grid( True ) plt . title( Brownian motion in 2D ) plt . show()","title":"Random Walk 2D (Function)"},{"location":"Projects/Rwalk/Rwalk/#random-walk-in-3d","text":"Similarly Random Walk in 3D can be created and visualized with .gif file as shown below","title":"Random Walk in 3D"},{"location":"References/ref/","text":"References Mkdocs Deploy MkDocs MkDoc Black and Blue Codehilit Syntax highlight all Syntax highlight code","title":"Reference"},{"location":"References/ref/#references","text":"","title":"References"},{"location":"References/ref/#mkdocs","text":"Deploy MkDocs MkDoc Black and Blue Codehilit Syntax highlight all Syntax highlight code","title":"Mkdocs"},{"location":"Scipy/Bessel/Bessel/","text":"Bessel Functions Scipy Library: Source In this notebook we are going to make some fun with Oscillating membrane implementing Bessel Functions. import numpy as np from scipy.special import jn, yn, jn_zeros, yn_zeros import scipy as sci import scipy.special as sp from __future__ import division import matplotlib.pyplot as plt import matplotlib import pylab from mpl_toolkits.mplot3d import Axes3D from matplotlib import cm, colors % matplotlib inline import seaborn as sns sns . set() Bessel Functions n = 0 # order x = 0.0 # Bessel function of first kind print ( J_ %d ( %f ) = %f % (n, x, jn(n, x))) x = 1.0 # Bessel function of second kind print ( Y_ %d ( %f ) = %f % (n, x, yn(n, x))) J_0(0.000000) = 1.000000 Y_0(1.000000) = 0.088257 x = np . linspace( 0 , 30 , 100 ) plt . figure(figsize = ( 15 , 8 )) for n in range ( 10 ): plt . plot(x, jn(n, x), label = r $J_ %d (x)$ % n) plt . legend(); Vibrating Circular Membrane The vibrations of a thin circular membrane stretched across a rigid circular frame (such as a drum head) can be described as normal modes written in terms of Bessel functions: \\( \\large{z(r,\u03b8;t)=AJ_n(kr)\\sin(n\u03b8)\\cos(k\u03bdt)}\\) where $(r,\u03b8)$ describes a position in polar co-ordinates with the origin at the centre of the membrane, t is time and v is a constant depending on the tension and surface density of the drum. The modes are labelled by integers $n=0,1,\u22ef $ and $m=1,2,3,\u22ef$ where k is the mth zero of $J_n$. The following program produces a plot of the displacement of the membrane in the n=3,m=2 normal mode at time t=0. Table p q --- --- --- --- --- --- def displacement (n, m, r, theta): Calculate the displacement of the drum membrane at (r, theta; t=0) in the normal mode described by integers n = 0, 0 m = mmax. # Pick off the mth zero of Bessel function Jn k = jn_zeros(n, mmax + 1 )[m] return np . sin(n * theta) * jn(n, r * k) Oscillating membrane ( SIngle Plot, (2,0)) # Allow calculations up to m = mmax mmax = 10 # Positions on the drum surface are specified in polar co-ordinates r = np . linspace( 0 , 1 , 100 ) theta = np . linspace( 0 , 2 * np . pi, 100 ) # Create arrays of cartesian co-ordinates (x, y) ... x = np . array([rr * np . cos(theta) for rr in r]) y = np . array([rr * np . sin(theta) for rr in r]) # ... and vertical displacement (z) for the required normal mode at # time, t = 0 n0, m0 = 2 , 0 z = np . array([displacement(n0, m0, rr, theta) for rr in r]) plt . figure(figsize = [ 8 , 8 ]) pylab . contour(x, y, z) pylab . show() Oscilating Membrane ( Single, 3D plot, (2,0)) r, theta = np . mgrid[ 0 : 1 : 100 j, 0 : 2 * np . pi: 100 j] x = r * np . cos(theta) y = r * np . sin(theta) z = displacement(n0, m0, r, theta) N = z / (z . max() - z . min()) fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ), figsize = ( 15 , 8 )) im = ax . plot_surface(x, y, z, rstride = 1 , cstride = 1 , facecolors = cm . jet(N)) mm = cm . ScalarMappable(cmap = cm . jet) mm . set_array(R) fig . colorbar(mm, shrink = 0.8 ); Oscillating Membrane (Multiplot) plt . figure(figsize = [ 15 , 25 ]) k = 0 for n in range ( 6 ): for m in range (n - 1 ): k = k + 1 z = np . array([displacement(n, m, rr, theta) for rr in r]) plt . subplot( 5 , 3 ,k) plt . title( str (n) + str (m)) pylab . contour(x, y, z) pylab . show() Oscilating Membrane ( m,n = 2,2) n0,m0 = 2 , 2 r, theta = np . mgrid[ 0 : 1 : 100 j, 0 : 2 * np . pi: 100 j] x = r * np . cos(theta) y = r * np . sin(theta) z = displacement(n0, m0, r, theta) N = z / (z . max() - z . min()) fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ), figsize = ( 15 , 8 )) im = ax . plot_surface(x, y, z, rstride = 1 , cstride = 1 , facecolors = cm . jet(N)) mm = cm . ScalarMappable(cmap = cm . jet) mm . set_array(R) fig . colorbar(mm, shrink = 0.8 ); References https://en.wikipedia.org/wiki/Vibrations_of_a_circular_membrane https://www.exoruskoh.me/single-post/2017/05/24/Vibrating-Membranes-and-Fancy-Animations https://www.acs.psu.edu/drussell/Demos/MembraneCircle/Circle.html http://balbuceosastropy.blogspot.com/2015/06/spherical-harmonics-in-python.html","title":"Oscillating Membrane"},{"location":"Scipy/Bessel/Bessel/#bessel-functions","text":"Scipy Library: Source In this notebook we are going to make some fun with Oscillating membrane implementing Bessel Functions. import numpy as np from scipy.special import jn, yn, jn_zeros, yn_zeros import scipy as sci import scipy.special as sp from __future__ import division import matplotlib.pyplot as plt import matplotlib import pylab from mpl_toolkits.mplot3d import Axes3D from matplotlib import cm, colors % matplotlib inline import seaborn as sns sns . set()","title":"Bessel Functions"},{"location":"Scipy/Bessel/Bessel/#bessel-functions_1","text":"n = 0 # order x = 0.0 # Bessel function of first kind print ( J_ %d ( %f ) = %f % (n, x, jn(n, x))) x = 1.0 # Bessel function of second kind print ( Y_ %d ( %f ) = %f % (n, x, yn(n, x))) J_0(0.000000) = 1.000000 Y_0(1.000000) = 0.088257 x = np . linspace( 0 , 30 , 100 ) plt . figure(figsize = ( 15 , 8 )) for n in range ( 10 ): plt . plot(x, jn(n, x), label = r $J_ %d (x)$ % n) plt . legend();","title":"Bessel Functions"},{"location":"Scipy/Bessel/Bessel/#vibrating-circular-membrane","text":"The vibrations of a thin circular membrane stretched across a rigid circular frame (such as a drum head) can be described as normal modes written in terms of Bessel functions: \\( \\large{z(r,\u03b8;t)=AJ_n(kr)\\sin(n\u03b8)\\cos(k\u03bdt)}\\) where $(r,\u03b8)$ describes a position in polar co-ordinates with the origin at the centre of the membrane, t is time and v is a constant depending on the tension and surface density of the drum. The modes are labelled by integers $n=0,1,\u22ef $ and $m=1,2,3,\u22ef$ where k is the mth zero of $J_n$. The following program produces a plot of the displacement of the membrane in the n=3,m=2 normal mode at time t=0. Table p q --- --- --- --- --- --- def displacement (n, m, r, theta): Calculate the displacement of the drum membrane at (r, theta; t=0) in the normal mode described by integers n = 0, 0 m = mmax. # Pick off the mth zero of Bessel function Jn k = jn_zeros(n, mmax + 1 )[m] return np . sin(n * theta) * jn(n, r * k)","title":"Vibrating Circular Membrane"},{"location":"Scipy/Bessel/Bessel/#oscillating-membrane-single-plot-20","text":"# Allow calculations up to m = mmax mmax = 10 # Positions on the drum surface are specified in polar co-ordinates r = np . linspace( 0 , 1 , 100 ) theta = np . linspace( 0 , 2 * np . pi, 100 ) # Create arrays of cartesian co-ordinates (x, y) ... x = np . array([rr * np . cos(theta) for rr in r]) y = np . array([rr * np . sin(theta) for rr in r]) # ... and vertical displacement (z) for the required normal mode at # time, t = 0 n0, m0 = 2 , 0 z = np . array([displacement(n0, m0, rr, theta) for rr in r]) plt . figure(figsize = [ 8 , 8 ]) pylab . contour(x, y, z) pylab . show()","title":"Oscillating membrane ( SIngle Plot, (2,0))"},{"location":"Scipy/Bessel/Bessel/#oscilating-membrane-single-3d-plot-20","text":"r, theta = np . mgrid[ 0 : 1 : 100 j, 0 : 2 * np . pi: 100 j] x = r * np . cos(theta) y = r * np . sin(theta) z = displacement(n0, m0, r, theta) N = z / (z . max() - z . min()) fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ), figsize = ( 15 , 8 )) im = ax . plot_surface(x, y, z, rstride = 1 , cstride = 1 , facecolors = cm . jet(N)) mm = cm . ScalarMappable(cmap = cm . jet) mm . set_array(R) fig . colorbar(mm, shrink = 0.8 );","title":"Oscilating Membrane ( Single, 3D plot, (2,0))"},{"location":"Scipy/Bessel/Bessel/#oscillating-membrane-multiplot","text":"plt . figure(figsize = [ 15 , 25 ]) k = 0 for n in range ( 6 ): for m in range (n - 1 ): k = k + 1 z = np . array([displacement(n, m, rr, theta) for rr in r]) plt . subplot( 5 , 3 ,k) plt . title( str (n) + str (m)) pylab . contour(x, y, z) pylab . show()","title":"Oscillating Membrane (Multiplot)"},{"location":"Scipy/Bessel/Bessel/#oscilating-membrane-mn-22","text":"n0,m0 = 2 , 2 r, theta = np . mgrid[ 0 : 1 : 100 j, 0 : 2 * np . pi: 100 j] x = r * np . cos(theta) y = r * np . sin(theta) z = displacement(n0, m0, r, theta) N = z / (z . max() - z . min()) fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ), figsize = ( 15 , 8 )) im = ax . plot_surface(x, y, z, rstride = 1 , cstride = 1 , facecolors = cm . jet(N)) mm = cm . ScalarMappable(cmap = cm . jet) mm . set_array(R) fig . colorbar(mm, shrink = 0.8 );","title":"Oscilating Membrane ( m,n = 2,2)"},{"location":"Scipy/Bessel/Bessel/#references","text":"https://en.wikipedia.org/wiki/Vibrations_of_a_circular_membrane https://www.exoruskoh.me/single-post/2017/05/24/Vibrating-Membranes-and-Fancy-Animations https://www.acs.psu.edu/drussell/Demos/MembraneCircle/Circle.html http://balbuceosastropy.blogspot.com/2015/06/spherical-harmonics-in-python.html","title":"References"},{"location":"Scipy/Harmonics/Harmonics/","text":"Spherical Harmonics Scipy Library: Source In this notebook we are going to make some fun with Spherical Harmonics. import numpy as np from scipy.special import jn, yn, jn_zeros, yn_zeros import scipy as sci import scipy.special as sp from __future__ import division import matplotlib.pyplot as plt import matplotlib import pylab from mpl_toolkits.mplot3d import Axes3D from matplotlib import cm, colors % matplotlib inline import seaborn as sns sns . set() Spherical Harmonics \\( Y^m_n(\\theta,\\phi) = \\sqrt{\\frac{2n+1}{4\\pi} \\frac{(n-m)!}{(n+m)!}} e^{i m \\theta} P^m_n(\\cos(\\phi)) \\) Some Examples \\( Y_0^0(\\theta, \\phi) = \\frac{1}{2} \\sqrt{\\frac{1}{\\pi}} \\) \\( Y_1^{-1}(\\theta, \\phi) = \\frac{1}{2} \\sqrt{\\frac{3}{2\\pi}} e^{-i\\theta} \\sin(\\phi) \\) \\( Y_1^0(\\theta, \\phi) = \\frac{1}{2} \\sqrt{\\frac{3}{\\pi}} \\cos(\\phi) \\) \\( Y_1^1(\\theta, \\phi) = -\\frac{1}{2} \\sqrt{\\frac{3}{2\\pi}} e^{i\\theta} \\sin(\\phi) \\) PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] #arrays of angular variables Spherical Harmonics : Y(1,0) l = 1 #degree m = 0 #order R = np . abs(sp . sph_harm(m, l, PHI, THETA)) #Array with the absolute values of Ylm #Now we convert to cartesian coordinates # for the 3D representation X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) # Normalize R for the plot colors to cover the entire range of colormap. N = R / R . max() fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) im = ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 , facecolors = cm . jet(N)) ax . set_title( r $|Y^1_ 0|$ , fontsize = 20 ) m = cm . ScalarMappable(cmap = cm . jet) m . set_array(R) # Assign the unnormalized data array to the mappable #so that the scale corresponds to the values of R fig . colorbar(m, shrink = 0.8 ); Spherical Harmonics : Y(2,0) and Y(2,1) l = 2 #degree m = 1 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] #arrays of angular variables R = np . abs(sp . sph_harm(m, l, PHI, THETA)) #Array with the absolute values of Ylm #Now we convert to cartesian coordinates # for the 3D representation X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) N = R / R . max() # Normalize R for the plot colors to cover the entire range of colormap. fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) im = ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 , facecolors = cm . jet(N)) ax . set_title( r $|Y^2_ 0|$ , fontsize = 20 ) m = cm . ScalarMappable(cmap = cm . jet) m . set_array(R) # Assign the unnormalized data array to the mappable #so that the scale corresponds to the values of R fig . colorbar(m, shrink = 0.8 ); l = 2 # degree m = 1 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] R = sp . sph_harm(m, l, PHI, THETA) . real X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) #As R has negative values, we ll use an instance of Normalize #see http://stackoverflow.com/questions/25023075/\\ #normalizing-colormap-used-by-facecolors-in-matplotlib norm = colors . Normalize() fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ), figsize = ( 10 , 8 )) m = cm . ScalarMappable(cmap = cm . jet) ax . plot_surface(X, Y, Z, rstride = 1 , cstride = 1 , facecolors = cm . jet(norm(R))) ax . set_title( real$(Y^2_ 1)$ , fontsize = 20 ) m . set_array(R) fig . colorbar(m, shrink = 0.8 ); Spherical Harmonics : Y(4,2) l = 4 #degree m = 2 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] #arrays of angular variables R = np . abs(sp . sph_harm(m, l, PHI, THETA)) #Array with the absolute values of Ylm #Now we convert to cartesian coordinates # for the 3D representation X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) N = R / R . max() # Normalize R for the plot colors to cover # the entire range of colormap. fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) im = ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 ,\\ facecolors = cm . jet(N)) ax . set_title( r $|Y^4_ 2|$ , fontsize = 20 ) m = cm . ScalarMappable(cmap = cm . jet) m . set_array(R) # Assign the unnormalized data array to the mappable #so that the scale corresponds to the values of R fig . colorbar(m, shrink = 0.8 ); l = 4 # degree m = 2 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] R = sp . sph_harm(m, l, PHI, THETA) . real X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) #As R has negative values, we ll use an instance of Normalize #see http://stackoverflow.com/questions/25023075/\\ #normalizing-colormap-used-by-facecolors-in-matplotlib norm = colors . Normalize() fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) m = cm . ScalarMappable(cmap = cm . jet) ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 ,\\ facecolors = cm . jet(norm(R))) ax . set_title( real$(Y^4_ 2)$ , fontsize = 20 ) m . set_array(R) fig . colorbar(m, shrink = 0.8 ); References https://en.wikipedia.org/wiki/Vibrations_of_a_circular_membrane https://www.exoruskoh.me/single-post/2017/05/24/Vibrating-Membranes-and-Fancy-Animations https://www.acs.psu.edu/drussell/Demos/MembraneCircle/Circle.html http://balbuceosastropy.blogspot.com/2015/06/spherical-harmonics-in-python.html","title":"Spherical Harmonics"},{"location":"Scipy/Harmonics/Harmonics/#spherical-harmonics","text":"Scipy Library: Source In this notebook we are going to make some fun with Spherical Harmonics. import numpy as np from scipy.special import jn, yn, jn_zeros, yn_zeros import scipy as sci import scipy.special as sp from __future__ import division import matplotlib.pyplot as plt import matplotlib import pylab from mpl_toolkits.mplot3d import Axes3D from matplotlib import cm, colors % matplotlib inline import seaborn as sns sns . set()","title":"Spherical Harmonics"},{"location":"Scipy/Harmonics/Harmonics/#spherical-harmonics_1","text":"\\( Y^m_n(\\theta,\\phi) = \\sqrt{\\frac{2n+1}{4\\pi} \\frac{(n-m)!}{(n+m)!}} e^{i m \\theta} P^m_n(\\cos(\\phi)) \\) Some Examples \\( Y_0^0(\\theta, \\phi) = \\frac{1}{2} \\sqrt{\\frac{1}{\\pi}} \\) \\( Y_1^{-1}(\\theta, \\phi) = \\frac{1}{2} \\sqrt{\\frac{3}{2\\pi}} e^{-i\\theta} \\sin(\\phi) \\) \\( Y_1^0(\\theta, \\phi) = \\frac{1}{2} \\sqrt{\\frac{3}{\\pi}} \\cos(\\phi) \\) \\( Y_1^1(\\theta, \\phi) = -\\frac{1}{2} \\sqrt{\\frac{3}{2\\pi}} e^{i\\theta} \\sin(\\phi) \\) PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] #arrays of angular variables","title":"Spherical Harmonics"},{"location":"Scipy/Harmonics/Harmonics/#spherical-harmonics-y10","text":"l = 1 #degree m = 0 #order R = np . abs(sp . sph_harm(m, l, PHI, THETA)) #Array with the absolute values of Ylm #Now we convert to cartesian coordinates # for the 3D representation X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) # Normalize R for the plot colors to cover the entire range of colormap. N = R / R . max() fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) im = ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 , facecolors = cm . jet(N)) ax . set_title( r $|Y^1_ 0|$ , fontsize = 20 ) m = cm . ScalarMappable(cmap = cm . jet) m . set_array(R) # Assign the unnormalized data array to the mappable #so that the scale corresponds to the values of R fig . colorbar(m, shrink = 0.8 );","title":"Spherical Harmonics : Y(1,0)"},{"location":"Scipy/Harmonics/Harmonics/#spherical-harmonics-y20-and-y21","text":"l = 2 #degree m = 1 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] #arrays of angular variables R = np . abs(sp . sph_harm(m, l, PHI, THETA)) #Array with the absolute values of Ylm #Now we convert to cartesian coordinates # for the 3D representation X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) N = R / R . max() # Normalize R for the plot colors to cover the entire range of colormap. fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) im = ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 , facecolors = cm . jet(N)) ax . set_title( r $|Y^2_ 0|$ , fontsize = 20 ) m = cm . ScalarMappable(cmap = cm . jet) m . set_array(R) # Assign the unnormalized data array to the mappable #so that the scale corresponds to the values of R fig . colorbar(m, shrink = 0.8 ); l = 2 # degree m = 1 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] R = sp . sph_harm(m, l, PHI, THETA) . real X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) #As R has negative values, we ll use an instance of Normalize #see http://stackoverflow.com/questions/25023075/\\ #normalizing-colormap-used-by-facecolors-in-matplotlib norm = colors . Normalize() fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ), figsize = ( 10 , 8 )) m = cm . ScalarMappable(cmap = cm . jet) ax . plot_surface(X, Y, Z, rstride = 1 , cstride = 1 , facecolors = cm . jet(norm(R))) ax . set_title( real$(Y^2_ 1)$ , fontsize = 20 ) m . set_array(R) fig . colorbar(m, shrink = 0.8 );","title":"Spherical Harmonics :  Y(2,0) and Y(2,1)"},{"location":"Scipy/Harmonics/Harmonics/#spherical-harmonics-y42","text":"l = 4 #degree m = 2 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] #arrays of angular variables R = np . abs(sp . sph_harm(m, l, PHI, THETA)) #Array with the absolute values of Ylm #Now we convert to cartesian coordinates # for the 3D representation X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) N = R / R . max() # Normalize R for the plot colors to cover # the entire range of colormap. fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) im = ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 ,\\ facecolors = cm . jet(N)) ax . set_title( r $|Y^4_ 2|$ , fontsize = 20 ) m = cm . ScalarMappable(cmap = cm . jet) m . set_array(R) # Assign the unnormalized data array to the mappable #so that the scale corresponds to the values of R fig . colorbar(m, shrink = 0.8 ); l = 4 # degree m = 2 # order PHI, THETA = np . mgrid[ 0 : 2 * np . pi: 200 j, 0 :np . pi: 100 j] R = sp . sph_harm(m, l, PHI, THETA) . real X = R * np . sin(THETA) * np . cos(PHI) Y = R * np . sin(THETA) * np . sin(PHI) Z = R * np . cos(THETA) #As R has negative values, we ll use an instance of Normalize #see http://stackoverflow.com/questions/25023075/\\ #normalizing-colormap-used-by-facecolors-in-matplotlib norm = colors . Normalize() fig, ax = plt . subplots(subplot_kw = dict (projection = 3d ),\\ figsize = ( 10 , 8 )) m = cm . ScalarMappable(cmap = cm . jet) ax . plot_surface(X, Y, Z, rstride = 1 ,\\ cstride = 1 ,\\ facecolors = cm . jet(norm(R))) ax . set_title( real$(Y^4_ 2)$ , fontsize = 20 ) m . set_array(R) fig . colorbar(m, shrink = 0.8 );","title":"Spherical Harmonics :  Y(4,2)"},{"location":"Scipy/Harmonics/Harmonics/#references","text":"https://en.wikipedia.org/wiki/Vibrations_of_a_circular_membrane https://www.exoruskoh.me/single-post/2017/05/24/Vibrating-Membranes-and-Fancy-Animations https://www.acs.psu.edu/drussell/Demos/MembraneCircle/Circle.html http://balbuceosastropy.blogspot.com/2015/06/spherical-harmonics-in-python.html","title":"References"},{"location":"Scipy/Laplace/laplace/","text":"Laplace Equation We want to solve Laplace equation both analytically and Computationally. Laplace equation in 2D is : \\( \\frac{d^2U}{dx^2} + \\frac{d^2U}{dy^2} = 0 \\) Analytic Solution By considering \\( U(x,y) = X(x)Y(y) \\) one can solve the equation to get analytic solution using periodic boundary conditions \\( U(x,y) = \\sum_{n=1}^{\\infty}E_{n} \\sin \\frac{n\\pi x}{L}\\sinh\\frac{n\\pi y}{L} \\) Where $E_n$ is a constant to be set by further boundary condition. Computational Method There are two methods Method of finite Difference We divide the entire square in to the lattice with equal spacing $\\triangle$ in both in the x and y directions. The x and y variables are now discrete: \\( x = x_o + i\\triangle \\); \\( y = y_o + i\\triangle \\); Where, \\( i,j = 0,N_{max} = L/D \\) We represent the potential by the arrey \\( U(N_{Max},N_{Max}) \\) Finite Difference Algorithm \\( U(i,j) = \\frac{1}{4}[U(i+1,j)+ U(i-1,j) + U(i,j+1) + U(i,j-1)] \\) Boundary Conditions \\( U(i,N_{max}) = 100, \\) (top) \\( U(1,j) = 0, \\) (left) \\( U(N_{max},j) = 0, \\) (right) \\( U(i,1) = 0, \\) (bottom) We define a function to control boundary conditions. Coding import numpy as np from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt import seaborn as sns sns . set() import random constants N = 100 # Number of lattice points Nitr = 1000 # Number of iterations def fun (k): if k == 0 : return 1 else : return 0 Initiate list to hold 2D array of U U = [[ 0.0 for x in range (N)] for y in range (N)] Now we want to impose boundary conditions def boundary_conditions (U): for i in range (N): U[i][N - 1 ] = 100.0 for j in range (N): U[ 0 ][j] = 0.0 for j in range (N): U[N - 1 ][j] = 0.0 for i in range (N): U[i][ 0 ] = 0.0 return U Now we iterate with this begining configurations: itr = 0 boundary_conditions(U) while itr Nitr: for i in range (N): for j in range (N): U[i][j] = ( 0.25 ) * (U[(i + 1 ) % N][j] + \\ U[(i - 1 ) + (fun(i) * N)][j] + U[i][(j + 1 ) % N] + \\ U[i][(j - 1 ) + (fun(j) * N)]) boundary_conditions(U) itr = itr + 1 def val (i,j): return U[i][j] fig = plt . figure(figsize = [ 15 , 8 ]) ax = fig . add_subplot( 111 , projection = 3d ) x = y = np . arange( 0 , N, 1 ) X, Y = np . meshgrid(x, y) ax . set_xlabel( X Label ) ax . set_ylabel( Y Label ) ax . set_zlabel( Z Label ) zs = np . array([val(x,y) for x,y in zip (np . ravel(X), np . ravel(Y))]) Z = zs . reshape(X . shape) ax . plot_surface(X, Y, Z) plt . show()","title":"Laplace Equation"},{"location":"Scipy/Laplace/laplace/#laplace-equation","text":"We want to solve Laplace equation both analytically and Computationally. Laplace equation in 2D is : \\( \\frac{d^2U}{dx^2} + \\frac{d^2U}{dy^2} = 0 \\)","title":"Laplace Equation"},{"location":"Scipy/Laplace/laplace/#analytic-solution","text":"By considering \\( U(x,y) = X(x)Y(y) \\) one can solve the equation to get analytic solution using periodic boundary conditions \\( U(x,y) = \\sum_{n=1}^{\\infty}E_{n} \\sin \\frac{n\\pi x}{L}\\sinh\\frac{n\\pi y}{L} \\) Where $E_n$ is a constant to be set by further boundary condition.","title":"Analytic Solution"},{"location":"Scipy/Laplace/laplace/#computational-method","text":"There are two methods Method of finite Difference We divide the entire square in to the lattice with equal spacing $\\triangle$ in both in the x and y directions. The x and y variables are now discrete: \\( x = x_o + i\\triangle \\); \\( y = y_o + i\\triangle \\); Where, \\( i,j = 0,N_{max} = L/D \\) We represent the potential by the arrey \\( U(N_{Max},N_{Max}) \\) Finite Difference Algorithm \\( U(i,j) = \\frac{1}{4}[U(i+1,j)+ U(i-1,j) + U(i,j+1) + U(i,j-1)] \\) Boundary Conditions \\( U(i,N_{max}) = 100, \\) (top) \\( U(1,j) = 0, \\) (left) \\( U(N_{max},j) = 0, \\) (right) \\( U(i,1) = 0, \\) (bottom) We define a function to control boundary conditions.","title":"Computational Method"},{"location":"Scipy/Laplace/laplace/#coding","text":"import numpy as np from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt import seaborn as sns sns . set() import random constants N = 100 # Number of lattice points Nitr = 1000 # Number of iterations def fun (k): if k == 0 : return 1 else : return 0 Initiate list to hold 2D array of U U = [[ 0.0 for x in range (N)] for y in range (N)] Now we want to impose boundary conditions def boundary_conditions (U): for i in range (N): U[i][N - 1 ] = 100.0 for j in range (N): U[ 0 ][j] = 0.0 for j in range (N): U[N - 1 ][j] = 0.0 for i in range (N): U[i][ 0 ] = 0.0 return U Now we iterate with this begining configurations: itr = 0 boundary_conditions(U) while itr Nitr: for i in range (N): for j in range (N): U[i][j] = ( 0.25 ) * (U[(i + 1 ) % N][j] + \\ U[(i - 1 ) + (fun(i) * N)][j] + U[i][(j + 1 ) % N] + \\ U[i][(j - 1 ) + (fun(j) * N)]) boundary_conditions(U) itr = itr + 1 def val (i,j): return U[i][j] fig = plt . figure(figsize = [ 15 , 8 ]) ax = fig . add_subplot( 111 , projection = 3d ) x = y = np . arange( 0 , N, 1 ) X, Y = np . meshgrid(x, y) ax . set_xlabel( X Label ) ax . set_ylabel( Y Label ) ax . set_zlabel( Z Label ) zs = np . array([val(x,y) for x,y in zip (np . ravel(X), np . ravel(Y))]) Z = zs . reshape(X . shape) ax . plot_surface(X, Y, Z) plt . show()","title":"Coding"},{"location":"Scipy/intro/Numerical-Methods/","text":"Numerical Methods: Integration Differential Equations Integration source import numpy as np from scipy.integrate import quad, dblquad, tplquad $$ y = mx +c$$ def f (x): return 5 * x + 4 x_lower = 0 # the lower limit of x x_upper = 1 # the upper limit of x val, abserr = quad(f, x_lower, x_upper) print ( integral value = , val, , absolute error = , abserr) integral value = 6.499999999999999 , absolute error = 7.216449660063516e-14 Bessel function from scipy.special import jn, yn, jn_zeros, yn_zeros def integrand (x, n): Bessel function of first kind and order n. return jn(n, x) x_lower = 0 # the lower limit of x x_upper = 10 # the upper limit of x val, abserr = quad(integrand, x_lower, x_upper, args = ( 3 ,)) print (val, abserr) 0.7366751370811073 9.389126882496403e-13 Gaussian function val, abserr = quad( lambda x: np . exp( - x ** 2 ), - 5.0 , 5.0 ) print ( numerical = , val, abserr) analytical = np . sqrt(np . pi) print ( analytical = , analytical) numerical = 1.7724538509027912 4.6261378229003154e-14 analytical = 1.7724538509055159 def integrand (x, y): return np . exp( - x ** 2 - y ** 2 ) x_lower = 0 x_upper = 10 y_lower = 0 y_upper = 10 val, abserr = dblquad(integrand, x_lower, x_upper,\\ lambda x : y_lower, lambda x: y_upper) print (val, abserr) 0.7853981633974476 1.3753098510218528e-08 Ordinary Differential Equations Source Odent Source from scipy.integrate import odeint, ode def dy (y, t, zeta, w0): The right-hand side of the damped oscillator ODE x, p = y[ 0 ], y[ 1 ] dx = p dp = - 2 * zeta * w0 * p - w0 ** 2 * x return [dx, dp] # initial state: y0 = [ 1.0 , 0.0 ] # time coodinate to solve the ODE for t = np . linspace( 0 , 10 , 1000 ) w0 = 2 * np . pi * 1.0 # solve the ODE problem for three different values of the damping ratio y1 = odeint(dy, y0, t, args = ( 0.0 , w0)) # undamped y2 = odeint(dy, y0, t, args = ( 0.2 , w0)) # under damped y3 = odeint(dy, y0, t, args = ( 1.0 , w0)) # critial damping y4 = odeint(dy, y0, t, args = ( 5.0 , w0)) # over damped plt . figure(figsize = [ 10 , 8 ]) plt . plot(t, y1[:, 0 ], k , label = undamped , linewidth = 0.25 ) plt . plot(t, y2[:, 0 ], r , label = under damped ) plt . plot(t, y3[:, 0 ], b , label = r critical damping ) plt . plot(t, y4[:, 0 ], g , label = over damped ) plt . legend(); Partial Differential Equations PDE : Eliptic Equation (Laplace Euation) $$ \\nabla^{2} u + c f(u) = 0 $$ $$\\frac{\\partial^{2}u}{\\partial^{2}x} + \\frac{\\partial^{2}u}{\\partial^{2}x} + cf(u) = 0$$ for $c=1, f(u)=0$ it becomes Laplace Equation Using Above lattice of finite difference: $$\\large{u_{i\u22121,j}+u_{i+1,j} + u_{i,j\u22121} + u{i,j+1} \u2212 4u_{i,j}+cf(u_{i,j})=0}$$ $$u_{i,j}=0; \\forall u \\in \u2202\u03a9$$ for 4 by 4 lattice view matrices here: source Problem Type : Solve $$\\large{Ax = b}$$ Implementation of Least square methods to solve a $Ax = b$ problem as a optimization problem % matplotlib inline import matplotlib.pyplot as plt import numpy as np from scipy.optimize import least_squares from scipy.sparse import coo_matrix import seaborn as sns sns . set() n = 100 c = 1 def f (u): return u ** 3 def f_prime (u): return 3 * u ** 2 Prepare the lattice def fun (u, n,f, f_prime,c, ** kwargs): v = np . zeros((n + 2 , n + 2 )) #buttom value = 1 v[n + 1 ,:] = 1 # top value = 1 #v[0,:] = 1 # center value = 1 #v[int(n/2),int(n/2)] = 1 u = u . reshape((n, n)) v[ 1 : - 1 , 1 : - 1 ] = u y = v[: - 2 , 1 : - 1 ] + v[ 2 :, 1 : - 1 ] + \\ v[ 1 : - 1 , : - 2 ] + v[ 1 : - 1 , 2 :] - \\ 4 * u + c * f(u) return y . ravel() Prepare Jacobians def compute_jac_indices (n): i = np . arange(n) jj, ii = np . meshgrid(i, i) ii = ii . ravel() jj = jj . ravel() ij = np . arange(n ** 2 ) jac_rows = [ij] jac_cols = [ij] mask = ii 0 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask - n) mask = ii n - 1 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask + n) mask = jj 0 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask - 1 ) mask = jj n - 1 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask + 1 ) return np . hstack(jac_rows), np . hstack(jac_cols) jac_rows, jac_cols = compute_jac_indices(n) jac_rows, jac_cols (array([ 0, 1, 2, ..., 9996, 9997, 9998]), array([ 0, 1, 2, ..., 9997, 9998, 9999])) def jac (u, n,f, f_prime,c, jac_rows = None , jac_cols = None ): jac_values = np . ones_like(jac_cols, dtype = float ) jac_values[:n ** 2 ] = - 4 + c * f_prime(u) return coo_matrix((jac_values, (jac_rows, jac_cols)), shape = (n ** 2 , n ** 2 )) u0 = np . ones(n ** 2 ) * 0.5 Optimization: Least Square res_1 = least_squares(fun, u0, jac = jac, gtol = 1e-3 , args = (n,f, f_prime,c),\\ kwargs = { jac_rows : jac_rows, jac_cols : jac_cols}, verbose = 1 ) `gtol` termination condition is satisfied. Function evaluations 738, initial cost 1.1562e+02, final cost 6.4462e-01, first-order optimality 9.38e-04. Returned quantities after solution res_1 . x . shape (10000,) res_1 . x array([0.00622038, 0.01236634, 0.01833963, ..., 0.01834064, 0.01236645, 0.00622026]) res_1 . fun array([-0.00014825, -0.00029118, -0.00041394, ..., -0.000414 , -0.00029121, -0.00014826]) res_1 . fun . shape (10000,) res_1 . jac 10000x10000 sparse matrix of type class numpy.float64 with 49600 stored elements in Compressed Sparse Row format Plot the solutions plt . figure(figsize = ( 16 , 5 )) plt . subplot( 131 ) plt . plot(res_1 . x) plt . subplot( 132 ) plt . imshow(res_1 . x . reshape((n, n)),\\ cmap = coolwarm ,\\ vmin =- max ( abs (res_1 . x)),\\ vmax = max ( abs (res_1 . x))) plt . colorbar(use_gridspec = True ,\\ fraction = 0.046 ,\\ pad = 0.04 ) plt . subplot( 133 ) plt . plot(res_1 . fun) plt . tight_layout() References: http://folk.ntnu.no/leifh/teaching/tkt4140/._main000.html http://folk.ntnu.no/leifh/teaching/tkt4140/._main055.html https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html#scipy.optimize.least_squares","title":"Introduction"},{"location":"Scipy/intro/Numerical-Methods/#numerical-methods","text":"Integration Differential Equations","title":"Numerical Methods:"},{"location":"Scipy/intro/Numerical-Methods/#integration-source","text":"import numpy as np from scipy.integrate import quad, dblquad, tplquad $$ y = mx +c$$ def f (x): return 5 * x + 4 x_lower = 0 # the lower limit of x x_upper = 1 # the upper limit of x val, abserr = quad(f, x_lower, x_upper) print ( integral value = , val, , absolute error = , abserr) integral value = 6.499999999999999 , absolute error = 7.216449660063516e-14","title":"Integration source"},{"location":"Scipy/intro/Numerical-Methods/#bessel-function","text":"from scipy.special import jn, yn, jn_zeros, yn_zeros def integrand (x, n): Bessel function of first kind and order n. return jn(n, x) x_lower = 0 # the lower limit of x x_upper = 10 # the upper limit of x val, abserr = quad(integrand, x_lower, x_upper, args = ( 3 ,)) print (val, abserr) 0.7366751370811073 9.389126882496403e-13","title":"Bessel function"},{"location":"Scipy/intro/Numerical-Methods/#gaussian-function","text":"val, abserr = quad( lambda x: np . exp( - x ** 2 ), - 5.0 , 5.0 ) print ( numerical = , val, abserr) analytical = np . sqrt(np . pi) print ( analytical = , analytical) numerical = 1.7724538509027912 4.6261378229003154e-14 analytical = 1.7724538509055159 def integrand (x, y): return np . exp( - x ** 2 - y ** 2 ) x_lower = 0 x_upper = 10 y_lower = 0 y_upper = 10 val, abserr = dblquad(integrand, x_lower, x_upper,\\ lambda x : y_lower, lambda x: y_upper) print (val, abserr) 0.7853981633974476 1.3753098510218528e-08","title":"Gaussian function"},{"location":"Scipy/intro/Numerical-Methods/#ordinary-differential-equations-source","text":"Odent Source from scipy.integrate import odeint, ode def dy (y, t, zeta, w0): The right-hand side of the damped oscillator ODE x, p = y[ 0 ], y[ 1 ] dx = p dp = - 2 * zeta * w0 * p - w0 ** 2 * x return [dx, dp] # initial state: y0 = [ 1.0 , 0.0 ] # time coodinate to solve the ODE for t = np . linspace( 0 , 10 , 1000 ) w0 = 2 * np . pi * 1.0 # solve the ODE problem for three different values of the damping ratio y1 = odeint(dy, y0, t, args = ( 0.0 , w0)) # undamped y2 = odeint(dy, y0, t, args = ( 0.2 , w0)) # under damped y3 = odeint(dy, y0, t, args = ( 1.0 , w0)) # critial damping y4 = odeint(dy, y0, t, args = ( 5.0 , w0)) # over damped plt . figure(figsize = [ 10 , 8 ]) plt . plot(t, y1[:, 0 ], k , label = undamped , linewidth = 0.25 ) plt . plot(t, y2[:, 0 ], r , label = under damped ) plt . plot(t, y3[:, 0 ], b , label = r critical damping ) plt . plot(t, y4[:, 0 ], g , label = over damped ) plt . legend();","title":"Ordinary Differential Equations Source"},{"location":"Scipy/intro/Numerical-Methods/#partial-differential-equations","text":"","title":"Partial Differential Equations"},{"location":"Scipy/intro/Numerical-Methods/#pde-eliptic-equation-laplace-euation","text":"$$ \\nabla^{2} u + c f(u) = 0 $$ $$\\frac{\\partial^{2}u}{\\partial^{2}x} + \\frac{\\partial^{2}u}{\\partial^{2}x} + cf(u) = 0$$ for $c=1, f(u)=0$ it becomes Laplace Equation Using Above lattice of finite difference: $$\\large{u_{i\u22121,j}+u_{i+1,j} + u_{i,j\u22121} + u{i,j+1} \u2212 4u_{i,j}+cf(u_{i,j})=0}$$ $$u_{i,j}=0; \\forall u \\in \u2202\u03a9$$ for 4 by 4 lattice view matrices here: source Problem Type : Solve $$\\large{Ax = b}$$","title":"PDE : Eliptic Equation (Laplace Euation)"},{"location":"Scipy/intro/Numerical-Methods/#implementation-of-least-square-methods-to-solve-a-ax-b-problem-as-a-optimization-problem","text":"% matplotlib inline import matplotlib.pyplot as plt import numpy as np from scipy.optimize import least_squares from scipy.sparse import coo_matrix import seaborn as sns sns . set() n = 100 c = 1 def f (u): return u ** 3 def f_prime (u): return 3 * u ** 2","title":"Implementation of Least square methods to solve a $Ax = b$ problem as a optimization problem"},{"location":"Scipy/intro/Numerical-Methods/#prepare-the-lattice","text":"def fun (u, n,f, f_prime,c, ** kwargs): v = np . zeros((n + 2 , n + 2 )) #buttom value = 1 v[n + 1 ,:] = 1 # top value = 1 #v[0,:] = 1 # center value = 1 #v[int(n/2),int(n/2)] = 1 u = u . reshape((n, n)) v[ 1 : - 1 , 1 : - 1 ] = u y = v[: - 2 , 1 : - 1 ] + v[ 2 :, 1 : - 1 ] + \\ v[ 1 : - 1 , : - 2 ] + v[ 1 : - 1 , 2 :] - \\ 4 * u + c * f(u) return y . ravel()","title":"Prepare the lattice"},{"location":"Scipy/intro/Numerical-Methods/#prepare-jacobians","text":"def compute_jac_indices (n): i = np . arange(n) jj, ii = np . meshgrid(i, i) ii = ii . ravel() jj = jj . ravel() ij = np . arange(n ** 2 ) jac_rows = [ij] jac_cols = [ij] mask = ii 0 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask - n) mask = ii n - 1 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask + n) mask = jj 0 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask - 1 ) mask = jj n - 1 ij_mask = ij[mask] jac_rows . append(ij_mask) jac_cols . append(ij_mask + 1 ) return np . hstack(jac_rows), np . hstack(jac_cols) jac_rows, jac_cols = compute_jac_indices(n) jac_rows, jac_cols (array([ 0, 1, 2, ..., 9996, 9997, 9998]), array([ 0, 1, 2, ..., 9997, 9998, 9999])) def jac (u, n,f, f_prime,c, jac_rows = None , jac_cols = None ): jac_values = np . ones_like(jac_cols, dtype = float ) jac_values[:n ** 2 ] = - 4 + c * f_prime(u) return coo_matrix((jac_values, (jac_rows, jac_cols)), shape = (n ** 2 , n ** 2 )) u0 = np . ones(n ** 2 ) * 0.5","title":"Prepare Jacobians"},{"location":"Scipy/intro/Numerical-Methods/#optimization-least-square","text":"res_1 = least_squares(fun, u0, jac = jac, gtol = 1e-3 , args = (n,f, f_prime,c),\\ kwargs = { jac_rows : jac_rows, jac_cols : jac_cols}, verbose = 1 ) `gtol` termination condition is satisfied. Function evaluations 738, initial cost 1.1562e+02, final cost 6.4462e-01, first-order optimality 9.38e-04.","title":"Optimization: Least Square"},{"location":"Scipy/intro/Numerical-Methods/#returned-quantities-after-solution","text":"res_1 . x . shape (10000,) res_1 . x array([0.00622038, 0.01236634, 0.01833963, ..., 0.01834064, 0.01236645, 0.00622026]) res_1 . fun array([-0.00014825, -0.00029118, -0.00041394, ..., -0.000414 , -0.00029121, -0.00014826]) res_1 . fun . shape (10000,) res_1 . jac 10000x10000 sparse matrix of type class numpy.float64 with 49600 stored elements in Compressed Sparse Row format","title":"Returned quantities after solution"},{"location":"Scipy/intro/Numerical-Methods/#plot-the-solutions","text":"plt . figure(figsize = ( 16 , 5 )) plt . subplot( 131 ) plt . plot(res_1 . x) plt . subplot( 132 ) plt . imshow(res_1 . x . reshape((n, n)),\\ cmap = coolwarm ,\\ vmin =- max ( abs (res_1 . x)),\\ vmax = max ( abs (res_1 . x))) plt . colorbar(use_gridspec = True ,\\ fraction = 0.046 ,\\ pad = 0.04 ) plt . subplot( 133 ) plt . plot(res_1 . fun) plt . tight_layout()","title":"Plot the solutions"},{"location":"Scipy/intro/Numerical-Methods/#references","text":"http://folk.ntnu.no/leifh/teaching/tkt4140/._main000.html http://folk.ntnu.no/leifh/teaching/tkt4140/._main055.html https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html#scipy.optimize.least_squares","title":"References:"},{"location":"machineLearning/clustering/","text":"Clustering: Agglomerative clustering with and without structure ( Source ) This example shows the effect of imposing a connectivity graph to capture local structure in the data. The graph is simply the graph of 20 nearest neighbors. Two consequences of imposing a connectivity can be seen. First clustering with a connectivity matrix is much faster. Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability. \"\"\" Authors: Gael Varoquaux, Nelle Varoquaux License: BSD 3 clause import time import matplotlib.pyplot as plt import numpy as np from sklearn.cluster import AgglomerativeClustering from sklearn.neighbors import kneighbors_graph # Generate sample data n_samples = 1500 np . random . seed( 0 ) t = 1.5 * np . pi * ( 1 + 3 * np . random . rand( 1 , n_samples)) x = t * np . cos(t) y = t * np . sin(t) X = np . concatenate((x, y)) X += . 7 * np . random . randn( 2 , n_samples) X = X . T # Create a graph capturing local connectivity. Larger number of neighbors # will give more homogeneous clusters to the cost of computation # time. A very large number of neighbors gives more evenly distributed # cluster sizes, but may not impose the local manifold structure of # the data knn_graph = kneighbors_graph(X, 30 , include_self = False ) for connectivity in ( None , knn_graph): for n_clusters in ( 30 , 3 ): plt . figure(figsize = ( 10 , 4 )) for index, linkage in enumerate (( average , complete , ward , single )): plt . subplot( 1 , 4 , index + 1 ) model = AgglomerativeClustering(linkage = linkage, connectivity = connectivity, n_clusters = n_clusters) t0 = time . time() model . fit(X) elapsed_time = time . time() - t0 plt . scatter(X[:, 0 ], X[:, 1 ], c = model . labels_, cmap = plt . cm . nipy_spectral) plt . title( linkage= %s \\n (time %.2f s) % (linkage, elapsed_time), fontdict = dict (verticalalignment = top )) plt . axis( equal ) plt . axis( off ) plt . subplots_adjust(bottom = 0 , top =. 83 , wspace = 0 , left = 0 , right = 1 ) plt . suptitle( n_cluster= %i , connectivity= %r % (n_clusters, connectivity is not None ), size = 17 ) plt . show()","title":"Clustering"},{"location":"machineLearning/clustering/#clustering","text":"Agglomerative clustering with and without structure ( Source ) This example shows the effect of imposing a connectivity graph to capture local structure in the data. The graph is simply the graph of 20 nearest neighbors. Two consequences of imposing a connectivity can be seen. First clustering with a connectivity matrix is much faster. Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability. \"\"\" Authors: Gael Varoquaux, Nelle Varoquaux License: BSD 3 clause import time import matplotlib.pyplot as plt import numpy as np from sklearn.cluster import AgglomerativeClustering from sklearn.neighbors import kneighbors_graph # Generate sample data n_samples = 1500 np . random . seed( 0 ) t = 1.5 * np . pi * ( 1 + 3 * np . random . rand( 1 , n_samples)) x = t * np . cos(t) y = t * np . sin(t) X = np . concatenate((x, y)) X += . 7 * np . random . randn( 2 , n_samples) X = X . T # Create a graph capturing local connectivity. Larger number of neighbors # will give more homogeneous clusters to the cost of computation # time. A very large number of neighbors gives more evenly distributed # cluster sizes, but may not impose the local manifold structure of # the data knn_graph = kneighbors_graph(X, 30 , include_self = False ) for connectivity in ( None , knn_graph): for n_clusters in ( 30 , 3 ): plt . figure(figsize = ( 10 , 4 )) for index, linkage in enumerate (( average , complete , ward , single )): plt . subplot( 1 , 4 , index + 1 ) model = AgglomerativeClustering(linkage = linkage, connectivity = connectivity, n_clusters = n_clusters) t0 = time . time() model . fit(X) elapsed_time = time . time() - t0 plt . scatter(X[:, 0 ], X[:, 1 ], c = model . labels_, cmap = plt . cm . nipy_spectral) plt . title( linkage= %s \\n (time %.2f s) % (linkage, elapsed_time), fontdict = dict (verticalalignment = top )) plt . axis( equal ) plt . axis( off ) plt . subplots_adjust(bottom = 0 , top =. 83 , wspace = 0 , left = 0 , right = 1 ) plt . suptitle( n_cluster= %i , connectivity= %r % (n_clusters, connectivity is not None ), size = 17 ) plt . show()","title":"Clustering:"},{"location":"machineLearning/linear/","text":"Linear models A Simple Linear Regression Example ( source ) This example uses the only the first feature of the diabetes dataset, in order to illustrate a two-dimensional plot of this regression technique. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation. The coefficients , the residual sum of squares and the variance score are also calculated. import numpy as np from sklearn import datasets, linear_model Import Diabetes Dataset diabetes = datasets . load_diabetes() Use only one feature diabetes_X = diabetes . data[:, np . newaxis, 2 ] Split Dataset to Train and Test Split the data into training/testing sets diabetes_X_train = diabetes_X[: - 20 ] diabetes_X_test = diabetes_X[ - 20 :] Split the targets into training/testing sets diabetes_y_train = diabetes . target[: - 20 ] diabetes_y_test = diabetes . target[ - 20 :] Fit the Model Create linear regression object regr = linear_model . LinearRegression() Train the model using the training sets regr . fit(diabetes_X_train, diabetes_y_train) LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) Calculate Regression cofficient, Mean Squared Error and Variance score. The coefficients print ( Coefficients: \\n , regr . coef_) The mean squared error print ( Mean squared error: %.2f % np . mean((regr . predict(diabetes_X_test) - diabetes_y_test) ** 2 )) Explained variance score: 1 is perfect prediction print ( Variance score: %.2f % regr . score(diabetes_X_test, diabetes_y_test)) Coefficients: [938.23786125] Mean squared error: 2548.07 Variance score: 0.47 import matplotlib.pyplot as plt import seaborn as sns sns . set() Plot outputs plt . figure(figsize = [ 12 , 8 ]) plt . scatter(diabetes_X_test,\\ diabetes_y_test,\\ color = black ) plt . plot(diabetes_X_test,\\ regr . predict(diabetes_X_test),\\ color = blue , linewidth = 3 ) plt . grid( True ) plt . show()","title":"Linear Regression"},{"location":"machineLearning/linear/#linear-models","text":"A Simple Linear Regression Example ( source ) This example uses the only the first feature of the diabetes dataset, in order to illustrate a two-dimensional plot of this regression technique. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation. The coefficients , the residual sum of squares and the variance score are also calculated. import numpy as np from sklearn import datasets, linear_model Import Diabetes Dataset diabetes = datasets . load_diabetes() Use only one feature diabetes_X = diabetes . data[:, np . newaxis, 2 ] Split Dataset to Train and Test Split the data into training/testing sets diabetes_X_train = diabetes_X[: - 20 ] diabetes_X_test = diabetes_X[ - 20 :] Split the targets into training/testing sets diabetes_y_train = diabetes . target[: - 20 ] diabetes_y_test = diabetes . target[ - 20 :] Fit the Model Create linear regression object regr = linear_model . LinearRegression() Train the model using the training sets regr . fit(diabetes_X_train, diabetes_y_train) LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) Calculate Regression cofficient, Mean Squared Error and Variance score. The coefficients print ( Coefficients: \\n , regr . coef_) The mean squared error print ( Mean squared error: %.2f % np . mean((regr . predict(diabetes_X_test) - diabetes_y_test) ** 2 )) Explained variance score: 1 is perfect prediction print ( Variance score: %.2f % regr . score(diabetes_X_test, diabetes_y_test)) Coefficients: [938.23786125] Mean squared error: 2548.07 Variance score: 0.47 import matplotlib.pyplot as plt import seaborn as sns sns . set() Plot outputs plt . figure(figsize = [ 12 , 8 ]) plt . scatter(diabetes_X_test,\\ diabetes_y_test,\\ color = black ) plt . plot(diabetes_X_test,\\ regr . predict(diabetes_X_test),\\ color = blue , linewidth = 3 ) plt . grid( True ) plt . show()","title":"Linear models"},{"location":"machineLearning/logistic/","text":"Logistic Regression 3-class Classifier ( source ) Show below is a logistic-regression classifiers decision boundaries on the iris https://en.wikipedia.org/wiki/Iris_flower_data_set _ dataset. The datapoints are colored according to their labels. import numpy as np import matplotlib.pyplot as plt from sklearn import linear_model, datasets # import some data to play with iris = datasets . load_iris() X = iris . data[:, : 2 ] # we only take the first two features. Y = iris . target h = . 02 # step size in the mesh logreg = linear_model . LogisticRegression(C = 1e5 ) # we create an instance of Neighbours # Classifier and fit the data. logreg . fit(X, Y) # Plot the decision boundary. # For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. x_min, x_max = X[:, 0 ] . min() - . 5 , X[:, 0 ] . max() + . 5 y_min, y_max = X[:, 1 ] . min() - . 5 , X[:, 1 ] . max() + . 5 xx, yy = np . meshgrid(np . arange(x_min, x_max, h),\\ np . arange(y_min, y_max, h)) Z = logreg . predict(np . c_[xx . ravel(), yy . ravel()]) # Put the result into a color plot Z = Z . reshape(xx . shape) plt . figure( 1 , figsize = ( 10 , 6 )) plt . pcolormesh(xx, yy, Z, cmap = plt . cm . Paired) # Plot also the training points plt . scatter(X[:, 0 ], X[:, 1 ], c = Y,\\ edgecolors = k , cmap = plt . cm . Paired) plt . xlabel( Sepal length ) plt . ylabel( Sepal width ) plt . xlim(xx . min(), xx . max()) plt . ylim(yy . min(), yy . max()) plt . xticks(()) plt . yticks(()) plt . show()","title":"Logistic Regression"},{"location":"machineLearning/logistic/#logistic-regression","text":"3-class Classifier ( source ) Show below is a logistic-regression classifiers decision boundaries on the iris https://en.wikipedia.org/wiki/Iris_flower_data_set _ dataset. The datapoints are colored according to their labels. import numpy as np import matplotlib.pyplot as plt from sklearn import linear_model, datasets # import some data to play with iris = datasets . load_iris() X = iris . data[:, : 2 ] # we only take the first two features. Y = iris . target h = . 02 # step size in the mesh logreg = linear_model . LogisticRegression(C = 1e5 ) # we create an instance of Neighbours # Classifier and fit the data. logreg . fit(X, Y) # Plot the decision boundary. # For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. x_min, x_max = X[:, 0 ] . min() - . 5 , X[:, 0 ] . max() + . 5 y_min, y_max = X[:, 1 ] . min() - . 5 , X[:, 1 ] . max() + . 5 xx, yy = np . meshgrid(np . arange(x_min, x_max, h),\\ np . arange(y_min, y_max, h)) Z = logreg . predict(np . c_[xx . ravel(), yy . ravel()]) # Put the result into a color plot Z = Z . reshape(xx . shape) plt . figure( 1 , figsize = ( 10 , 6 )) plt . pcolormesh(xx, yy, Z, cmap = plt . cm . Paired) # Plot also the training points plt . scatter(X[:, 0 ], X[:, 1 ], c = Y,\\ edgecolors = k , cmap = plt . cm . Paired) plt . xlabel( Sepal length ) plt . ylabel( Sepal width ) plt . xlim(xx . min(), xx . max()) plt . ylim(yy . min(), yy . max()) plt . xticks(()) plt . yticks(()) plt . show()","title":"Logistic Regression"},{"location":"machineLearning/nnc/","text":"Nearest Neighbors Nearest Neighbors Classification ( Source ) Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class. import numpy as np import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap from sklearn import neighbors, datasets n_neighbors = 15 # import some data to play with iris = datasets . load_iris() # we only take the first two features. We could avoid this ugly # slicing by using a two-dim dataset X = iris . data[:, : 2 ] y = iris . target h = . 02 # step size in the mesh # Create color maps cmap_light = ListedColormap([ orange , cyan , cornflowerblue ]) cmap_bold = ListedColormap([ darkorange , c , darkblue ]) for weights in [ uniform , distance ]: # we create an instance of Neighbours Classifier and fit the data. clf = neighbors . KNeighborsClassifier(n_neighbors, weights = weights) clf . fit(X, y) # Plot the decision boundary. For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. x_min, x_max = X[:, 0 ] . min() - 1 , X[:, 0 ] . max() + 1 y_min, y_max = X[:, 1 ] . min() - 1 , X[:, 1 ] . max() + 1 xx, yy = np . meshgrid(np . arange(x_min, x_max, h), np . arange(y_min, y_max, h)) Z = clf . predict(np . c_[xx . ravel(), yy . ravel()]) # Put the result into a color plot Z = Z . reshape(xx . shape) plt . figure(figsize = [ 10 , 6 ]) plt . pcolormesh(xx, yy, Z, cmap = cmap_light) # Plot also the training points plt . scatter(X[:, 0 ], X[:, 1 ], c = y, cmap = cmap_bold, edgecolor = k , s = 20 ) plt . xlim(xx . min(), xx . max()) plt . ylim(yy . min(), yy . max()) plt . title( 3-Class classification (k = %i , weights = %s ) % (n_neighbors, weights)) plt . show()","title":"Nearest Neighbours"},{"location":"machineLearning/nnc/#nearest-neighbors","text":"Nearest Neighbors Classification ( Source ) Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class. import numpy as np import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap from sklearn import neighbors, datasets n_neighbors = 15 # import some data to play with iris = datasets . load_iris() # we only take the first two features. We could avoid this ugly # slicing by using a two-dim dataset X = iris . data[:, : 2 ] y = iris . target h = . 02 # step size in the mesh # Create color maps cmap_light = ListedColormap([ orange , cyan , cornflowerblue ]) cmap_bold = ListedColormap([ darkorange , c , darkblue ]) for weights in [ uniform , distance ]: # we create an instance of Neighbours Classifier and fit the data. clf = neighbors . KNeighborsClassifier(n_neighbors, weights = weights) clf . fit(X, y) # Plot the decision boundary. For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. x_min, x_max = X[:, 0 ] . min() - 1 , X[:, 0 ] . max() + 1 y_min, y_max = X[:, 1 ] . min() - 1 , X[:, 1 ] . max() + 1 xx, yy = np . meshgrid(np . arange(x_min, x_max, h), np . arange(y_min, y_max, h)) Z = clf . predict(np . c_[xx . ravel(), yy . ravel()]) # Put the result into a color plot Z = Z . reshape(xx . shape) plt . figure(figsize = [ 10 , 6 ]) plt . pcolormesh(xx, yy, Z, cmap = cmap_light) # Plot also the training points plt . scatter(X[:, 0 ], X[:, 1 ], c = y, cmap = cmap_bold, edgecolor = k , s = 20 ) plt . xlim(xx . min(), xx . max()) plt . ylim(yy . min(), yy . max()) plt . title( 3-Class classification (k = %i , weights = %s ) % (n_neighbors, weights)) plt . show()","title":"Nearest Neighbors"},{"location":"machineLearning/perceptron/","text":"Perceptron Varying regularization in Multi-layer Perceptron ( Source ) A comparison of different values for regularization parameter 'alpha' on synthetic datasets. The plot shows that different alphas yield different decision functions. Alpha is a parameter for regularization term, aka penalty term, that combats overfitting by constraining the size of the weights. Increasing alpha may fix high variance (a sign of overfitting) by encouraging smaller weights, resulting in a decision boundary plot that appears with lesser curvatures. Similarly, decreasing alpha may fix high bias (a sign of underfitting) by encouraging larger weights, potentially resulting in a more complicated decision boundary. Author: Issam H. Laradji License: BSD 3 clause import numpy as np from matplotlib import pyplot as plt from matplotlib.colors import ListedColormap from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.datasets import make_moons, make_circles, make_classification from sklearn.neural_network import MLPClassifier from sklearn.pipeline import make_pipeline h = . 02 # step size in the mesh alphas = np . logspace( - 5 , 3 , 5 ) names = [ alpha + str (i) for i in alphas] classifiers = [] for i in alphas: classifiers . append(make_pipeline( StandardScaler(), MLPClassifier(solver = lbfgs , alpha = i, random_state = 1 , max_iter = 2000 , early_stopping = True , hidden_layer_sizes = [ 100 , 100 ]) )) X, y = make_classification(n_features = 2 , n_redundant = 0 , n_informative = 2 , random_state = 0 , n_clusters_per_class = 1 ) rng = np . random . RandomState( 2 ) X += 2 * rng . uniform(size = X . shape) linearly_separable = (X, y) datasets = [make_moons(noise = 0.3 , random_state = 0 ), make_circles(noise = 0.2 , factor = 0.5 , random_state = 1 ), linearly_separable] figure = plt . figure(figsize = ( 17 , 9 )) i = 1 # iterate over datasets for X, y in datasets: # preprocess dataset, split into training and test part X = StandardScaler() . fit_transform(X) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =. 4 ) x_min, x_max = X[:, 0 ] . min() - . 5 , X[:, 0 ] . max() + . 5 y_min, y_max = X[:, 1 ] . min() - . 5 , X[:, 1 ] . max() + . 5 xx, yy = np . meshgrid(np . arange(x_min, x_max, h), np . arange(y_min, y_max, h)) # just plot the dataset first cm = plt . cm . RdBu cm_bright = ListedColormap([ #FF0000 , #0000FF ]) ax = plt . subplot( len (datasets), len (classifiers) + 1 , i) # Plot the training points ax . scatter(X_train[:, 0 ], X_train[:, 1 ], c = y_train, cmap = cm_bright) # and testing points ax . scatter(X_test[:, 0 ], X_test[:, 1 ], c = y_test, cmap = cm_bright, alpha = 0.6 ) ax . set_xlim(xx . min(), xx . max()) ax . set_ylim(yy . min(), yy . max()) ax . set_xticks(()) ax . set_yticks(()) i += 1 # iterate over classifiers for name, clf in zip (names, classifiers): ax = plt . subplot( len (datasets), len (classifiers) + 1 , i) clf . fit(X_train, y_train) score = clf . score(X_test, y_test) # Plot the decision boundary. For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. if hasattr (clf, decision_function ): Z = clf . decision_function(np . c_[xx . ravel(), yy . ravel()]) else : Z = clf . predict_proba(np . c_[xx . ravel(), yy . ravel()])[:, 1 ] # Put the result into a color plot Z = Z . reshape(xx . shape) ax . contourf(xx, yy, Z, cmap = cm, alpha =. 8 ) # Plot also the training points ax . scatter(X_train[:, 0 ], X_train[:, 1 ], c = y_train, cmap = cm_bright, edgecolors = black , s = 25 ) # and testing points ax . scatter(X_test[:, 0 ], X_test[:, 1 ], c = y_test, cmap = cm_bright, alpha = 0.6 , edgecolors = black , s = 25 ) ax . set_xlim(xx . min(), xx . max()) ax . set_ylim(yy . min(), yy . max()) ax . set_xticks(()) ax . set_yticks(()) ax . set_title(name) ax . text(xx . max() - . 3 , yy . min() + . 3 , ( %.2f % score) . lstrip( 0 ), size = 15 , horizontalalignment = right ) i += 1 figure . subplots_adjust(left =. 02 , right =. 98 ) plt . show()","title":"Perceptron"},{"location":"machineLearning/perceptron/#perceptron","text":"Varying regularization in Multi-layer Perceptron ( Source ) A comparison of different values for regularization parameter 'alpha' on synthetic datasets. The plot shows that different alphas yield different decision functions. Alpha is a parameter for regularization term, aka penalty term, that combats overfitting by constraining the size of the weights. Increasing alpha may fix high variance (a sign of overfitting) by encouraging smaller weights, resulting in a decision boundary plot that appears with lesser curvatures. Similarly, decreasing alpha may fix high bias (a sign of underfitting) by encouraging larger weights, potentially resulting in a more complicated decision boundary. Author: Issam H. Laradji License: BSD 3 clause import numpy as np from matplotlib import pyplot as plt from matplotlib.colors import ListedColormap from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.datasets import make_moons, make_circles, make_classification from sklearn.neural_network import MLPClassifier from sklearn.pipeline import make_pipeline h = . 02 # step size in the mesh alphas = np . logspace( - 5 , 3 , 5 ) names = [ alpha + str (i) for i in alphas] classifiers = [] for i in alphas: classifiers . append(make_pipeline( StandardScaler(), MLPClassifier(solver = lbfgs , alpha = i, random_state = 1 , max_iter = 2000 , early_stopping = True , hidden_layer_sizes = [ 100 , 100 ]) )) X, y = make_classification(n_features = 2 , n_redundant = 0 , n_informative = 2 , random_state = 0 , n_clusters_per_class = 1 ) rng = np . random . RandomState( 2 ) X += 2 * rng . uniform(size = X . shape) linearly_separable = (X, y) datasets = [make_moons(noise = 0.3 , random_state = 0 ), make_circles(noise = 0.2 , factor = 0.5 , random_state = 1 ), linearly_separable] figure = plt . figure(figsize = ( 17 , 9 )) i = 1 # iterate over datasets for X, y in datasets: # preprocess dataset, split into training and test part X = StandardScaler() . fit_transform(X) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =. 4 ) x_min, x_max = X[:, 0 ] . min() - . 5 , X[:, 0 ] . max() + . 5 y_min, y_max = X[:, 1 ] . min() - . 5 , X[:, 1 ] . max() + . 5 xx, yy = np . meshgrid(np . arange(x_min, x_max, h), np . arange(y_min, y_max, h)) # just plot the dataset first cm = plt . cm . RdBu cm_bright = ListedColormap([ #FF0000 , #0000FF ]) ax = plt . subplot( len (datasets), len (classifiers) + 1 , i) # Plot the training points ax . scatter(X_train[:, 0 ], X_train[:, 1 ], c = y_train, cmap = cm_bright) # and testing points ax . scatter(X_test[:, 0 ], X_test[:, 1 ], c = y_test, cmap = cm_bright, alpha = 0.6 ) ax . set_xlim(xx . min(), xx . max()) ax . set_ylim(yy . min(), yy . max()) ax . set_xticks(()) ax . set_yticks(()) i += 1 # iterate over classifiers for name, clf in zip (names, classifiers): ax = plt . subplot( len (datasets), len (classifiers) + 1 , i) clf . fit(X_train, y_train) score = clf . score(X_test, y_test) # Plot the decision boundary. For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. if hasattr (clf, decision_function ): Z = clf . decision_function(np . c_[xx . ravel(), yy . ravel()]) else : Z = clf . predict_proba(np . c_[xx . ravel(), yy . ravel()])[:, 1 ] # Put the result into a color plot Z = Z . reshape(xx . shape) ax . contourf(xx, yy, Z, cmap = cm, alpha =. 8 ) # Plot also the training points ax . scatter(X_train[:, 0 ], X_train[:, 1 ], c = y_train, cmap = cm_bright, edgecolors = black , s = 25 ) # and testing points ax . scatter(X_test[:, 0 ], X_test[:, 1 ], c = y_test, cmap = cm_bright, alpha = 0.6 , edgecolors = black , s = 25 ) ax . set_xlim(xx . min(), xx . max()) ax . set_ylim(yy . min(), yy . max()) ax . set_xticks(()) ax . set_yticks(()) ax . set_title(name) ax . text(xx . max() - . 3 , yy . min() + . 3 , ( %.2f % score) . lstrip( 0 ), size = 15 , horizontalalignment = right ) i += 1 figure . subplots_adjust(left =. 02 , right =. 98 ) plt . show()","title":"Perceptron"},{"location":"machineLearning/svm/","text":"Support Vector Machine (SVM): Maximum margin separating hyperplane ( Source )_ Plot the maximum margin separating hyperplane within a two-class separable dataset using a Support Vector Machine classifier with linear kernel. import numpy as np import matplotlib.pyplot as plt from sklearn import svm from sklearn.datasets import make_blobs # we create 40 separable points X, y = make_blobs(n_samples = 40 , centers = 2 , random_state = 6 ) # fit the model, don t regularize for illustration purposes clf = svm . SVC(kernel = linear , C = 1000 ) clf . fit(X, y) plt . figure(figsize = [ 12 , 8 ]) plt . scatter(X[:, 0 ], X[:, 1 ], c = y, s = 30 , cmap = plt . cm . Paired) # plot the decision function ax = plt . gca() xlim = ax . get_xlim() ylim = ax . get_ylim() # create grid to evaluate model xx = np . linspace(xlim[ 0 ], xlim[ 1 ], 30 ) yy = np . linspace(ylim[ 0 ], ylim[ 1 ], 30 ) YY, XX = np . meshgrid(yy, xx) xy = np . vstack([XX . ravel(), YY . ravel()]) . T Z = clf . decision_function(xy) . reshape(XX . shape) # plot decision boundary and margins ax . contour(XX, YY, Z, colors = k , levels = [ - 1 , 0 , 1 ], alpha = 0.5 , linestyles = [ -- , - , -- ]) # plot support vectors ax . scatter(clf . support_vectors_[:, 0 ], clf . support_vectors_[:, 1 ], s = 100 , linewidth = 1 , facecolors = none , edgecolors = k ) plt . show()","title":"Support Vector Machine"},{"location":"machineLearning/svm/#support-vector-machine-svm","text":"Maximum margin separating hyperplane ( Source )_ Plot the maximum margin separating hyperplane within a two-class separable dataset using a Support Vector Machine classifier with linear kernel. import numpy as np import matplotlib.pyplot as plt from sklearn import svm from sklearn.datasets import make_blobs # we create 40 separable points X, y = make_blobs(n_samples = 40 , centers = 2 , random_state = 6 ) # fit the model, don t regularize for illustration purposes clf = svm . SVC(kernel = linear , C = 1000 ) clf . fit(X, y) plt . figure(figsize = [ 12 , 8 ]) plt . scatter(X[:, 0 ], X[:, 1 ], c = y, s = 30 , cmap = plt . cm . Paired) # plot the decision function ax = plt . gca() xlim = ax . get_xlim() ylim = ax . get_ylim() # create grid to evaluate model xx = np . linspace(xlim[ 0 ], xlim[ 1 ], 30 ) yy = np . linspace(ylim[ 0 ], ylim[ 1 ], 30 ) YY, XX = np . meshgrid(yy, xx) xy = np . vstack([XX . ravel(), YY . ravel()]) . T Z = clf . decision_function(xy) . reshape(XX . shape) # plot decision boundary and margins ax . contour(XX, YY, Z, colors = k , levels = [ - 1 , 0 , 1 ], alpha = 0.5 , linestyles = [ -- , - , -- ]) # plot support vectors ax . scatter(clf . support_vectors_[:, 0 ], clf . support_vectors_[:, 1 ], s = 100 , linewidth = 1 , facecolors = none , edgecolors = k ) plt . show()","title":"Support Vector Machine (SVM):"},{"location":"machineLearning/tree/","text":"Decision Tree Decision Tree Regression ( Source ) A 1D regression with decision tree. The :ref: decision trees tree is used to fit a sine curve with addition noisy observation. As a result, it learns local linear regressions approximating the sine curve. We can see that if the maximum depth of the tree (controlled by the max_depth parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit. # Import the necessary modules and libraries import numpy as np from sklearn.tree import DecisionTreeRegressor import matplotlib.pyplot as plt # Create a random dataset rng = np . random . RandomState( 1 ) X = np . sort( 5 * rng . rand( 80 , 1 ), axis = 0 ) y = np . sin(X) . ravel() y[:: 5 ] += 3 * ( 0.5 - rng . rand( 16 )) # Fit regression model regr_1 = DecisionTreeRegressor(max_depth = 2 ) regr_2 = DecisionTreeRegressor(max_depth = 5 ) regr_1 . fit(X, y) regr_2 . fit(X, y) # Predict X_test = np . arange( 0.0 , 5.0 , 0.01 )[:, np . newaxis] y_1 = regr_1 . predict(X_test) y_2 = regr_2 . predict(X_test) # Plot the results plt . figure(figsize = [ 12 , 8 ]) plt . scatter(X, y, s = 20 , edgecolor = black , c = darkorange , label = data ) plt . plot(X_test, y_1, color = cornflowerblue , label = max_depth=2 , linewidth = 2 ) plt . plot(X_test, y_2, color = yellowgreen , label = max_depth=5 , linewidth = 2 ) plt . xlabel( data ) plt . ylabel( target ) plt . title( Decision Tree Regression ) plt . legend() plt . show()","title":"Decision Tree"},{"location":"machineLearning/tree/#decision-tree","text":"Decision Tree Regression ( Source ) A 1D regression with decision tree. The :ref: decision trees tree is used to fit a sine curve with addition noisy observation. As a result, it learns local linear regressions approximating the sine curve. We can see that if the maximum depth of the tree (controlled by the max_depth parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit. # Import the necessary modules and libraries import numpy as np from sklearn.tree import DecisionTreeRegressor import matplotlib.pyplot as plt # Create a random dataset rng = np . random . RandomState( 1 ) X = np . sort( 5 * rng . rand( 80 , 1 ), axis = 0 ) y = np . sin(X) . ravel() y[:: 5 ] += 3 * ( 0.5 - rng . rand( 16 )) # Fit regression model regr_1 = DecisionTreeRegressor(max_depth = 2 ) regr_2 = DecisionTreeRegressor(max_depth = 5 ) regr_1 . fit(X, y) regr_2 . fit(X, y) # Predict X_test = np . arange( 0.0 , 5.0 , 0.01 )[:, np . newaxis] y_1 = regr_1 . predict(X_test) y_2 = regr_2 . predict(X_test) # Plot the results plt . figure(figsize = [ 12 , 8 ]) plt . scatter(X, y, s = 20 , edgecolor = black , c = darkorange , label = data ) plt . plot(X_test, y_1, color = cornflowerblue , label = max_depth=2 , linewidth = 2 ) plt . plot(X_test, y_2, color = yellowgreen , label = max_depth=5 , linewidth = 2 ) plt . xlabel( data ) plt . ylabel( target ) plt . title( Decision Tree Regression ) plt . legend() plt . show()","title":"Decision Tree"}]}